{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANSWER KEY: Capstone Project Solution\n",
    "\n",
    "This notebook contains complete solutions for the StreamCart Retention System capstone.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except:\n",
    "    !pip install lightgbm -q\n",
    "    import lightgbm as lgb\n",
    "\n",
    "# Load data\n",
    "DATA_URL = \"https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/\"\n",
    "customers = pd.read_csv(DATA_URL + \"streamcart_customers.csv\")\n",
    "print(f\"Loaded {len(customers):,} customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Problem Framing - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Completed framing template\n",
    "\n",
    "framing_solution = \"\"\"\n",
    "=== ML PROBLEM FRAMING ===\n",
    "\n",
    "1. Business Goal: Reduce customer churn by targeting at-risk customers with retention calls.\n",
    "\n",
    "2. ML Task Type: Binary Classification\n",
    "\n",
    "3. Target (y): churn_30d - whether a customer cancels within 30 days of the snapshot date.\n",
    "\n",
    "4. Prediction Point: Weekly, on the snapshot_date for each customer.\n",
    "\n",
    "5. Features (X): Historical data available before snapshot_date:\n",
    "   - Account info: tenure_months, subscription_plan\n",
    "   - Activity: logins_last_30d, orders_last_30d\n",
    "   - Support: support_tickets_last_30d\n",
    "   - Sentiment: nps_score\n",
    "   - Derived: orders_per_month, support_intensity, engagement_score\n",
    "\n",
    "6. Success Metric: Precision@500 (accuracy in the top 500 predictions)\n",
    "   - Why: We have a capacity constraint of 500 calls/week\n",
    "   - Secondary: Lift over random baseline\n",
    "\n",
    "7. Business Action: Top 500 predicted churners receive retention calls with discount offers.\n",
    "   - If prediction = high risk AND customer is called → 30% chance of saving them\n",
    "   - Each saved customer = $200 value\n",
    "   - Each call = $15 cost\n",
    "\"\"\"\n",
    "print(framing_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Baseline calculation\n",
    "\n",
    "base_churn_rate = customers['churn_30d'].mean()\n",
    "calls_per_week = 500\n",
    "save_rate = 0.30\n",
    "value_per_save = 200\n",
    "cost_per_call = 15\n",
    "\n",
    "# Random selection baseline\n",
    "expected_churners_random = calls_per_week * base_churn_rate\n",
    "expected_saves_random = expected_churners_random * save_rate\n",
    "net_value_random = (expected_saves_random * value_per_save) - (calls_per_week * cost_per_call)\n",
    "\n",
    "print(f\"=== RANDOM SELECTION BASELINE ===\")\n",
    "print(f\"Churn rate: {base_churn_rate:.1%}\")\n",
    "print(f\"Expected churners in 500 random calls: {expected_churners_random:.0f}\")\n",
    "print(f\"Expected saves: {expected_saves_random:.0f}\")\n",
    "print(f\"Net value: ${net_value_random:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Feature Engineering - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Feature engineering\n",
    "\n",
    "df = customers.copy()\n",
    "\n",
    "# Feature 1: Orders per month (ratio - normalizes by tenure)\n",
    "df['orders_per_month'] = df['orders_last_30d'] / (df['tenure_months'] + 1)\n",
    "\n",
    "# Feature 2: Support intensity (high tickets relative to tenure = problem)\n",
    "df['support_intensity'] = df['support_tickets_last_30d'] / (df['tenure_months'] + 1)\n",
    "\n",
    "# Feature 3: Engagement score (logins per order - high ratio might mean browsing without buying)\n",
    "df['engagement_score'] = df['logins_last_30d'] / (df['orders_last_30d'] + 1)\n",
    "\n",
    "# Feature 4: Low NPS flag (detractors)\n",
    "df['is_detractor'] = (df['nps_score'] <= 6).astype(int)\n",
    "\n",
    "# Feature 5: New customer flag (first 3 months are risky)\n",
    "df['is_new_customer'] = (df['tenure_months'] <= 3).astype(int)\n",
    "\n",
    "print(\"Engineered features:\")\n",
    "print(df[['orders_per_month', 'support_intensity', 'engagement_score', 'is_detractor', 'is_new_customer']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Leakage audit\n",
    "\n",
    "leakage_audit_solution = \"\"\"\n",
    "=== FEATURE LEAKAGE AUDIT ===\n",
    "\n",
    "| Feature | Source | Available at prediction? | Safe? |\n",
    "|---------|--------|-------------------------|-------|\n",
    "| tenure_months | Account creation date | Yes - historical | ✓ |\n",
    "| logins_last_30d | Activity logs | Yes - historical | ✓ |\n",
    "| orders_last_30d | Order history | Yes - historical | ✓ |\n",
    "| support_tickets_last_30d | Support system | Yes - historical | ✓ |\n",
    "| nps_score | Survey response | Yes - collected before snapshot | ✓ |\n",
    "| orders_per_month | orders / tenure | Yes - derived from safe features | ✓ |\n",
    "| support_intensity | tickets / tenure | Yes - derived from safe features | ✓ |\n",
    "| engagement_score | logins / orders | Yes - derived from safe features | ✓ |\n",
    "| is_detractor | nps_score <= 6 | Yes - derived from safe feature | ✓ |\n",
    "| is_new_customer | tenure <= 3 | Yes - derived from safe feature | ✓ |\n",
    "\n",
    "EXCLUDED (leaky):\n",
    "- churn_date: Only known AFTER churn happens\n",
    "- cancel_reason: Only known AFTER cancellation\n",
    "\n",
    "Confirm: ✓ All features use data available at prediction time.\n",
    "\"\"\"\n",
    "print(leakage_audit_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Final feature set\n",
    "\n",
    "all_features = [\n",
    "    # Base features\n",
    "    'tenure_months',\n",
    "    'logins_last_30d',\n",
    "    'orders_last_30d',\n",
    "    'support_tickets_last_30d',\n",
    "    'nps_score',\n",
    "    # Engineered features\n",
    "    'orders_per_month',\n",
    "    'support_intensity',\n",
    "    'engagement_score',\n",
    "    'is_detractor',\n",
    "    'is_new_customer'\n",
    "]\n",
    "\n",
    "X = df[all_features].fillna(0)\n",
    "y = df['churn_30d']\n",
    "\n",
    "print(f\"Features: {len(all_features)}\")\n",
    "print(f\"Samples: {len(X):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Model Training - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train/val/test split\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"Train: {len(X_train):,} | Val: {len(X_val):,} | Test: {len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Logistic Regression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model_lr = LogisticRegression(random_state=42, max_iter=1000, C=0.5)\n",
    "model_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "probs_lr_val = model_lr.predict_proba(X_val_scaled)[:, 1]\n",
    "auc_lr_val = roc_auc_score(y_val, probs_lr_val)\n",
    "print(f\"Logistic Regression Val AUC: {auc_lr_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: LightGBM with early stopping\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    num_leaves=31,\n",
    "    max_depth=6,\n",
    "    min_child_samples=20,\n",
    "    learning_rate=0.05,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "model_lgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    ")\n",
    "\n",
    "probs_lgb_val = model_lgb.predict_proba(X_val)[:, 1]\n",
    "auc_lgb_val = roc_auc_score(y_val, probs_lgb_val)\n",
    "print(f\"LightGBM Val AUC: {auc_lgb_val:.3f}\")\n",
    "print(f\"Trees used: {model_lgb.best_iteration_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Evaluation - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Test set evaluation\n",
    "\n",
    "probs_lr_test = model_lr.predict_proba(X_test_scaled)[:, 1]\n",
    "probs_lgb_test = model_lgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_lr_test = roc_auc_score(y_test, probs_lr_test)\n",
    "auc_lgb_test = roc_auc_score(y_test, probs_lgb_test)\n",
    "\n",
    "print(f\"Test AUC - Logistic Regression: {auc_lr_test:.3f}\")\n",
    "print(f\"Test AUC - LightGBM: {auc_lgb_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Precision@K\n",
    "\n",
    "def precision_at_k(y_true, y_proba, k):\n",
    "    top_k_idx = np.argsort(y_proba)[::-1][:k]\n",
    "    return y_true.iloc[top_k_idx].mean()\n",
    "\n",
    "K = 500\n",
    "k_test = int(K * len(y_test) / len(y))\n",
    "\n",
    "precision_random = y_test.mean()\n",
    "precision_lr = precision_at_k(y_test, probs_lr_test, k_test)\n",
    "precision_lgb = precision_at_k(y_test, probs_lgb_test, k_test)\n",
    "\n",
    "lift_lr = precision_lr / precision_random\n",
    "lift_lgb = precision_lgb / precision_random\n",
    "\n",
    "print(f\"\\nPrecision@{k_test}:\")\n",
    "print(f\"  Random: {precision_random:.1%}\")\n",
    "print(f\"  Logistic Regression: {precision_lr:.1%} (Lift: {lift_lr:.1f}x)\")\n",
    "print(f\"  LightGBM: {precision_lgb:.1%} (Lift: {lift_lgb:.1f}x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Business impact\n",
    "\n",
    "best_precision = max(precision_lr, precision_lgb)\n",
    "best_model = \"LightGBM\" if precision_lgb > precision_lr else \"Logistic Regression\"\n",
    "\n",
    "expected_churners_model = 500 * best_precision\n",
    "expected_saves_model = expected_churners_model * save_rate\n",
    "net_value_model = (expected_saves_model * value_per_save) - (500 * cost_per_call)\n",
    "value_improvement = net_value_model - net_value_random\n",
    "\n",
    "print(f\"\\n=== BUSINESS IMPACT ({best_model}) ===\")\n",
    "print(f\"Expected churners in top 500: {expected_churners_model:.0f} (vs {expected_churners_random:.0f} random)\")\n",
    "print(f\"Expected saves: {expected_saves_model:.0f} (vs {expected_saves_random:.0f} random)\")\n",
    "print(f\"Net value per week: ${net_value_model:,.0f}\")\n",
    "print(f\"\\nWeekly improvement: ${value_improvement:,.0f}\")\n",
    "print(f\"Annual improvement: ${value_improvement * 52:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Communication - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: PM Update\n",
    "\n",
    "pm_update_solution = f\"\"\"\n",
    "=== WEEKLY UPDATE: CHURN PREDICTION MODEL ===\n",
    "\n",
    "Hi Sarah,\n",
    "\n",
    "WHAT WE BUILT\n",
    "We built a machine learning model that predicts which customers are likely to cancel \n",
    "in the next 30 days. The model uses customer behavior data (logins, orders, support \n",
    "tickets) to identify at-risk customers before they churn.\n",
    "\n",
    "KEY RESULTS\n",
    "Using our model to select which 500 customers to call each week:\n",
    "- We expect to reach {expected_churners_model:.0f} actual churners vs {expected_churners_random:.0f} with random selection\n",
    "- That's {lift_lgb:.1f}x more churners than current random approach\n",
    "- Projected annual value: ${value_improvement * 52:,.0f} in additional retained customers\n",
    "\n",
    "RECOMMENDATION\n",
    "I recommend we deploy the LightGBM model. While slightly less interpretable than \n",
    "simpler alternatives, it delivers the best precision where it matters (top 500). \n",
    "The model correctly identifies customers with high support tickets and low engagement \n",
    "as highest risk.\n",
    "\n",
    "NEXT STEPS\n",
    "1. Pilot: Run model predictions alongside current process for 2 weeks to validate\n",
    "2. Integration: Connect model output to the retention team's call queue system\n",
    "3. Monitoring: Set up weekly dashboards tracking precision and save rate\n",
    "\n",
    "Happy to walk through the details whenever works for you.\n",
    "\n",
    "Best,\n",
    "[Your Name]\n",
    "\"\"\"\n",
    "\n",
    "print(pm_update_solution)\n",
    "print(f\"\\nWord count: {len(pm_update_solution.split())} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Grading Notes\n",
    "\n",
    "## Part 1 (20 points)\n",
    "- Full credit: All 7 lines completed with specific, correct answers\n",
    "- Partial credit: Missing time windows or vague success metrics\n",
    "\n",
    "## Part 2 (20 points)\n",
    "- Full credit: 3+ meaningful features, complete leakage audit, no future data\n",
    "- Deductions: Leaky features, features that don't make business sense\n",
    "\n",
    "## Part 3 (20 points)\n",
    "- Full credit: Two models trained, early stopping used, overfitting checked\n",
    "- Deductions: No validation set, no early stopping, large train/test gap\n",
    "\n",
    "## Part 4 (20 points)\n",
    "- Full credit: Precision@K reported, Lift calculated, $ impact computed\n",
    "- Deductions: Wrong metrics, no comparison to baseline\n",
    "\n",
    "## Part 5 (20 points)\n",
    "- Full credit: Clear update, business metrics, recommendation, next steps\n",
    "- Deductions: Too technical, no concrete numbers, missing recommendation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
