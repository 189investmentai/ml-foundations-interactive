{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Add-On: Impact Validation & Production Monitoring\n",
    "\n",
    "**Prerequisite:** Complete the main capstone project first.\n",
    "\n",
    "**Scenario:** You've built a churn prediction model with 3x+ lift. Leadership likes the results but asks:\n",
    "\n",
    "> \"How do we PROVE this actually reduces churn? And how do we keep it healthy after launch?\"\n",
    "\n",
    "This add-on covers:\n",
    "1. Designing an A/B test or holdout experiment\n",
    "2. Understanding why risk models can waste money (uplift vs. risk)\n",
    "3. Building a production monitoring plan\n",
    "\n",
    "**Runtime:** ~30-45 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup (same as main capstone)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your capstone results (or re-run if needed)\n",
    "# These are the key numbers from your main capstone:\n",
    "BASE_CHURN_RATE = 0.12  # Update with your actual value\n",
    "MODEL_PRECISION_AT_500 = 0.40  # Update with your actual value\n",
    "LIFT = 3.3  # Update with your actual value\n",
    "\n",
    "# Business parameters\n",
    "CAPACITY = 500  # Calls per week\n",
    "SAVE_RATE = 0.30  # 30% of churners can be saved by a call\n",
    "LTV_PER_SAVE = 200  # $200 value per saved customer\n",
    "COST_PER_CALL = 15  # $15 per call\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Your model: {MODEL_PRECISION_AT_500:.0%} precision @ 500 ({LIFT:.1f}x lift)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Experiment Design (Proving Business Impact)\n",
    "\n",
    "Your offline metrics (AUC, Precision@500) prove the model **ranks well**. But they don't prove:\n",
    "- That calling these customers actually saves them\n",
    "- That your targeting is better than other strategies\n",
    "- That the model will keep working over time\n",
    "\n",
    "To prove business impact, you need an **experiment**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Choosing an Experiment Design\n",
    "\n",
    "Three common approaches:\n",
    "\n",
    "| Design | How it works | Pros | Cons |\n",
    "|--------|--------------|------|------|\n",
    "| **A/B test** | Randomly assign customers to Model vs. Random targeting | Gold standard | Wastes calls on random group |\n",
    "| **Holdout** | Give most customers to model, hold back small control | More efficient | Less statistical power |\n",
    "| **Champion/Challenger** | Model vs. current production rule | Tests incremental improvement | Confounded if rule is correlated with model |\n",
    "\n",
    "For StreamCart, we'll design a **holdout experiment** since the retention team doesn't want to waste too many calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the experiment plan\n",
    "\n",
    "experiment_plan = \"\"\"\n",
    "=== EXPERIMENT PLAN: CHURN MODEL IMPACT TEST ===\n",
    "\n",
    "1. HYPOTHESIS\n",
    "   If we use the churn model to target retention calls (instead of random),\n",
    "   we will reduce churn by [X]% among the called population.\n",
    "   \n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "2. PRIMARY METRIC\n",
    "   What business outcome will you measure?\n",
    "   (Hint: churn rate, saves, revenue... be specific about time window)\n",
    "   \n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "3. POPULATION\n",
    "   Who is eligible for this experiment?\n",
    "   (Hint: tenure requirements? active subscribers only?)\n",
    "   \n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "4. RANDOMIZATION UNIT\n",
    "   What gets randomly assigned: customer, household, or something else?\n",
    "   \n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "5. TREATMENT VS CONTROL\n",
    "   - Treatment (____%): Model selects top [K] customers for calls\n",
    "   - Control (____%): Random selection OR no calls\n",
    "   \n",
    "   YOUR ANSWER: Treatment ___%, Control ___%\n",
    "   \n",
    "   Why did you choose this split?\n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "6. DURATION\n",
    "   How long will you run the experiment?\n",
    "   (Consider: how long until churn manifests? sample size needed?)\n",
    "   \n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "7. GUARDRAILS\n",
    "   What could go wrong? How will you check for contamination?\n",
    "   \n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "\"\"\"\n",
    "print(experiment_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Sample Size Considerations\n",
    "\n",
    "Quick rule of thumb for a two-group comparison:\n",
    "\n",
    "```\n",
    "n ≈ 16 × σ² / δ²\n",
    "\n",
    "where:\n",
    "- σ = standard deviation of the outcome\n",
    "- δ = minimum detectable effect (the difference you want to find)\n",
    "```\n",
    "\n",
    "For binary outcomes (churn/no churn), σ² ≈ p(1-p) where p is the base rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample size estimation\n",
    "\n",
    "# Baseline churn rate (your estimate)\n",
    "p_baseline = BASE_CHURN_RATE\n",
    "\n",
    "# Minimum detectable effect (MDE)\n",
    "# If model saves 30% of churners and reaches 3x more churners,\n",
    "# expected churn reduction among called customers is roughly:\n",
    "# (more churners reached) × (save rate) = potential improvement\n",
    "\n",
    "# TODO: Calculate your expected churn reduction\n",
    "# Hint: If random reaches 12% churners and model reaches 40%,\n",
    "#       and 30% of reached churners are saved...\n",
    "\n",
    "random_saves_per_100_calls = 100 * BASE_CHURN_RATE * SAVE_RATE\n",
    "model_saves_per_100_calls = 100 * MODEL_PRECISION_AT_500 * SAVE_RATE\n",
    "\n",
    "print(f\"Random: {random_saves_per_100_calls:.1f} saves per 100 calls\")\n",
    "print(f\"Model: {model_saves_per_100_calls:.1f} saves per 100 calls\")\n",
    "print(f\"Expected improvement: {model_saves_per_100_calls - random_saves_per_100_calls:.1f} extra saves per 100 calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough sample size calculation\n",
    "import math\n",
    "\n",
    "# Variance for binary outcome\n",
    "variance = p_baseline * (1 - p_baseline)\n",
    "\n",
    "# Effect size we want to detect (e.g., 3 percentage points)\n",
    "delta = 0.03  # TODO: Adjust based on your expected effect\n",
    "\n",
    "# Sample size per group (rough rule of thumb)\n",
    "n_per_group = 16 * variance / (delta ** 2)\n",
    "\n",
    "print(f\"To detect a {delta:.0%} difference with ~80% power:\")\n",
    "print(f\"Need approximately {n_per_group:,.0f} customers per group\")\n",
    "print(f\"\\nWith 500 calls/week:\")\n",
    "print(f\"  - 80/20 split: Treatment gets ~400/week, Control gets ~100/week\")\n",
    "print(f\"  - Weeks needed: ~{n_per_group / 100:.0f} weeks for Control to reach sample size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Self-Check: Experiment Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer these questions to validate your experiment design\n",
    "\n",
    "design_check = \"\"\"\n",
    "=== EXPERIMENT DESIGN CHECKLIST ===\n",
    "\n",
    "□ I have a clear, measurable hypothesis\n",
    "□ My primary metric is a business outcome (not a model metric)\n",
    "□ I've defined who is eligible and who is excluded\n",
    "□ I've specified how randomization will work\n",
    "□ My Treatment/Control split makes sense given constraints\n",
    "□ I've estimated how long the experiment needs to run\n",
    "□ I've identified potential threats (contamination, spillover, etc.)\n",
    "\n",
    "Common mistakes to avoid:\n",
    "- Using AUC or Precision as the experiment outcome (these are model metrics, not business metrics)\n",
    "- Running too short and getting noisy results\n",
    "- Peeking at results early and stopping when it \"looks good\"\n",
    "- Forgetting to check that Treatment and Control are balanced\n",
    "\"\"\"\n",
    "print(design_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Risk vs. Uplift (When Targeting Can Backfire)\n",
    "\n",
    "Your churn model predicts **who is likely to churn**. But the business cares about **who we can save**.\n",
    "\n",
    "These are not the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 The Four Quadrants\n",
    "\n",
    "```\n",
    "                    Would Churn Without Call?\n",
    "                         YES          NO\n",
    "                    ┌───────────┬───────────┐\n",
    "    Will Call       │ PERSUADE  │  WASTED   │\n",
    "    Save Them?      │  (value)  │  EFFORT   │\n",
    "         YES        │           │           │\n",
    "                    ├───────────┼───────────┤\n",
    "         NO         │   LOST    │ SLEEPING  │\n",
    "                    │  CAUSE    │   DOGS    │\n",
    "                    └───────────┴───────────┘\n",
    "```\n",
    "\n",
    "**Risk models find the left column** (likely to churn). But only the **top-left** creates value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Think through this scenario\n",
    "\n",
    "scenario = \"\"\"\n",
    "=== SCENARIO: TWO HIGH-RISK CUSTOMERS ===\n",
    "\n",
    "Both customers have 70% predicted churn probability. Your model ranks them equally.\n",
    "\n",
    "Customer A:\n",
    "- Frustrated about a billing issue\n",
    "- Recently contacted support twice\n",
    "- Has been a customer for 2 years\n",
    "\n",
    "Customer B:\n",
    "- Already signed up with a competitor\n",
    "- Hasn't logged in for 60 days\n",
    "- Posted on social media about leaving\n",
    "\n",
    "QUESTIONS:\n",
    "\n",
    "1. If you can only call ONE customer, which would you choose?\n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "2. Why might calling Customer B be a waste of money?\n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "3. What additional signals could help distinguish Persuadables from Lost Causes?\n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "\"\"\"\n",
    "print(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Break-Even Analysis\n",
    "\n",
    "Even without uplift modeling, you can calculate the **break-even probability** threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate break-even threshold\n",
    "\n",
    "# Expected value of calling a customer with churn probability P:\n",
    "# EV = P × SaveRate × LTV - CostPerCall\n",
    "#\n",
    "# Break-even when EV = 0:\n",
    "# P × SaveRate × LTV = CostPerCall\n",
    "# P = CostPerCall / (SaveRate × LTV)\n",
    "\n",
    "break_even_p = COST_PER_CALL / (SAVE_RATE * LTV_PER_SAVE)\n",
    "\n",
    "print(f\"=== BREAK-EVEN ANALYSIS ===\")\n",
    "print(f\"Cost per call: ${COST_PER_CALL}\")\n",
    "print(f\"Save rate: {SAVE_RATE:.0%}\")\n",
    "print(f\"Value per save: ${LTV_PER_SAVE}\")\n",
    "print(f\"\")\n",
    "print(f\"Break-even churn probability: {break_even_p:.1%}\")\n",
    "print(f\"\")\n",
    "print(f\"Interpretation: Only call customers with P(churn) > {break_even_p:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Answer this question\n",
    "\n",
    "critical_thinking = \"\"\"\n",
    "=== CRITICAL THINKING ===\n",
    "\n",
    "The break-even calculation assumes that the SAVE RATE is constant across all customers.\n",
    "\n",
    "But is this realistic?\n",
    "\n",
    "Consider:\n",
    "- Does a \"Lost Cause\" customer have the same 30% save rate as a \"Persuadable\"?\n",
    "- If not, how does this change your targeting strategy?\n",
    "\n",
    "YOUR ANSWER:\n",
    "_____________________________________________________________\n",
    "_____________________________________________________________\n",
    "_____________________________________________________________\n",
    "\n",
    "\"\"\"\n",
    "print(critical_thinking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Practical Fallback: Hybrid Scoring\n",
    "\n",
    "If you don't have data for true uplift modeling, layer **engagement signals** on top of risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Hybrid scoring approach\n",
    "# (This is a heuristic, not true uplift modeling)\n",
    "\n",
    "# Simulated data for illustration\n",
    "np.random.seed(42)\n",
    "n_customers = 1000\n",
    "\n",
    "df_example = pd.DataFrame({\n",
    "    'customer_id': range(n_customers),\n",
    "    'churn_prob': np.random.beta(2, 10, n_customers),  # Model output\n",
    "    'logins_last_30d': np.random.poisson(5, n_customers),  # Engagement proxy\n",
    "})\n",
    "\n",
    "# Pure risk ranking\n",
    "df_example['risk_rank'] = df_example['churn_prob'].rank(ascending=False)\n",
    "\n",
    "# Hybrid: risk × engagement (normalized)\n",
    "# Intuition: target customers who are at-risk AND still engaged (persuadable)\n",
    "df_example['engagement_score'] = np.clip(df_example['logins_last_30d'] / 10, 0.1, 1.0)\n",
    "df_example['hybrid_score'] = df_example['churn_prob'] * df_example['engagement_score']\n",
    "df_example['hybrid_rank'] = df_example['hybrid_score'].rank(ascending=False)\n",
    "\n",
    "# Compare top 50 by each method\n",
    "print(\"=== TOP 50 COMPARISON ===\")\n",
    "print(\"\\nPure Risk (top 5):\")\n",
    "top_risk = df_example.nsmallest(5, 'risk_rank')[['customer_id', 'churn_prob', 'logins_last_30d']]\n",
    "print(top_risk.to_string(index=False))\n",
    "\n",
    "print(\"\\nHybrid Score (top 5):\")\n",
    "top_hybrid = df_example.nsmallest(5, 'hybrid_rank')[['customer_id', 'churn_prob', 'logins_last_30d']]\n",
    "print(top_hybrid.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explain the difference\n",
    "\n",
    "hybrid_explanation = \"\"\"\n",
    "=== YOUR ANALYSIS ===\n",
    "\n",
    "Look at the two rankings above.\n",
    "\n",
    "1. What's different about the customers selected by Hybrid vs Pure Risk?\n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "2. Why might the Hybrid approach be better for intervention targeting?\n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "3. What's the main limitation of this heuristic?\n",
    "   (Hint: we're not measuring actual treatment effect)\n",
    "   YOUR ANSWER: _____________\n",
    "\n",
    "\"\"\"\n",
    "print(hybrid_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Production Monitoring Plan\n",
    "\n",
    "Deploying the model is not the end-it's the beginning. Models decay, data drifts, and business changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 What Can Go Wrong\n",
    "\n",
    "| Problem | Symptom | Example |\n",
    "|---------|---------|----------|\n",
    "| **Data drift** | Feature distributions shift | Login behavior changes after app redesign |\n",
    "| **Concept drift** | Same features, different outcomes | Competitor launches aggressive win-back campaign |\n",
    "| **Silent failure** | Model runs but outputs garbage | Upstream data pipeline broke |\n",
    "| **Feedback loop** | Model performance degrades | Saved customers change future training data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete your monitoring plan\n",
    "\n",
    "monitoring_plan = \"\"\"\n",
    "=== PRODUCTION MONITORING PLAN: CHURN MODEL ===\n",
    "\n",
    "Model: StreamCart Churn Prediction\n",
    "Owner: [Your Name]\n",
    "Last Trained: [Date]\n",
    "\n",
    "---\n",
    "\n",
    "DAILY CHECKS (automated alerts)\n",
    "\n",
    "□ Data freshness\n",
    "  - Check: Features updated within last 24 hours\n",
    "  - Alert if: Timestamp > 24h old\n",
    "  - YOUR ACTION IF ALERT: _____________\n",
    "\n",
    "□ Missing data\n",
    "  - Check: Null rates for key features\n",
    "  - Alert if: Null rate > [X]% (set your threshold)\n",
    "  - YOUR THRESHOLD: _____________\n",
    "\n",
    "□ Score distribution\n",
    "  - Check: Are predictions still spread out?\n",
    "  - Alert if: >80% of scores in single decile\n",
    "  - WHY THIS MATTERS: _____________\n",
    "\n",
    "---\n",
    "\n",
    "WEEKLY CHECKS (manual review)\n",
    "\n",
    "□ Feature distributions\n",
    "  - Compare this week's distributions to historical\n",
    "  - Flag if: Mean shifted >2 standard deviations\n",
    "  - TOP 3 FEATURES TO WATCH:\n",
    "    1. _____________\n",
    "    2. _____________\n",
    "    3. _____________\n",
    "\n",
    "□ Precision@500\n",
    "  - Calculate: Of top 500 scored customers, how many actually churned?\n",
    "  - Baseline: [Your model's test set precision]\n",
    "  - Alert if: Drops >15% from baseline\n",
    "  - YOUR BASELINE VALUE: _____________\n",
    "\n",
    "□ Lift vs random\n",
    "  - Compare: Model precision vs base churn rate\n",
    "  - Minimum acceptable lift: [Your threshold]\n",
    "  - YOUR MINIMUM LIFT: _____________\n",
    "\n",
    "---\n",
    "\n",
    "MONTHLY CHECKS\n",
    "\n",
    "□ Calibration\n",
    "  - Check: Do predicted probabilities match actual rates?\n",
    "  - Method: Calibration plot (predicted vs actual by decile)\n",
    "\n",
    "□ Feature importance stability\n",
    "  - Check: Are the same features driving predictions?\n",
    "  - Alert if: Top-5 features changed dramatically\n",
    "\n",
    "---\n",
    "\n",
    "RETRAIN TRIGGERS\n",
    "\n",
    "□ Scheduled: Every [X] months\n",
    "  YOUR SCHEDULE: _____________\n",
    "\n",
    "□ Triggered: When any of these occur:\n",
    "  - Precision@500 drops >___% from baseline\n",
    "  - Feature drift detected on >___ features\n",
    "  - Major product/business change\n",
    "  \n",
    "  YOUR THRESHOLDS: _____________\n",
    "\n",
    "---\n",
    "\n",
    "ESCALATION\n",
    "\n",
    "Alert channel: _____________\n",
    "Primary owner: _____________\n",
    "Backup owner: _____________\n",
    "\n",
    "\"\"\"\n",
    "print(monitoring_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Feedback Loop Awareness\n",
    "\n",
    "Your model changes behavior → behavior changes data → data changes the next model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Identify feedback loop risks\n",
    "\n",
    "feedback_analysis = \"\"\"\n",
    "=== FEEDBACK LOOP ANALYSIS ===\n",
    "\n",
    "The churn model targets high-risk customers for retention calls.\n",
    "Some of them stay because of the call.\n",
    "\n",
    "QUESTION 1: How does this affect your next training dataset?\n",
    "(Think: what label do \"saved\" customers get?)\n",
    "\n",
    "YOUR ANSWER: _____________________________________________________________\n",
    "_____________________________________________________________\n",
    "\n",
    "QUESTION 2: Could this make your next model worse? How?\n",
    "\n",
    "YOUR ANSWER: _____________________________________________________________\n",
    "_____________________________________________________________\n",
    "\n",
    "QUESTION 3: What's one way to mitigate this risk?\n",
    "(Hint: think about your experiment design from Part 1)\n",
    "\n",
    "YOUR ANSWER: _____________________________________________________________\n",
    "_____________________________________________________________\n",
    "\n",
    "\"\"\"\n",
    "print(feedback_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Final Deliverable - PM Update\n",
    "\n",
    "Write a 150-250 word update for leadership explaining:\n",
    "1. How you'll prove the model works (experiment plan)\n",
    "2. A key risk with pure risk-based targeting\n",
    "3. How you'll keep the model healthy (monitoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your PM update\n",
    "\n",
    "pm_update = \"\"\"\n",
    "=== PM UPDATE: MODEL VALIDATION & MONITORING PLAN ===\n",
    "\n",
    "Hi [Leadership Team],\n",
    "\n",
    "[PROVING IMPACT]\n",
    "TODO: Explain how you'll test whether the model actually reduces churn.\n",
    "Include: experiment design, key metric, timeline.\n",
    "\n",
    "\n",
    "\n",
    "[KEY RISK]\n",
    "TODO: Explain one risk with targeting based purely on churn risk.\n",
    "What could go wrong? How will you mitigate it?\n",
    "\n",
    "\n",
    "\n",
    "[KEEPING IT HEALTHY]\n",
    "TODO: Summarize your monitoring plan.\n",
    "What will you check? When will you retrain?\n",
    "\n",
    "\n",
    "\n",
    "[NEXT STEPS]\n",
    "TODO: List 2-3 concrete actions you'll take.\n",
    "\n",
    "\n",
    "\n",
    "Let me know if you have questions.\n",
    "\n",
    "[Your Name]\n",
    "\"\"\"\n",
    "\n",
    "print(pm_update)\n",
    "print(f\"\\nWord count: {len(pm_update.split())} words (target: 150-250)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Self-Assessment Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist = \"\"\"\n",
    "=== ADD-ON CHECKLIST ===\n",
    "\n",
    "Part 1: Experiment Design\n",
    "[ ] Completed experiment plan template\n",
    "[ ] Chose appropriate Treatment/Control split\n",
    "[ ] Estimated required duration\n",
    "[ ] Identified guardrails\n",
    "\n",
    "Part 2: Risk vs Uplift\n",
    "[ ] Explained the Four Quadrants\n",
    "[ ] Calculated break-even probability\n",
    "[ ] Understood why risk ≠ value\n",
    "[ ] Considered hybrid scoring approach\n",
    "\n",
    "Part 3: Monitoring Plan\n",
    "[ ] Defined daily/weekly/monthly checks\n",
    "[ ] Set specific thresholds\n",
    "[ ] Specified retrain triggers\n",
    "[ ] Identified feedback loop risks\n",
    "\n",
    "Part 4: PM Update\n",
    "[ ] Explained experiment plan clearly\n",
    "[ ] Communicated key risk\n",
    "[ ] Summarized monitoring approach\n",
    "[ ] Listed concrete next steps\n",
    "[ ] 150-250 words, no jargon\n",
    "\"\"\"\n",
    "print(checklist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed the impact validation add-on. You now understand:\n",
    "\n",
    "1. **How to prove business impact** with experiments, not just offline metrics\n",
    "2. **Why risk models can waste money** and when to consider uplift signals\n",
    "3. **How to keep a model healthy** with monitoring and retraining\n",
    "\n",
    "These skills separate \"ML project\" from \"ML in production.\" Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
