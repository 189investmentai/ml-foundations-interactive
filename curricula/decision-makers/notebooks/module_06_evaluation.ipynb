{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6: Evaluating What Actually Matters\n",
    "\n",
    "**Goal:** Choose the right metric for your business problem\n",
    "\n",
    "**Time:** ~20 minutes\n",
    "\n",
    "**What you'll do:**\n",
    "1. Understand precision vs recall tradeoff\n",
    "2. Pick thresholds based on business constraints\n",
    "3. Build a cost-sensitive evaluation\n",
    "4. Check if your probabilities are calibrated\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, \n",
    "    precision_recall_curve, roc_curve\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/data/streamcart_customers.csv')\n",
    "\n",
    "features = ['tenure_months', 'logins_last_7d', 'logins_last_30d',\n",
    "            'support_tickets_last_30d', 'items_skipped_last_3_boxes', 'nps_score']\n",
    "\n",
    "X = df[features].fillna(-1)\n",
    "y = df['churn_30d']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = lgb.LGBMClassifier(n_estimators=100, max_depth=5, random_state=42, verbose=-1)\n",
    "model.fit(X_train, y_train)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Test set: {len(y_test):,} customers\")\n",
    "print(f\"Churn rate: {y_test.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: The Precision-Recall Tradeoff\n",
    "\n",
    "You can't maximize both. Understanding WHY is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision and recall at different thresholds\n",
    "thresholds = [0.05, 0.10, 0.15, 0.20, 0.30, 0.50]\n",
    "\n",
    "print(\"=== Threshold Impact ===\")\n",
    "print(f\"{'Threshold':<12} {'Precision':<12} {'Recall':<12} {'Flagged %':<12}\")\n",
    "print(\"-\" * 48)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred = (y_proba >= thresh).astype(int)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    flagged = y_pred.mean()\n",
    "    print(f\"{thresh:<12.2f} {prec:<12.1%} {rec:<12.1%} {flagged:<12.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tradeoff\n",
    "precision, recall, thresh = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(recall, precision, 'b-', linewidth=2)\n",
    "plt.xlabel('Recall (% of churners found)')\n",
    "plt.ylabel('Precision (% correct among flagged)')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Mark key points\n",
    "plt.scatter([0.5], [precision[np.argmin(np.abs(recall - 0.5))]], \n",
    "            color='red', s=100, zorder=5, label='50% recall')\n",
    "plt.scatter([0.8], [precision[np.argmin(np.abs(recall - 0.8))]], \n",
    "            color='green', s=100, zorder=5, label='80% recall')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ Moving right (more recall) = precision drops\")\n",
    "print(\"   You can find more churners, but with more false positives.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insight\n",
    "\n",
    "The tradeoff exists because:\n",
    "- **High threshold**: Only flag very confident predictions â†’ miss some churners (low recall)\n",
    "- **Low threshold**: Flag more customers â†’ include non-churners (low precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Choosing a Threshold\n",
    "\n",
    "The right threshold depends on your BUSINESS constraint, not a magic number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 1: Limited capacity (500 calls/week)\n",
    "# We want: top 500 predictions\n",
    "\n",
    "capacity = 500\n",
    "\n",
    "# Find threshold that gives us ~500 predictions\n",
    "sorted_probs = np.sort(y_proba)[::-1]\n",
    "threshold_for_capacity = sorted_probs[min(capacity, len(sorted_probs)-1)]\n",
    "\n",
    "y_pred_cap = (y_proba >= threshold_for_capacity).astype(int)\n",
    "\n",
    "print(f\"=== Capacity-Based Threshold ===\")\n",
    "print(f\"Capacity: {capacity} calls/week\")\n",
    "print(f\"Threshold: {threshold_for_capacity:.3f}\")\n",
    "print(f\"Customers flagged: {y_pred_cap.sum()}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_cap):.1%}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_cap):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2: Must catch 80% of churners (high recall required)\n",
    "# Use case: Fraud detection, safety alerts\n",
    "\n",
    "target_recall = 0.80\n",
    "\n",
    "# Find threshold that achieves target recall\n",
    "for t in np.arange(0.01, 0.50, 0.01):\n",
    "    y_pred_t = (y_proba >= t).astype(int)\n",
    "    rec = recall_score(y_test, y_pred_t)\n",
    "    if rec >= target_recall:\n",
    "        threshold_for_recall = t\n",
    "        break\n",
    "\n",
    "y_pred_recall = (y_proba >= threshold_for_recall).astype(int)\n",
    "\n",
    "print(f\"=== Recall-Based Threshold ===\")\n",
    "print(f\"Target recall: {target_recall:.0%}\")\n",
    "print(f\"Threshold: {threshold_for_recall:.3f}\")\n",
    "print(f\"Customers flagged: {y_pred_recall.sum()} ({y_pred_recall.mean():.1%})\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_recall):.1%}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_recall):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Cost-Based Evaluation\n",
    "\n",
    "The real question: What's the BUSINESS VALUE of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define business costs\n",
    "COST_PER_CALL = 15          # Cost to call a customer\n",
    "VALUE_SAVED_CHURNER = 200   # Value of preventing a churn (via retention offer)\n",
    "RETENTION_SUCCESS_RATE = 0.3  # 30% of called churners are saved\n",
    "\n",
    "# TODO: Calculate expected value at different thresholds\n",
    "#\n",
    "# For each threshold:\n",
    "#   - How many customers flagged? (cost = flagged * COST_PER_CALL)\n",
    "#   - How many true positives? (value = TP * RETENTION_SUCCESS_RATE * VALUE_SAVED_CHURNER)\n",
    "#   - Net value = value - cost\n",
    "\n",
    "results = []\n",
    "for thresh in np.arange(0.05, 0.50, 0.02):\n",
    "    y_pred = (y_proba >= thresh).astype(int)\n",
    "    \n",
    "    flagged = y_pred.sum()\n",
    "    true_positives = ((y_pred == 1) & (y_test == 1)).sum()\n",
    "    \n",
    "    cost = flagged * COST_PER_CALL\n",
    "    value = true_positives * RETENTION_SUCCESS_RATE * VALUE_SAVED_CHURNER\n",
    "    net = value - cost\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': thresh,\n",
    "        'flagged': flagged,\n",
    "        'true_positives': true_positives,\n",
    "        'cost': cost,\n",
    "        'value': value,\n",
    "        'net_value': net\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "best_row = results_df.loc[results_df['net_value'].idxmax()]\n",
    "\n",
    "print(\"=== Cost-Based Optimization ===\")\n",
    "print(f\"\\nOptimal threshold: {best_row['threshold']:.2f}\")\n",
    "print(f\"Customers to call: {best_row['flagged']:.0f}\")\n",
    "print(f\"True churners caught: {best_row['true_positives']:.0f}\")\n",
    "print(f\"Expected saves: {best_row['true_positives'] * RETENTION_SUCCESS_RATE:.0f}\")\n",
    "print(f\"\\nCost: ${best_row['cost']:,.0f}\")\n",
    "print(f\"Value: ${best_row['value']:,.0f}\")\n",
    "print(f\"Net value: ${best_row['net_value']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize net value by threshold\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results_df['threshold'], results_df['net_value'], 'g-', linewidth=2)\n",
    "plt.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=best_row['threshold'], color='blue', linestyle='--', \n",
    "            label=f'Optimal ({best_row[\"threshold\"]:.2f})')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Net Value ($)')\n",
    "plt.title('Business Value by Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Calibration - Do Probabilities Mean What They Say?\n",
    "\n",
    "If the model says \"30% churn probability\", does ~30% of those customers actually churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check calibration\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_proba, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Perfectly calibrated')\n",
    "plt.plot(prob_pred, prob_true, 'bo-', label='Our model')\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives (actual churn rate)')\n",
    "plt.title('Calibration Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"  - Points above the line: model UNDERestimates risk\")\n",
    "print(\"  - Points below the line: model OVERestimates risk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantify calibration by bucket\n",
    "print(\"=== Calibration by Probability Bucket ===\")\n",
    "print(f\"{'Predicted Range':<20} {'Actual Rate':<15} {'Customers':<12}\")\n",
    "print(\"-\" * 47)\n",
    "\n",
    "for i in range(10):\n",
    "    lower = i * 0.1\n",
    "    upper = (i + 1) * 0.1\n",
    "    mask = (y_proba >= lower) & (y_proba < upper)\n",
    "    if mask.sum() > 0:\n",
    "        actual_rate = y_test[mask].mean()\n",
    "        expected_rate = (lower + upper) / 2\n",
    "        count = mask.sum()\n",
    "        print(f\"{lower:.1f} - {upper:.1f}          {actual_rate:>10.1%}     {count:>8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Which Metric for Which Situation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  SITUATION                     â”‚  PRIMARY METRIC         â”‚  WHY             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Limited capacity              â”‚  Precision@K            â”‚  Maximize ROI    â”‚\n",
    "â”‚  (500 calls, 100 reviews)      â”‚                         â”‚  per action      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Can't miss positives          â”‚  Recall + Precision     â”‚  Catch all       â”‚\n",
    "â”‚  (fraud, safety, disease)      â”‚  at target recall       â”‚  bad cases       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Costs are quantifiable        â”‚  Cost-weighted          â”‚  Maximize        â”‚\n",
    "â”‚  (known $ values)              â”‚  net value              â”‚  profit          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Comparing models              â”‚  AUC                    â”‚  Ranking         â”‚\n",
    "â”‚  (which is better overall)     â”‚                         â”‚  ability         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Probabilistic decisions       â”‚  Calibration +          â”‚  Trust the       â”‚\n",
    "â”‚  (expected value calcs)        â”‚  Brier score            â”‚  numbers         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\"\n",
    "print(guidance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Final Exercise: Explain It\n",
    "\n",
    "The finance team asks: \"What's the ROI of this model? How do we know it's worth investing in?\"\n",
    "\n",
    "Write a 4-5 sentence response using the cost analysis above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your response:\n",
    "\n",
    "finance_response = \"\"\"\n",
    "YOUR RESPONSE HERE\n",
    "\"\"\"\n",
    "\n",
    "print(finance_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Module 6 Complete!\n",
    "\n",
    "**What you learned:**\n",
    "- The precision-recall tradeoff and why it exists\n",
    "- How to choose thresholds based on business constraints\n",
    "- How to evaluate with business costs/values\n",
    "- What calibration means and why it matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=== Module 6 Summary ===\")\n",
    "print(f\"\\nModel AUC: {roc_auc_score(y_test, y_proba):.3f}\")\n",
    "print(f\"\\nBest threshold (cost-optimized): {best_row['threshold']:.2f}\")\n",
    "print(f\"Expected net value: ${best_row['net_value']:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next:** [Module 7: Finding Natural Groups â†’](./module_07_clustering.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
