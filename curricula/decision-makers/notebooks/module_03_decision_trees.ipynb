{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: When Linear Isn't Enough\n",
    "\n",
    "**Goal:** Understand decision trees and random forests, and when they beat logistic regression\n",
    "\n",
    "**Time:** ~20 minutes\n",
    "\n",
    "**What you'll do:**\n",
    "1. Train and visualize a decision tree\n",
    "2. Train a random forest\n",
    "3. Compare to logistic regression\n",
    "4. Interpret feature importance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/shared/data/streamcart_customers.csv')\n",
    "\n",
    "# Prepare features\n",
    "features = ['tenure_months', 'logins_last_7d', 'logins_last_30d',\n",
    "            'support_tickets_last_30d', 'items_skipped_last_3_boxes', 'nps_score']\n",
    "\n",
    "X = df[features].fillna(df[features].median())\n",
    "y = df['churn_30d']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training: {len(X_train):,} | Test: {len(X_test):,}\")\n",
    "print(f\"Churn rate: {y_train.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Train a Decision Tree\n",
    "\n",
    "Decision trees ask yes/no questions to split customers into groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a decision tree with max_depth=3\n",
    "#\n",
    "# Why max_depth=3? Deeper trees overfit. Start shallow.\n",
    "\n",
    "tree_model = None  # Replace with your code\n",
    "\n",
    "# Uncomment when ready:\n",
    "# tree_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "# tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK\n",
    "# ============================================\n",
    "\n",
    "assert tree_model is not None, \"Create the tree model first!\"\n",
    "assert hasattr(tree_model, 'tree_'), \"Model not trained‚Äîdid you call .fit()?\"\n",
    "print(f\"‚úì Tree trained with {tree_model.tree_.node_count} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Tree\n",
    "\n",
    "This is the beauty of decision trees‚Äîyou can actually see the logic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    tree_model,\n",
    "    feature_names=features,\n",
    "    class_names=['Stay', 'Churn'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "plt.title('Churn Decision Tree')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Look at the tree and answer:\n",
    "#\n",
    "# 1. What feature does the tree split on FIRST? ___________\n",
    "# 2. What's the threshold for that split? ___________\n",
    "# 3. Does this make business sense? ___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Train a Random Forest\n",
    "\n",
    "Random forests = 100+ trees voting together. More accurate but less interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a random forest with 100 trees, max_depth=5\n",
    "\n",
    "rf_model = None  # Replace with your code\n",
    "\n",
    "# Uncomment when ready:\n",
    "# rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "# rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK\n",
    "# ============================================\n",
    "\n",
    "assert rf_model is not None, \"Create the random forest first!\"\n",
    "assert len(rf_model.estimators_) == 100, \"Should have 100 trees\"\n",
    "print(f\"‚úì Random forest with {len(rf_model.estimators_)} trees trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Compare All Three Models\n",
    "\n",
    "Let's train logistic regression too and compare all approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression for comparison\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions from each model\n",
    "tree_probs = tree_model.predict_proba(X_test)[:, 1]\n",
    "rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
    "lr_probs = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate AUC for each\n",
    "tree_auc = roc_auc_score(y_test, tree_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "print(\"=== AUC Comparison ===\")\n",
    "print(f\"Logistic Regression: {lr_auc:.3f}\")\n",
    "print(f\"Single Decision Tree: {tree_auc:.3f}\")\n",
    "print(f\"Random Forest:        {rf_auc:.3f}\")\n",
    "print(f\"\\nBest: {'Random Forest' if rf_auc > lr_auc else 'Logistic Regression'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision@500 for each\n",
    "k = 500\n",
    "baseline = y_test.mean()\n",
    "\n",
    "def precision_at_k(y_true, y_proba, k):\n",
    "    top_k = np.argsort(y_proba)[-k:]\n",
    "    return y_true.iloc[top_k].mean()\n",
    "\n",
    "tree_prec = precision_at_k(y_test, tree_probs, k)\n",
    "rf_prec = precision_at_k(y_test, rf_probs, k)\n",
    "lr_prec = precision_at_k(y_test, lr_probs, k)\n",
    "\n",
    "print(f\"=== Precision@{k} ===\")\n",
    "print(f\"Random baseline:      {baseline:.1%}\")\n",
    "print(f\"Logistic Regression:  {lr_prec:.1%} (lift: {lr_prec/baseline:.1f}x)\")\n",
    "print(f\"Single Decision Tree: {tree_prec:.1%} (lift: {tree_prec/baseline:.1f}x)\")\n",
    "print(f\"Random Forest:        {rf_prec:.1%} (lift: {rf_prec/baseline:.1f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Question\n",
    "\n",
    "Did the random forest beat logistic regression? By how much?\n",
    "\n",
    "Often the improvement is small (0.01-0.03 AUC). Is that worth the loss of interpretability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Feature Importance\n",
    "\n",
    "Random forests tell us which features matter most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from random forest\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "print(\"=== Feature Importance (Random Forest) ===\")\n",
    "for _, row in importance_df.iterrows():\n",
    "    print(f\"{row['feature']:30} {row['importance']:.3f}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(importance_df['feature'], importance_df['importance'], color='steelblue')\n",
    "plt.xlabel('Importance (Gini)')\n",
    "plt.title('Which Features Matter Most?')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to Logistic Regression Coefficients\n",
    "\n",
    "Feature importance (trees) vs coefficients (logistic regression) measure different things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare rankings\n",
    "lr_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'lr_coef_abs': np.abs(lr_model.coef_[0]),\n",
    "    'rf_importance': rf_model.feature_importances_\n",
    "})\n",
    "\n",
    "lr_importance['lr_rank'] = lr_importance['lr_coef_abs'].rank(ascending=False)\n",
    "lr_importance['rf_rank'] = lr_importance['rf_importance'].rank(ascending=False)\n",
    "\n",
    "print(\"=== Feature Ranking Comparison ===\")\n",
    "print(lr_importance[['feature', 'lr_rank', 'rf_rank']].sort_values('rf_rank'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Why Trees Find Interactions\n",
    "\n",
    "Trees can find patterns like \"High tenure AND support tickets = very high risk\" automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at churn rates in different segments\n",
    "df_analysis = df.copy()\n",
    "df_analysis['tenure_bucket'] = pd.cut(df['tenure_months'], bins=[0, 6, 12, 100], labels=['New', 'Medium', 'Veteran'])\n",
    "df_analysis['has_tickets'] = (df['support_tickets_last_30d'] > 0).astype(int)\n",
    "\n",
    "# Cross-tabulation\n",
    "segment_churn = df_analysis.groupby(['tenure_bucket', 'has_tickets'])['churn_30d'].agg(['mean', 'count'])\n",
    "segment_churn.columns = ['churn_rate', 'count']\n",
    "segment_churn['churn_rate'] = segment_churn['churn_rate'].map('{:.1%}'.format)\n",
    "\n",
    "print(\"=== Churn by Segment ===\")\n",
    "print(segment_churn)\n",
    "print(\"\\nüí° Notice: Veterans WITH tickets might have different risk than the average.\")\n",
    "print(\"   Trees find these interactions automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Overfitting Demo\n",
    "\n",
    "What happens if we remove the depth limit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an unrestricted tree\n",
    "tree_overfit = DecisionTreeClassifier(random_state=42)  # No max_depth!\n",
    "tree_overfit.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_auc = roc_auc_score(y_train, tree_overfit.predict_proba(X_train)[:, 1])\n",
    "test_auc = roc_auc_score(y_test, tree_overfit.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\"=== Unrestricted Tree ===\")\n",
    "print(f\"Number of leaves: {tree_overfit.get_n_leaves()}\")\n",
    "print(f\"Train AUC: {train_auc:.3f}\")\n",
    "print(f\"Test AUC:  {test_auc:.3f}\")\n",
    "print(f\"\\n‚ö†Ô∏è  Gap of {train_auc - test_auc:.3f} = OVERFITTING!\")\n",
    "print(f\"   The tree memorized {tree_overfit.get_n_leaves()} tiny groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Final Exercise: Explain It\n",
    "\n",
    "The PM sees that random forest beats logistic regression and asks: \"Why did it predict this customer would churn?\"\n",
    "\n",
    "Write a 4-5 sentence response explaining the interpretability tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your response:\n",
    "\n",
    "pm_response = \"\"\"\n",
    "YOUR RESPONSE HERE\n",
    "\"\"\"\n",
    "\n",
    "print(pm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Module 3 Complete!\n",
    "\n",
    "**What you learned:**\n",
    "- How decision trees make splits\n",
    "- Why random forests are more robust\n",
    "- How to read feature importance\n",
    "- The overfitting danger with unrestricted trees\n",
    "\n",
    "**Key takeaway:** Trees find interactions automatically, but sacrifice interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=== Module 3 Summary ===\")\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  Logistic Regression: {lr_auc:.3f} AUC\")\n",
    "print(f\"  Decision Tree:       {tree_auc:.3f} AUC\")\n",
    "print(f\"  Random Forest:       {rf_auc:.3f} AUC\")\n",
    "print(f\"\\nTop Feature (RF): {features[np.argmax(rf_model.feature_importances_)]}\")\n",
    "print(f\"\\nOverfitting demo: Unrestricted tree had {train_auc - test_auc:.2f} train-test gap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next:** [Module 4: Combining Many Weak Learners ‚Üí](./module_04_boosting.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
