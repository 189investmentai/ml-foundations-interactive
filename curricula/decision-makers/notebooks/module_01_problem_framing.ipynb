{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 1: Is This Even an ML Problem?\n",
        "\n",
        "**Goal:** Learn to frame ML problems correctly and avoid the most common mistake (data leakage)\n",
        "\n",
        "**Time:** ~20 minutes\n",
        "\n",
        "**What you'll do:**\n",
        "1. Explore the StreamCart dataset\n",
        "2. Practice the 7-line framing template\n",
        "3. Identify data leakage in features\n",
        "4. Define a proper churn label\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Run this cell to load the data. No installation needed-just pandas and numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "DATA_URL = 'https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/shared/data/streamcart_customers.csv'\n",
        "\n",
        "def generate_streamcart_data(n=5000):\n",
        "    \"\"\"Generate synthetic StreamCart data if remote URL is unavailable.\"\"\"\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    signup_dates = [datetime(2023, 1, 1) + timedelta(days=np.random.randint(0, 500)) for _ in range(n)]\n",
        "    snapshot_date = datetime(2024, 6, 1)\n",
        "    tenure = [(snapshot_date - d).days // 30 for d in signup_dates]\n",
        "    \n",
        "    churn_prob = np.clip(0.1 + 0.3 * (np.array(tenure) < 3) + 0.2 * np.random.random(n), 0, 0.6)\n",
        "    churned = np.random.random(n) < churn_prob\n",
        "    \n",
        "    cancel_dates = [snapshot_date + timedelta(days=np.random.randint(1, 45)) if c else None for c in churned]\n",
        "    \n",
        "    df = pd.DataFrame({\n",
        "        'customer_id': range(1, n+1),\n",
        "        'signup_date': signup_dates,\n",
        "        'snapshot_date': [snapshot_date] * n,\n",
        "        'subscription_status': ['canceled' if c else 'active' for c in churned],\n",
        "        'churn_date': cancel_dates,\n",
        "        'cancel_reason': [np.random.choice(['too_expensive', 'not_using', 'competitor', 'other']) if c else None for c in churned],\n",
        "        'tenure_months': tenure,\n",
        "        'logins_last_7d': np.random.poisson(3, n),\n",
        "        'logins_last_30d': np.random.poisson(12, n),\n",
        "        'support_tickets_last_30d': np.random.poisson(0.5, n),\n",
        "        'items_skipped_last_3_boxes': np.random.poisson(1, n),\n",
        "        'nps_score': [np.random.choice([None] + list(range(1, 11)), p=[0.3] + [0.07]*10) for _ in range(n)],\n",
        "        'plan_type': np.random.choice(['basic', 'premium', 'family'], n),\n",
        "        'avg_order_value': np.random.exponential(45, n),\n",
        "    })\n",
        "    \n",
        "    # Create 30-day churn label\n",
        "    df['churn_30d'] = (\n",
        "        (df['subscription_status'] == 'canceled') & \n",
        "        (pd.to_datetime(df['churn_date']) <= snapshot_date + timedelta(days=30))\n",
        "    ).astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Try to load from remote, fall back to synthetic data\n",
        "try:\n",
        "    df = pd.read_csv(DATA_URL)\n",
        "    print(f\"Loaded {len(df):,} customers from remote\")\n",
        "except Exception as e:\n",
        "    print(f\"Remote data unavailable ({type(e).__name__}). Generating synthetic data...\")\n",
        "    df = generate_streamcart_data(5000)\n",
        "    print(f\"Generated {len(df):,} synthetic customers\")\n",
        "\n",
        "print(f\"Columns: {len(df.columns)}\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Explore the Data\n",
        "\n",
        "Before building any model, understand what you're working with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# What's in this dataset?\n",
        "print(\"=== Column Types ===\")\n",
        "print(df.dtypes)\n",
        "print(\"\\n=== Basic Stats ===\")\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# The target variable: churn_30d\n",
        "print(\"=== Churn Distribution ===\")\n",
        "print(df['churn_30d'].value_counts())\n",
        "print(f\"\\nChurn rate: {df['churn_30d'].mean():.1%}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick Check\n",
        "\n",
        "**Question:** About what percentage of customers churned in the next 30 days?\n",
        "\n",
        "This is your **baseline**. A model that predicts \"no churn\" for everyone would be right ~89% of the time. But that's useless for the business."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 2: The 7-Line Framing Template\n",
        "\n",
        "Before writing any model code, fill out this template. If you can't, you're not ready to build.\n",
        "\n",
        "| Line | Question | Your Answer |\n",
        "|------|----------|-------------|\n",
        "| 1. Problem | What business outcome are we trying to improve? | |\n",
        "| 2. Action | What will we DO with the prediction? | |\n",
        "| 3. Prediction | What exactly does the model output? | |\n",
        "| 4. Label | How do we define this in historical data? | |\n",
        "| 5. Features | What info is available at prediction time? | |\n",
        "| 6. Metric | How do we measure if the model helps? | |\n",
        "| 7. Constraints | What limits exist in production? | |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Fill out the framing for StreamCart's churn problem\n",
        "#\n",
        "# Context: StreamCart's retention team can call 500 customers per week.\n",
        "# They want to prioritize customers most likely to cancel.\n",
        "\n",
        "problem_framing = {\n",
        "    \"problem\": \"????\",      # What business metric are we improving?\n",
        "    \"action\": \"????\",       # What will the retention team DO?\n",
        "    \"prediction\": \"????\",   # What does the model output? (probability? score? yes/no?)\n",
        "    \"label\": \"????\",        # How is churn defined in the data?\n",
        "    \"features\": \"????\",     # List 3-5 features that would be available\n",
        "    \"metric\": \"????\",       # How do we know if the model is good? (hint: 500/week capacity)\n",
        "    \"constraints\": \"????\"   # Any production limits?\n",
        "}\n",
        "\n",
        "# Uncomment to see your answers:\n",
        "# for k, v in problem_framing.items():\n",
        "#     print(f\"{k}: {v}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# SELF-CHECK: Run this to validate your framing\n",
        "# ============================================\n",
        "\n",
        "def check_framing(framing):\n",
        "    errors = []\n",
        "    \n",
        "    # Check problem\n",
        "    if 'churn' not in framing['problem'].lower() and 'cancel' not in framing['problem'].lower() and 'retain' not in framing['problem'].lower():\n",
        "        errors.append(\"Problem should mention churn, cancellation, or retention\")\n",
        "    \n",
        "    # Check action\n",
        "    if framing['action'] == \"????\" or len(framing['action']) < 10:\n",
        "        errors.append(\"Action should describe what the team will DO with predictions\")\n",
        "    \n",
        "    # Check metric mentions capacity\n",
        "    if '500' not in framing['metric'] and 'precision' not in framing['metric'].lower() and 'top' not in framing['metric'].lower():\n",
        "        errors.append(\"Metric should account for the 500/week capacity (hint: precision@500)\")\n",
        "    \n",
        "    # Check features don't include leakage\n",
        "    leaky_terms = ['cancel_reason', 'churn_date', 'cancel_date']\n",
        "    for term in leaky_terms:\n",
        "        if term in framing['features'].lower():\n",
        "            errors.append(f\"'{term}' is leakage! It only exists AFTER someone churns.\")\n",
        "    \n",
        "    if errors:\n",
        "        print(\"‚ùå Issues found:\")\n",
        "        for e in errors:\n",
        "            print(f\"   - {e}\")\n",
        "    else:\n",
        "        print(\"‚úì Framing looks good!\")\n",
        "    \n",
        "    return len(errors) == 0\n",
        "\n",
        "check_framing(problem_framing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 3: Spotting Data Leakage\n",
        "\n",
        "This is the **#1 mistake** in applied ML. Leakage means using information that wouldn't be available at prediction time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Look at all columns\n",
        "print(\"=== All Columns ===\")\n",
        "for col in df.columns:\n",
        "    print(f\"  {col}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Which columns would cause DATA LEAKAGE if used as features?\n",
        "#\n",
        "# Remember: At prediction time (snapshot_date), we're predicting if they'll\n",
        "# churn in the NEXT 30 days. Any info that only exists AFTER they churn is leakage.\n",
        "\n",
        "leaky_columns = [\n",
        "    # \"???\",  # List columns that would leak\n",
        "    # \"???\",\n",
        "]\n",
        "\n",
        "safe_columns = [\n",
        "    # \"???\",  # List columns that are safe to use\n",
        "    # \"???\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# SELF-CHECK: Verify your leakage detection\n",
        "# ============================================\n",
        "\n",
        "KNOWN_LEAKY = {'churn_30d', 'churn_date', 'cancel_reason'}\n",
        "KNOWN_SAFE = {'tenure_months', 'logins_last_7d', 'logins_last_30d', \n",
        "              'support_tickets_last_30d', 'items_skipped_last_3_boxes',\n",
        "              'nps_score', 'plan_type', 'avg_order_value'}\n",
        "\n",
        "your_leaky = set(leaky_columns)\n",
        "your_safe = set(safe_columns)\n",
        "\n",
        "# Check leaky\n",
        "if KNOWN_LEAKY.issubset(your_leaky):\n",
        "    print(\"‚úì Correctly identified leaky columns!\")\n",
        "else:\n",
        "    missing = KNOWN_LEAKY - your_leaky\n",
        "    print(f\"‚ùå Missed leaky columns: {missing}\")\n",
        "    print(\"   Hint: These only exist AFTER someone churns\")\n",
        "\n",
        "# Check safe\n",
        "if len(your_safe) >= 5:\n",
        "    print(f\"‚úì Identified {len(your_safe)} safe features\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Only {len(your_safe)} safe features. Look for behavioral features.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 4: Why Leakage Is Dangerous\n",
        "\n",
        "Let's see what happens if you accidentally use a leaky feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Split data\n",
        "X = df[['tenure_months', 'logins_last_30d', 'support_tickets_last_30d']].fillna(0)\n",
        "y = df['churn_30d']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model (no leakage)\n",
        "model_clean = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)\n",
        "model_clean.fit(X_train, y_train)\n",
        "\n",
        "clean_auc = roc_auc_score(y_test, model_clean.predict_proba(X_test)[:, 1])\n",
        "print(f\"AUC without leakage: {clean_auc:.3f}\")\n",
        "print(\"This is realistic performance.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Now let's \"accidentally\" include a leaky feature\n",
        "# cancel_reason is encoded (it only exists for churners!)\n",
        "\n",
        "df['has_cancel_reason'] = df['cancel_reason'].notna().astype(int)\n",
        "\n",
        "X_leaky = df[['tenure_months', 'logins_last_30d', 'support_tickets_last_30d', 'has_cancel_reason']].fillna(0)\n",
        "\n",
        "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(X_leaky, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_leaky = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)\n",
        "model_leaky.fit(X_train_l, y_train_l)\n",
        "\n",
        "leaky_auc = roc_auc_score(y_test_l, model_leaky.predict_proba(X_test_l)[:, 1])\n",
        "print(f\"AUC with leakage: {leaky_auc:.3f}\")\n",
        "print(\"\\n‚ö†Ô∏è  This is suspiciously perfect! The model is 'cheating'.\")\n",
        "print(\"   In production, has_cancel_reason would always be 0 (they haven't canceled yet).\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === Business Metric: Precision@500 ===\n",
        "# The retention team can call 500 customers/week.\n",
        "# How many actual churners are in the model's top 500 predictions?\n",
        "\n",
        "def precision_at_k(y_true, y_scores, k=500):\n",
        "    \"\"\"Calculate precision at k: what fraction of top-k predictions are true positives.\"\"\"\n",
        "    top_k_idx = np.argsort(y_scores)[-k:][::-1]\n",
        "    return y_true.iloc[top_k_idx].mean()\n",
        "\n",
        "# Calculate for the clean model (no leakage)\n",
        "y_scores_clean = model_clean.predict_proba(X_test)[:, 1]\n",
        "p500_clean = precision_at_k(y_test, y_scores_clean, k=min(500, len(y_test)))\n",
        "baseline = y_test.mean()\n",
        "\n",
        "print(\"=== Business Metric: Precision@500 ===\")\n",
        "print(f\"Precision@500: {p500_clean:.1%}\")\n",
        "print(f\"Baseline (random selection): {baseline:.1%}\")\n",
        "print(f\"Lift: {p500_clean / baseline:.1f}x better than random\")\n",
        "print(f\"\\nIn 500 calls:\")\n",
        "print(f\"  - With model: ~{int(500 * p500_clean)} actual churners\")\n",
        "print(f\"  - Random: ~{int(500 * baseline)} actual churners\")\n",
        "print(f\"  - Extra saves: ~{int(500 * (p500_clean - baseline))} more churners reached\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Lesson\n",
        "\n",
        "If your AUC is above 0.95, **be suspicious**. Real-world churn models typically achieve 0.70-0.85.\n",
        "\n",
        "A model with leakage will:\n",
        "- Look amazing in development\n",
        "- Fail completely in production\n",
        "- Waste months of work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 5: Defining the Label Properly\n",
        "\n",
        "The label `churn_30d` is already defined. But let's understand what goes into defining it correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# What's in our label?\n",
        "print(\"snapshot_date:\", df['snapshot_date'].iloc[0])\n",
        "print(\"\\nFor churners:\")\n",
        "churners = df[df['churn_30d'] == 1][['customer_id', 'snapshot_date', 'churn_date']].head(5)\n",
        "print(churners)\n",
        "\n",
        "print(\"\\nFor non-churners:\")\n",
        "stayers = df[df['churn_30d'] == 0][['customer_id', 'snapshot_date', 'churn_date']].head(5)\n",
        "print(stayers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: If you had to define churn_30d from raw data, how would you do it?\n",
        "#\n",
        "# Complete this function:\n",
        "\n",
        "def define_churn_label(df, snapshot_date, window_days=30):\n",
        "    \"\"\"\n",
        "    Define churn label: Did the customer cancel within window_days after snapshot_date?\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame with 'churn_date' column (or None if still active)\n",
        "    snapshot_date : The point-in-time we're predicting FROM (string or datetime)\n",
        "    window_days : How many days to look forward\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    Series with 1 (churned) or 0 (stayed)\n",
        "    \"\"\"\n",
        "    # TODO: Implement this\n",
        "    # Hint: churn = 1 if churn_date is between snapshot_date and snapshot_date + window_days\n",
        "    # Hint: Use pd.to_datetime() to convert dates, timedelta for date math\n",
        "    \n",
        "    pass  # Replace with your implementation\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# SELF-CHECK: Test your function\n",
        "# ============================================\n",
        "\n",
        "# Run this after implementing define_churn_label above\n",
        "if 'define_churn_label' in dir() and callable(define_churn_label):\n",
        "    try:\n",
        "        # Get snapshot date from data (or use default)\n",
        "        if 'snapshot_date' in df.columns:\n",
        "            test_snapshot = pd.to_datetime(df['snapshot_date'].iloc[0])\n",
        "        else:\n",
        "            test_snapshot = pd.Timestamp('2024-06-01')\n",
        "        \n",
        "        my_labels = define_churn_label(df, test_snapshot, 30)\n",
        "        \n",
        "        if my_labels is None:\n",
        "            print(\"‚ö†Ô∏è  Your function returned None. Make sure to return a Series.\")\n",
        "        else:\n",
        "            match_rate = (my_labels == df['churn_30d']).mean()\n",
        "            print(f\"Your labels match ground truth: {match_rate:.1%}\")\n",
        "            \n",
        "            if match_rate > 0.95:\n",
        "                print(\"‚úì Excellent! Your label logic is correct.\")\n",
        "            elif match_rate > 0.80:\n",
        "                print(\"‚ö†Ô∏è  Close! Check your date comparison logic.\")\n",
        "                print(\"   Hint: Make sure you're comparing dates, not strings.\")\n",
        "            else:\n",
        "                print(\"‚ùå Labels don't match. Review the logic.\")\n",
        "                print(\"   Expected: churn = 1 if churn_date is between snapshot and snapshot + 30 days\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error testing function: {e}\")\n",
        "        print(\"   Make sure your function handles date conversions properly.\")\n",
        "else:\n",
        "    print(\"Implement define_churn_label above, then run this cell to test.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìù Final Exercise: Explain It\n",
        "\n",
        "Your VP asks: \"Why can't we just predict churn using their subscription status?\"\n",
        "\n",
        "Write a 3-4 sentence response explaining why that's circular reasoning.\n",
        "\n",
        "### Rubric (self-assess against this)\n",
        "\n",
        "A strong answer should:\n",
        "1. **Explain the circularity** - subscription_status IS the outcome, not a predictor\n",
        "2. **Clarify the timing problem** - you want to predict BEFORE they cancel, not after\n",
        "3. **Give a concrete example** - what prediction time looks like vs. using the outcome\n",
        "\n",
        "### Example Response (reveal AFTER writing yours)\n",
        "\n",
        "<details>\n",
        "<summary>Click to reveal example</summary>\n",
        "\n",
        "\"Subscription status tells us who already canceled-but we need to predict who WILL cancel before it happens, so we can intervene. Using status would be like predicting yesterday's weather using today's newspaper. Instead, we use behavioral signals (login frequency, support tickets, skipped items) measured BEFORE the cancellation decision, so our predictions are actionable.\"\n",
        "\n",
        "</details>\n",
        "\n",
        "See the full grading rubric in `rubrics/explain_it_rubric.md`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write your response here (as a comment or string):\n",
        "\n",
        "vp_response = \"\"\"\n",
        "YOUR RESPONSE HERE\n",
        "\"\"\"\n",
        "\n",
        "print(vp_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Module 1 Complete!\n",
        "\n",
        "**What you learned:**\n",
        "- The 7-line framing template\n",
        "- How to identify data leakage\n",
        "- Why leakage creates fake performance\n",
        "- How to define labels properly\n",
        "\n",
        "**Key takeaway:** The most important ML skill isn't coding-it's asking \"Would I have this data at prediction time?\"\n",
        "\n",
        "**Next:** [Module 2: Your First Prediction Model ‚Üí](./module_02_logistic_regression.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}