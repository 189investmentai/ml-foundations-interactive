{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Drill 08: Bad Similarity Search\n",
    "\n",
    "**Symptom:** Your colleague built a ticket similarity search. When support searches for \"refund request\", the top result is about \"shipping delay\". The search seems broken.\n",
    "\n",
    "**Your task:** Find the bug, fix the search, and write a postmortem.\n",
    "\n",
    "**Time:** 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tickets\n",
    "tickets = pd.read_csv('https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/data/streamcart_tickets.csv')\n",
    "print(f\"Loaded {len(tickets)} tickets\")\n",
    "print(tickets['ticket_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COLLEAGUE'S CODE (CONTAINS BUGS) =====\n",
    "\n",
    "# Bug 1: Using raw counts instead of TF-IDF\n",
    "vectorizer = CountVectorizer(max_features=100)  # Should use TfidfVectorizer\n",
    "ticket_vectors = vectorizer.fit_transform(tickets['ticket_text'])\n",
    "\n",
    "def search_tickets_buggy(query, top_k=5):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    \n",
    "    # Bug 2: Using Euclidean distance instead of cosine similarity\n",
    "    distances = euclidean_distances(query_vector, ticket_vectors)[0]\n",
    "    \n",
    "    # Bug 3: Taking largest distances (should be smallest, or use similarity)\n",
    "    top_indices = np.argsort(distances)[-top_k:][::-1]  # WRONG: gets largest\n",
    "    \n",
    "    return tickets.iloc[top_indices][['ticket_text', 'category']]\n",
    "\n",
    "# Test the buggy search\n",
    "print(\"Search: 'refund request'\")\n",
    "print(search_tickets_buggy(\"refund request\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Investigation\n",
    "\n",
    "**Q1:** Identify at least 2 bugs in the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: List the bugs you found\n",
    "# Bug 1: \n",
    "# Bug 2: \n",
    "# Bug 3: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** Why is TF-IDF better than raw counts for similarity search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your explanation\n",
    "# TF-IDF is better because..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the Bug\n",
    "\n",
    "**Q3:** Build a correct similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix all the bugs\n",
    "\n",
    "# Fix 1: Use TF-IDF\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=500,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "ticket_vectors_fixed = tfidf.fit_transform(tickets['ticket_text'])\n",
    "\n",
    "def search_tickets_fixed(query, top_k=5):\n",
    "    query_vector = tfidf.transform([query])\n",
    "    \n",
    "    # Fix 2: Use cosine similarity\n",
    "    similarities = cosine_similarity(query_vector, ticket_vectors_fixed)[0]\n",
    "    \n",
    "    # Fix 3: Get highest similarities\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    results = tickets.iloc[top_indices][['ticket_text', 'category']].copy()\n",
    "    results['similarity'] = similarities[top_indices]\n",
    "    return results\n",
    "\n",
    "# Test the fixed search\n",
    "print(\"Search: 'refund request'\")\n",
    "print(search_tickets_fixed(\"refund request\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test more queries\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Search: 'shipping delay'\")\n",
    "print(search_tickets_fixed(\"shipping delay\"))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Search: 'cancel subscription'\")\n",
    "print(search_tickets_fixed(\"cancel subscription\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify fix\n",
    "refund_results = search_tickets_fixed(\"refund request\", top_k=3)\n",
    "\n",
    "# At least one result should be about billing/refunds\n",
    "has_billing = any('billing' in str(cat).lower() or 'refund' in str(text).lower() \n",
    "                  for cat, text in zip(refund_results['category'], refund_results['ticket_text']))\n",
    "\n",
    "assert refund_results['similarity'].iloc[0] > 0.1, \"Top result should have decent similarity\"\n",
    "print(\"PASS: Search returns relevant results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postmortem\n",
    "\n",
    "Write 3 bullets:\n",
    "1. **Root cause:** \n",
    "2. **How we detected it:** \n",
    "3. **Prevention for next time:** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
