{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Drill 04: The Overfitting Trap\n",
    "\n",
    "**Symptom:** Your colleague's LightGBM model has 99% AUC on training data but only 58% on the holdout test set.\n",
    "\n",
    "**Your task:** Find the bug, fix it, and write a postmortem.\n",
    "\n",
    "**Time:** 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/shared/data/streamcart_customers.csv')\n",
    "\n",
    "features = ['tenure_months', 'logins_last_30d', 'orders_last_30d', \n",
    "            'support_tickets_last_30d', 'nps_score']\n",
    "X = df[features].fillna(0)\n",
    "y = df['churn_30d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COLLEAGUE'S CODE (CONTAINS BUG) =====\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train LightGBM with \"optimized\" parameters\n",
    "model = lgb.LGBMClassifier(\n",
    "    n_estimators=2000,      # Lots of trees!\n",
    "    num_leaves=256,         # Very deep trees!\n",
    "    max_depth=-1,           # No limit on depth!\n",
    "    min_child_samples=1,    # Can fit single examples!\n",
    "    learning_rate=0.3,      # Fast learning!\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check performance\n",
    "train_pred = model.predict_proba(X_train)[:, 1]\n",
    "test_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Training AUC: {roc_auc_score(y_train, train_pred):.4f}\")\n",
    "print(f\"Test AUC: {roc_auc_score(y_test, test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Investigation\n",
    "\n",
    "**Q1:** What's the gap between training and test AUC? What does this indicate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate and interpret the gap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** Which hyperparameters are causing overfitting? List at least 3 problematic settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Identify the problematic parameters\n",
    "# 1. \n",
    "# 2. \n",
    "# 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the Bug\n",
    "\n",
    "**Q3:** Retrain with proper regularization AND early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix the model - use reasonable hyperparameters and early stopping\n",
    "\n",
    "# Split into train/val/test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "model_fixed = lgb.LGBMClassifier(\n",
    "    # TODO: Set reasonable parameters\n",
    "    n_estimators=1000,       # Still many, but we'll use early stopping\n",
    "    num_leaves=31,           # TODO: What's a reasonable value?\n",
    "    max_depth=6,             # TODO: What's a reasonable value?\n",
    "    min_child_samples=20,    # TODO: What's a reasonable value?\n",
    "    learning_rate=0.05,      # TODO: What's a reasonable value?\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# TODO: Add early stopping\n",
    "model_fixed.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    ")\n",
    "\n",
    "# Check performance\n",
    "train_pred = model_fixed.predict_proba(X_train)[:, 1]\n",
    "val_pred = model_fixed.predict_proba(X_val)[:, 1]\n",
    "test_pred = model_fixed.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Training AUC: {roc_auc_score(y_train, train_pred):.4f}\")\n",
    "print(f\"Validation AUC: {roc_auc_score(y_val, val_pred):.4f}\")\n",
    "print(f\"Test AUC: {roc_auc_score(y_test, test_pred):.4f}\")\n",
    "print(f\"\\nTrees used: {model_fixed.best_iteration_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify fix worked\n",
    "gap = abs(roc_auc_score(y_train, train_pred) - roc_auc_score(y_test, test_pred))\n",
    "assert gap < 0.10, f\"Gap still too large: {gap:.4f}\"\n",
    "assert roc_auc_score(y_test, test_pred) > 0.65, \"Test AUC too low\"\n",
    "print(\"PASS: Overfitting controlled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postmortem\n",
    "\n",
    "Write 3 bullets:\n",
    "1. **Root cause:** \n",
    "2. **How we detected it:** \n",
    "3. **Prevention for next time:** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
