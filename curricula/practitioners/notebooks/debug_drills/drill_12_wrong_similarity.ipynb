{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Drill: The Wrong Distance\n",
    "\n",
    "**Scenario:**\n",
    "A colleague built a support ticket similarity system to find duplicate tickets.\n",
    "\n",
    "\"I'm using Euclidean distance like we learned in school!\" they say.\n",
    "\n",
    "But the results are terrible: completely unrelated tickets are matched.\n",
    "\n",
    "**Your Task:**\n",
    "1. Run the similarity search and see the bad results\n",
    "2. Diagnose why Euclidean distance fails for text\n",
    "3. Fix it with the right metric\n",
    "4. Write a 3-bullet postmortem\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample support tickets with clear topics\n",
    "tickets = [\n",
    "    # Password/Login issues (0-3)\n",
    "    \"I can't log in to my account\",\n",
    "    \"Password reset not working please help\",\n",
    "    \"Unable to access my account after password change\",\n",
    "    \"Login credentials not accepted\",\n",
    "    \n",
    "    # Shipping issues (4-7)\n",
    "    \"Where is my order it's been two weeks\",\n",
    "    \"Package tracking shows delivered but I never received it\",\n",
    "    \"Shipping is taking way too long\",\n",
    "    \"My delivery is late when will it arrive\",\n",
    "    \n",
    "    # Refund issues (8-11)\n",
    "    \"I want a refund for this product\",\n",
    "    \"How do I return this item and get my money back\",\n",
    "    \"Request for refund - product not as described\",\n",
    "    \"Cancel my order and refund please\",\n",
    "]\n",
    "\n",
    "# Expected groupings: 0-3 (password), 4-7 (shipping), 8-11 (refund)\n",
    "topics = ['password'] * 4 + ['shipping'] * 4 + ['refund'] * 4\n",
    "\n",
    "# Create TF-IDF embeddings\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "embeddings = vectorizer.fit_transform(tickets).toarray()\n",
    "\n",
    "print(f\"Tickets: {len(tickets)}\")\n",
    "print(f\"Embedding dimensions: {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COLLEAGUE'S CODE (BUG: WRONG METRIC) =====\n",
    "\n",
    "# Using Euclidean distance (wrong for sparse high-dim text!)\n",
    "nn_euclidean = NearestNeighbors(n_neighbors=3, metric='euclidean')  # <-- BUG!\n",
    "nn_euclidean.fit(embeddings)\n",
    "\n",
    "def search_euclidean(query):\n",
    "    \"\"\"Find similar tickets using Euclidean distance.\"\"\"\n",
    "    query_emb = vectorizer.transform([query]).toarray()\n",
    "    distances, indices = nn_euclidean.kneighbors(query_emb)\n",
    "    \n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(\"Top matches (Euclidean):\")\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        topic = topics[idx]\n",
    "        print(f\"  [{dist:.3f}] [{topic}] {tickets[idx]}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== Colleague's Results (Euclidean Distance) ===\")\n",
    "print()\n",
    "search_euclidean(\"password problem\")\n",
    "search_euclidean(\"shipping delay\")\n",
    "search_euclidean(\"want refund\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Your Investigation\n",
    "\n",
    "### Step 1: Why Euclidean fails for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Why Euclidean Distance Fails for Text ===\")\n",
    "print()\n",
    "print(\"Problem 1: Sparse vectors\")\n",
    "print(f\"  Average non-zero elements: {(embeddings > 0).sum(axis=1).mean():.1f} out of {embeddings.shape[1]}\")\n",
    "print(\"  Most dimensions are 0 â†’ Euclidean distance is dominated by zeros\")\n",
    "print()\n",
    "print(\"Problem 2: Vector length varies\")\n",
    "norms = np.linalg.norm(embeddings, axis=1)\n",
    "print(f\"  Vector norms range: {norms.min():.3f} to {norms.max():.3f}\")\n",
    "print(\"  Longer documents have larger vectors â†’ appear more different\")\n",
    "print()\n",
    "print(\"Problem 3: High dimensionality\")\n",
    "print(f\"  {embeddings.shape[1]} dimensions â†’ curse of dimensionality\")\n",
    "print(\"  All points become roughly equidistant in high dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distance distributions\n",
    "euc_distances = euclidean_distances(embeddings)\n",
    "cos_similarities = cosine_similarity(embeddings)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Euclidean distances\n",
    "ax1 = axes[0]\n",
    "im1 = ax1.imshow(euc_distances, cmap='RdYlGn_r', vmin=0)\n",
    "ax1.set_title('Euclidean Distances (lower = more similar)')\n",
    "ax1.set_xticks(range(12))\n",
    "ax1.set_yticks(range(12))\n",
    "plt.colorbar(im1, ax=ax1)\n",
    "\n",
    "# Cosine similarities\n",
    "ax2 = axes[1]\n",
    "im2 = ax2.imshow(cos_similarities, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "ax2.set_title('Cosine Similarities (higher = more similar)')\n",
    "ax2.set_xticks(range(12))\n",
    "ax2.set_yticks(range(12))\n",
    "plt.colorbar(im2, ax=ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¡ Cosine similarity shows clear 3x3 blocks (topics)!\")\n",
    "print(\"   Euclidean distances don't show this structure as clearly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: TODO - Fix with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use cosine similarity instead\n",
    "\n",
    "# Uncomment and complete:\n",
    "\n",
    "# nn_cosine = NearestNeighbors(n_neighbors=3, metric='cosine')  # Fixed!\n",
    "# nn_cosine.fit(embeddings)\n",
    "# \n",
    "# def search_cosine(query):\n",
    "#     \"\"\"Find similar tickets using cosine distance.\"\"\"\n",
    "#     query_emb = vectorizer.transform([query]).toarray()\n",
    "#     distances, indices = nn_cosine.kneighbors(query_emb)\n",
    "#     \n",
    "#     print(f\"Query: '{query}'\")\n",
    "#     print(\"Top matches (Cosine):\")\n",
    "#     for dist, idx in zip(distances[0], indices[0]):\n",
    "#         similarity = 1 - dist  # Convert distance to similarity\n",
    "#         topic = topics[idx]\n",
    "#         print(f\"  [{similarity:.3f}] [{topic}] {tickets[idx]}\")\n",
    "#     print()\n",
    "# \n",
    "# print(\"=== Fixed Results (Cosine Similarity) ===\")\n",
    "# print()\n",
    "# search_cosine(\"password problem\")\n",
    "# search_cosine(\"shipping delay\")\n",
    "# search_cosine(\"want refund\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare retrieval quality\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# def evaluate_retrieval(nn_model, metric_name):\n",
    "#     \"\"\"Check if nearest neighbors are from the same topic.\"\"\"\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     \n",
    "#     for i in range(len(tickets)):\n",
    "#         distances, indices = nn_model.kneighbors(embeddings[i:i+1])\n",
    "#         # Check neighbors (excluding self)\n",
    "#         for idx in indices[0][1:]:  # Skip first (self)\n",
    "#             total += 1\n",
    "#             if topics[idx] == topics[i]:\n",
    "#                 correct += 1\n",
    "#     \n",
    "#     accuracy = correct / total\n",
    "#     print(f\"{metric_name}: {accuracy:.1%} neighbors from same topic\")\n",
    "#     return accuracy\n",
    "# \n",
    "# print(\"=== Retrieval Quality ===\")\n",
    "# acc_euclidean = evaluate_retrieval(nn_euclidean, \"Euclidean\")\n",
    "# acc_cosine = evaluate_retrieval(nn_cosine, \"Cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK\n",
    "# ============================================\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# assert acc_cosine > acc_euclidean, \"Cosine should outperform Euclidean for text\"\n",
    "# assert acc_cosine > 0.7, \"Cosine should get most neighbors correct\"\n",
    "# \n",
    "# print(\"âœ“ Metric fixed!\")\n",
    "# print(f\"âœ“ Euclidean accuracy: {acc_euclidean:.1%}\")\n",
    "# print(f\"âœ“ Cosine accuracy: {acc_cosine:.1%}\")\n",
    "# print(f\"âœ“ Improvement: {acc_cosine - acc_euclidean:+.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write your postmortem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postmortem = \"\"\"\n",
    "## Postmortem: The Wrong Distance\n",
    "\n",
    "### What happened:\n",
    "- (Your answer: What was the observed problem with retrieval quality?)\n",
    "\n",
    "### Root cause:\n",
    "- (Your answer: Why does Euclidean distance fail for text embeddings?)\n",
    "\n",
    "### How to prevent:\n",
    "- (Your answer: What metric should we use for text similarity?)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(postmortem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Drill Complete!\n",
    "\n",
    "**Key lessons:**\n",
    "\n",
    "1. **Cosine similarity is the standard for text.** It measures the angle between vectors, ignoring magnitude.\n",
    "\n",
    "2. **Euclidean distance fails for sparse, high-dimensional data.** All points become roughly equidistant.\n",
    "\n",
    "3. **Vector length doesn't indicate semantic content.** A long document isn't necessarily more relevant.\n",
    "\n",
    "4. **Always visualize your similarity matrix** to verify the metric captures the structure you expect.\n",
    "\n",
    "---\n",
    "\n",
    "## Similarity Metric Guide\n",
    "\n",
    "| Data Type | Recommended Metric | Why |\n",
    "|-----------|-------------------|-----|\n",
    "| Text/NLP | **Cosine** | Sparse, high-dim, length-invariant |\n",
    "| Images (CNN) | Cosine | Normalized embeddings |\n",
    "| Dense embeddings | Cosine or Euclidean | Both work, test empirically |\n",
    "| Geographic | Euclidean or Haversine | Physical distance matters |\n",
    "| Binary features | Jaccard | Set intersection/union |\n",
    "| Mixed features | Gower | Handles different types |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
