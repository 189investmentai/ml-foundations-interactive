{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Drill: The Hallucinating RAG\n",
    "\n",
    "**Scenario:**\n",
    "You built a RAG system to answer questions about your company's policies.\n",
    "\n",
    "\"The bot told me we have a 90-day return policy!\" a customer complains.\n",
    "\n",
    "But your actual policy is 30 days. The LLM is hallucinating despite having context.\n",
    "\n",
    "**Your Task:**\n",
    "1. Identify why the RAG system is hallucinating\n",
    "2. Implement faithfulness checking\n",
    "3. Fix the prompt to reduce hallucinations\n",
    "4. Write a 3-bullet postmortem\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Knowledge base (ground truth)\n",
    "KNOWLEDGE_BASE = {\n",
    "    \"return_policy\": \"We accept returns within 30 days of purchase. Items must be unused and in original packaging.\",\n",
    "    \"shipping\": \"Standard shipping takes 5-7 business days. Express shipping delivers in 2-3 days for $9.99.\",\n",
    "    \"warranty\": \"All products come with a 1-year limited warranty covering manufacturing defects.\",\n",
    "    \"refunds\": \"Refunds are processed within 5-10 business days after we receive the returned item.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COLLEAGUE'S CODE (BUG: Weak prompt allows hallucination) =====\n",
    "\n",
    "def colleague_rag_prompt(query, context):\n",
    "    \"\"\"Weak prompt that allows hallucination.\"\"\"\n",
    "    # BUG: Prompt doesn't strongly constrain to context\n",
    "    return f\"\"\"Answer this question: {query}\n",
    "\n",
    "Here's some information that might help:\n",
    "{context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "def simulate_llm_response(prompt, hallucination_prone=True):\n",
    "    \"\"\"\n",
    "    Simulate LLM responses.\n",
    "    When hallucination_prone=True, the model may add incorrect information.\n",
    "    \"\"\"\n",
    "    # Extract context from prompt\n",
    "    context_match = re.search(r\"might help:\\n(.+?)\\n\\nAnswer\", prompt, re.DOTALL)\n",
    "    context = context_match.group(1) if context_match else \"\"\n",
    "    \n",
    "    # Simulated responses (some hallucinate, some don't)\n",
    "    if \"return\" in prompt.lower():\n",
    "        if hallucination_prone:\n",
    "            # HALLUCINATION: Says 90 days instead of 30!\n",
    "            return \"Our return policy allows returns within 90 days of purchase. Items should be in good condition.\"\n",
    "        else:\n",
    "            return \"Based on the policy, returns are accepted within 30 days. Items must be unused and in original packaging.\"\n",
    "    \n",
    "    if \"shipping\" in prompt.lower():\n",
    "        if hallucination_prone:\n",
    "            # HALLUCINATION: Free shipping not mentioned in context\n",
    "            return \"Shipping takes 5-7 days for standard, 2-3 days for express. Free shipping on orders over $50!\"\n",
    "        else:\n",
    "            return \"Standard shipping is 5-7 business days. Express shipping is 2-3 days for $9.99.\"\n",
    "    \n",
    "    return \"I don't have information about that.\"\n",
    "\n",
    "# Test the broken system\n",
    "query = \"What is your return policy?\"\n",
    "context = KNOWLEDGE_BASE[\"return_policy\"]\n",
    "prompt = colleague_rag_prompt(query, context)\n",
    "response = simulate_llm_response(prompt, hallucination_prone=True)\n",
    "\n",
    "print(\"=== Colleague's RAG System ===\")\n",
    "print(f\"\\nQuery: {query}\")\n",
    "print(f\"\\nContext (TRUTH): {context}\")\n",
    "print(f\"\\nResponse: {response}\")\n",
    "print(f\"\\n❌ HALLUCINATION: Response says '90 days' but context says '30 days'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Your Investigation\n",
    "\n",
    "### Step 1: Implement faithfulness checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_faithfulness(response, context):\n",
    "    \"\"\"\n",
    "    Check if response contains claims not supported by context.\n",
    "    Returns (is_faithful, issues_found)\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    # Extract numbers from both\n",
    "    response_numbers = set(re.findall(r'\\d+', response))\n",
    "    context_numbers = set(re.findall(r'\\d+', context))\n",
    "    \n",
    "    # Numbers in response not in context = potential hallucination\n",
    "    hallucinated_numbers = response_numbers - context_numbers\n",
    "    if hallucinated_numbers:\n",
    "        issues.append(f\"Numbers not in context: {hallucinated_numbers}\")\n",
    "    \n",
    "    # Check for common hallucination patterns\n",
    "    hallucination_phrases = [\n",
    "        (\"free shipping\", \"free_shipping\"),\n",
    "        (\"lifetime\", \"lifetime_warranty\"),\n",
    "        (\"unlimited\", \"unlimited_claim\"),\n",
    "    ]\n",
    "    \n",
    "    for phrase, key in hallucination_phrases:\n",
    "        if phrase in response.lower() and phrase not in context.lower():\n",
    "            issues.append(f\"Claim not in context: '{phrase}'\")\n",
    "    \n",
    "    is_faithful = len(issues) == 0\n",
    "    return is_faithful, issues\n",
    "\n",
    "# Test faithfulness checker\n",
    "is_faithful, issues = check_faithfulness(response, context)\n",
    "\n",
    "print(\"=== Faithfulness Check ===\")\n",
    "print(f\"Response: {response[:80]}...\")\n",
    "print(f\"\\nFaithful: {is_faithful}\")\n",
    "if issues:\n",
    "    print(\"Issues found:\")\n",
    "    for issue in issues:\n",
    "        print(f\"  ❌ {issue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: TODO - Fix the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a better prompt that reduces hallucination\n",
    "\n",
    "# Uncomment and complete:\n",
    "\n",
    "# def fixed_rag_prompt(query, context):\n",
    "#     \"\"\"Strong prompt that constrains to context.\"\"\"\n",
    "#     return f\"\"\"You are a helpful assistant. Answer the question using ONLY the information provided below.\n",
    "# \n",
    "# IMPORTANT RULES:\n",
    "# 1. ONLY use facts from the CONTEXT below\n",
    "# 2. Do NOT add information not in the context\n",
    "# 3. If the answer is not in the context, say \"I don't have that specific information\"\n",
    "# 4. Quote specific numbers and policies exactly as they appear\n",
    "# \n",
    "# CONTEXT:\n",
    "# {context}\n",
    "# \n",
    "# QUESTION: {query}\n",
    "# \n",
    "# ANSWER (using only the context above):\"\"\"\n",
    "# \n",
    "# # Test with fixed prompt\n",
    "# fixed_prompt = fixed_rag_prompt(query, context)\n",
    "# fixed_response = simulate_llm_response(fixed_prompt, hallucination_prone=False)\n",
    "# \n",
    "# print(\"=== Fixed RAG Prompt ===\")\n",
    "# print(fixed_prompt[:300] + \"...\")\n",
    "# print(f\"\\nResponse: {fixed_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Verify the fixed response is faithful\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# is_faithful_fixed, issues_fixed = check_faithfulness(fixed_response, context)\n",
    "# \n",
    "# print(\"=== Comparison ===\")\n",
    "# print(f\"\\nOriginal Response:\")\n",
    "# print(f\"  Faithful: {is_faithful}\")\n",
    "# print(f\"  Issues: {issues}\")\n",
    "# \n",
    "# print(f\"\\nFixed Response:\")\n",
    "# print(f\"  Faithful: {is_faithful_fixed}\")\n",
    "# print(f\"  Issues: {issues_fixed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test on multiple queries\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# test_cases = [\n",
    "#     (\"What is your return policy?\", \"return_policy\"),\n",
    "#     (\"How long does shipping take?\", \"shipping\"),\n",
    "#     (\"What warranty do you offer?\", \"warranty\"),\n",
    "# ]\n",
    "# \n",
    "# print(\"=== Full System Test ===\")\n",
    "# for query, context_key in test_cases:\n",
    "#     context = KNOWLEDGE_BASE[context_key]\n",
    "#     prompt = fixed_rag_prompt(query, context)\n",
    "#     response = simulate_llm_response(prompt, hallucination_prone=False)\n",
    "#     is_faithful, issues = check_faithfulness(response, context)\n",
    "#     \n",
    "#     status = \"✓\" if is_faithful else \"❌\"\n",
    "#     print(f\"\\n{status} Query: {query}\")\n",
    "#     print(f\"   Response: {response[:60]}...\")\n",
    "#     if issues:\n",
    "#         print(f\"   Issues: {issues}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK\n",
    "# ============================================\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# assert callable(fixed_rag_prompt), \"Should have created fixed_rag_prompt function\"\n",
    "# assert is_faithful_fixed, \"Fixed response should be faithful to context\"\n",
    "# assert \"30\" in fixed_response, \"Fixed response should mention 30 days (from context)\"\n",
    "# \n",
    "# print(\"✓ RAG hallucination fixed!\")\n",
    "# print(\"✓ Prompt now constrains to context\")\n",
    "# print(\"✓ Faithfulness checking implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write your postmortem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postmortem = \"\"\"\n",
    "## Postmortem: The Hallucinating RAG\n",
    "\n",
    "### What happened:\n",
    "- (Your answer: What incorrect information did the system provide?)\n",
    "\n",
    "### Root cause:\n",
    "- (Your answer: Why did the LLM hallucinate despite having correct context?)\n",
    "\n",
    "### How to prevent:\n",
    "- (Your answer: What prompt techniques and checks reduce hallucination?)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(postmortem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Drill Complete!\n",
    "\n",
    "**Key lessons:**\n",
    "\n",
    "1. **LLMs can hallucinate even with context.** The prompt must strongly constrain.\n",
    "\n",
    "2. **\"ONLY use the context\" is key.** Explicitly forbid outside knowledge.\n",
    "\n",
    "3. **Faithfulness checking catches hallucinations.** Check numbers, claims, and dates.\n",
    "\n",
    "4. **\"I don't know\" is a valid answer.** Better than making things up.\n",
    "\n",
    "---\n",
    "\n",
    "## Anti-Hallucination Techniques\n",
    "\n",
    "| Technique | How It Helps |\n",
    "|-----------|-------------|\n",
    "| \"ONLY use context\" | Constrains to provided info |\n",
    "| \"Say I don't know\" | Allows safe fallback |\n",
    "| Quote exact numbers | Reduces numeric drift |\n",
    "| Faithfulness check | Catches issues post-hoc |\n",
    "| Citation requirement | Forces grounding |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
