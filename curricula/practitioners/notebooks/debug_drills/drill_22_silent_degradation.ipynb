{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Drill: The Silent Degradation\n",
    "\n",
    "**Scenario:**\n",
    "Your churn model has been in production for 3 months. Business metrics are declining.\n",
    "\n",
    "\"Our retention offers aren't working anymore!\" the PM complains. \"Customers aren't responding.\"\n",
    "\n",
    "Nobody noticed the model was degrading because there were no alerts.\n",
    "\n",
    "**Your Task:**\n",
    "1. Identify where the model degraded\n",
    "2. Set up proper monitoring with alerts\n",
    "3. Create a retraining decision framework\n",
    "4. Write a 3-bullet postmortem\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples, drift_factor=0, concept_drift=0):\n",
    "    \"\"\"Generate data with optional drift.\"\"\"\n",
    "    tenure = np.random.exponential(20, n_samples)\n",
    "    spend = np.random.normal(100, 30, n_samples)\n",
    "    tickets = np.random.poisson(2, n_samples)\n",
    "    \n",
    "    # Apply data drift\n",
    "    if drift_factor > 0:\n",
    "        spend = spend * (1 + drift_factor * 0.5)\n",
    "        tenure = tenure * (1 + drift_factor * 0.3)\n",
    "    \n",
    "    # Base churn probability\n",
    "    churn_prob = 0.2 + 0.2 * (tickets > 3) - 0.1 * (spend > 100)\n",
    "    \n",
    "    # Apply concept drift (relationship changes!)\n",
    "    if concept_drift > 0:\n",
    "        # Now spend becomes MORE predictive, tickets less\n",
    "        churn_prob = 0.2 - 0.2 * (spend > 100) + 0.05 * (tickets > 3)\n",
    "    \n",
    "    churn_prob = np.clip(churn_prob, 0.05, 0.95)\n",
    "    churned = (np.random.random(n_samples) < churn_prob).astype(int)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'tenure': tenure,\n",
    "        'spend': spend,\n",
    "        'tickets': tickets,\n",
    "        'churned': churned\n",
    "    })\n",
    "\n",
    "# Generate training data (no drift)\n",
    "train_data = generate_data(2000)\n",
    "\n",
    "# Train model\n",
    "features = ['tenure', 'spend', 'tickets']\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['churned']\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "baseline_auc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
    "print(f\"Baseline AUC: {baseline_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COLLEAGUE'S CODE (BUG: No monitoring!) =====\n",
    "\n",
    "def broken_predict(model, data, features):\n",
    "    \"\"\"Production prediction without any monitoring.\"\"\"\n",
    "    X = data[features]\n",
    "    predictions = model.predict_proba(X)[:, 1]\n",
    "    return predictions  # Just returns predictions, no monitoring!\n",
    "\n",
    "# Simulate 12 weeks of production\n",
    "print(\"=== Production Over 12 Weeks (No Monitoring) ===\")\n",
    "weekly_data = []\n",
    "\n",
    "for week in range(12):\n",
    "    # Gradual drift increases over time\n",
    "    drift = min(week / 8, 1.0) * 0.6\n",
    "    concept_drift = max(0, (week - 4) / 8) * 0.8\n",
    "    \n",
    "    prod_data = generate_data(500, drift_factor=drift, concept_drift=concept_drift)\n",
    "    \n",
    "    # Make predictions (without monitoring)\n",
    "    preds = broken_predict(model, prod_data, features)\n",
    "    \n",
    "    # Calculate actual performance (we can see this in hindsight)\n",
    "    actual_auc = roc_auc_score(prod_data['churned'], preds)\n",
    "    \n",
    "    weekly_data.append({\n",
    "        'week': week + 1,\n",
    "        'auc': actual_auc,\n",
    "        'drift': drift,\n",
    "        'concept_drift': concept_drift\n",
    "    })\n",
    "    \n",
    "    # BUG: No alerts triggered, even when performance drops!\n",
    "    if week == 11:\n",
    "        print(f\"Week 12: AUC = {actual_auc:.3f} (down from {baseline_auc:.3f})\")\n",
    "        print(\"âŒ Nobody was alerted! Business metrics are already suffering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the degradation\n",
    "df_weekly = pd.DataFrame(weekly_data)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_weekly['week'], df_weekly['auc'], 'b-o', linewidth=2, markersize=8)\n",
    "plt.axhline(y=baseline_auc, color='g', linestyle='--', label='Baseline')\n",
    "plt.axhline(y=baseline_auc - 0.05, color='orange', linestyle='--', label='Warning')\n",
    "plt.axhline(y=baseline_auc - 0.10, color='r', linestyle='--', label='Critical')\n",
    "\n",
    "# Mark when alerts SHOULD have fired\n",
    "for _, row in df_weekly.iterrows():\n",
    "    if row['auc'] < baseline_auc - 0.10:\n",
    "        plt.scatter(row['week'], row['auc'], color='red', s=200, zorder=5)\n",
    "\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('Model Degradation (Undetected)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸš¨ Red dots show weeks where CRITICAL alerts should have fired!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Your Investigation\n",
    "\n",
    "### Step 1: Understand the failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Silent Degradation Analysis ===\")\n",
    "print()\n",
    "print(\"What happened:\")\n",
    "print(\"  Week 1-4: Model performing well (AUC ~0.70)\")\n",
    "print(\"  Week 5-8: Data drift starts, concept drift begins\")\n",
    "print(\"  Week 9-12: Significant degradation (AUC ~0.55)\")\n",
    "print()\n",
    "print(\"Why no one noticed:\")\n",
    "print(\"  - No monitoring in place\")\n",
    "print(\"  - No alerts configured\")\n",
    "print(\"  - No drift detection\")\n",
    "print()\n",
    "print(\"Business impact:\")\n",
    "print(\"  - Targeting wrong customers with retention offers\")\n",
    "print(\"  - Wasting marketing budget\")\n",
    "print(\"  - Missing actual churners\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: TODO - Implement monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create monitoring class\n",
    "\n",
    "# Uncomment and complete:\n",
    "\n",
    "# def calculate_psi(expected, actual, buckets=10):\n",
    "#     \"\"\"Calculate Population Stability Index.\"\"\"\n",
    "#     bins = np.percentile(expected, np.linspace(0, 100, buckets + 1))\n",
    "#     bins[0], bins[-1] = -np.inf, np.inf\n",
    "#     \n",
    "#     exp_counts = np.histogram(expected, bins)[0] / len(expected)\n",
    "#     act_counts = np.histogram(actual, bins)[0] / len(actual)\n",
    "#     \n",
    "#     exp_counts = np.clip(exp_counts, 0.0001, None)\n",
    "#     act_counts = np.clip(act_counts, 0.0001, None)\n",
    "#     \n",
    "#     return np.sum((act_counts - exp_counts) * np.log(act_counts / exp_counts))\n",
    "# \n",
    "# class ModelMonitor:\n",
    "#     def __init__(self, baseline_data, baseline_auc, thresholds):\n",
    "#         self.baseline_data = baseline_data\n",
    "#         self.baseline_auc = baseline_auc\n",
    "#         self.thresholds = thresholds\n",
    "#         self.alerts = []\n",
    "#     \n",
    "#     def check(self, current_data, predictions, actuals=None):\n",
    "#         \"\"\"Check for drift and performance degradation.\"\"\"\n",
    "#         alerts = []\n",
    "#         \n",
    "#         # Check data drift (PSI)\n",
    "#         for feature in ['tenure', 'spend', 'tickets']:\n",
    "#             psi = calculate_psi(\n",
    "#                 self.baseline_data[feature].values,\n",
    "#                 current_data[feature].values\n",
    "#             )\n",
    "#             if psi > self.thresholds['psi_critical']:\n",
    "#                 alerts.append(f\"ðŸš¨ CRITICAL: {feature} PSI={psi:.2f}\")\n",
    "#             elif psi > self.thresholds['psi_warning']:\n",
    "#                 alerts.append(f\"âš ï¸ WARNING: {feature} PSI={psi:.2f}\")\n",
    "#         \n",
    "#         # Check performance (if we have ground truth)\n",
    "#         if actuals is not None:\n",
    "#             current_auc = roc_auc_score(actuals, predictions)\n",
    "#             auc_drop = self.baseline_auc - current_auc\n",
    "#             \n",
    "#             if auc_drop > self.thresholds['auc_critical']:\n",
    "#                 alerts.append(f\"ðŸš¨ CRITICAL: AUC dropped {auc_drop:.2%}\")\n",
    "#             elif auc_drop > self.thresholds['auc_warning']:\n",
    "#                 alerts.append(f\"âš ï¸ WARNING: AUC dropped {auc_drop:.2%}\")\n",
    "#         \n",
    "#         self.alerts.extend(alerts)\n",
    "#         return alerts\n",
    "# \n",
    "# # Configure thresholds\n",
    "# thresholds = {\n",
    "#     'psi_warning': 0.1,\n",
    "#     'psi_critical': 0.25,\n",
    "#     'auc_warning': 0.03,\n",
    "#     'auc_critical': 0.05\n",
    "# }\n",
    "# \n",
    "# monitor = ModelMonitor(train_data, baseline_auc, thresholds)\n",
    "# print(\"âœ“ ModelMonitor created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Re-run with monitoring\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# print(\"=== Re-simulating with Monitoring ===\")\n",
    "# monitor.alerts = []  # Reset alerts\n",
    "# \n",
    "# for week in range(12):\n",
    "#     drift = min(week / 8, 1.0) * 0.6\n",
    "#     concept_drift = max(0, (week - 4) / 8) * 0.8\n",
    "#     \n",
    "#     prod_data = generate_data(500, drift_factor=drift, concept_drift=concept_drift)\n",
    "#     preds = model.predict_proba(prod_data[features])[:, 1]\n",
    "#     \n",
    "#     alerts = monitor.check(prod_data, preds, prod_data['churned'])\n",
    "#     \n",
    "#     if alerts:\n",
    "#         print(f\"\\nWeek {week + 1}:\")\n",
    "#         for alert in alerts:\n",
    "#             print(f\"  {alert}\")\n",
    "# \n",
    "# print(f\"\\nâœ“ Monitoring caught {len(monitor.alerts)} alerts!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK\n",
    "# ============================================\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# assert len(monitor.alerts) > 0, \"Monitor should have caught alerts\"\n",
    "# assert any('CRITICAL' in a for a in monitor.alerts), \"Should have critical alerts\"\n",
    "# \n",
    "# print(\"âœ“ Monitoring system working!\")\n",
    "# print(f\"âœ“ Total alerts: {len(monitor.alerts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write your postmortem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postmortem = \"\"\"\n",
    "## Postmortem: The Silent Degradation\n",
    "\n",
    "### What happened:\n",
    "- (Your answer: How long did degradation go unnoticed?)\n",
    "\n",
    "### Root cause:\n",
    "- (Your answer: Why were there no alerts?)\n",
    "\n",
    "### How to prevent:\n",
    "- (Your answer: What monitoring should be in place?)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(postmortem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Drill Complete!\n",
    "\n",
    "**Key lessons:**\n",
    "\n",
    "1. **Monitor early, alert often.** Don't wait for business metrics to drop.\n",
    "\n",
    "2. **Track both drift and performance.** PSI for features, AUC for accuracy.\n",
    "\n",
    "3. **Set tiered thresholds.** Warning â†’ investigate, Critical â†’ act.\n",
    "\n",
    "4. **Automate retraining decisions.** Define clear triggers.\n",
    "\n",
    "---\n",
    "\n",
    "## Monitoring Checklist\n",
    "\n",
    "| Metric | Warning | Critical |\n",
    "|--------|---------|----------|\n",
    "| PSI (data drift) | > 0.1 | > 0.25 |\n",
    "| AUC drop | > 3% | > 5% |\n",
    "| Prediction shift | > 1 std | > 2 std |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
