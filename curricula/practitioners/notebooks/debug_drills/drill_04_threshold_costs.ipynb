{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Drill: The Expensive Threshold\n",
    "\n",
    "**Scenario:**\n",
    "A colleague built a churn prediction model and deployed it with the default threshold of 0.5.\n",
    "\n",
    "\"It works great!\" they say. \"We're catching churners!\"\n",
    "\n",
    "But the CFO is unhappy: \"Our retention campaign costs are through the roof!\"\n",
    "\n",
    "**Your Task:**\n",
    "1. Run the current model and understand the cost structure\n",
    "2. Find why the threshold is suboptimal\n",
    "3. Fix it to minimize business cost\n",
    "4. Write a 3-bullet postmortem\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and train model\n",
    "DATA_URL = 'https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/shared/data/'\n",
    "\n",
    "customers = pd.read_csv(DATA_URL + 'streamcart_customers.csv')\n",
    "print(f\"Loaded {len(customers)} customers\")\n",
    "print(f\"Churn rate: {customers['churn_30d'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "if 'tenure_days' not in customers.columns:\n",
    "    customers['tenure_days'] = (pd.to_datetime('2024-01-01') - pd.to_datetime(customers['signup_date'])).dt.days\n",
    "if 'avg_order_value' not in customers.columns:\n",
    "    customers['avg_order_value'] = customers['total_spend'] / customers['orders_total'].replace(0, 1)\n",
    "\n",
    "feature_cols = ['tenure_days', 'orders_total', 'total_spend', 'support_tickets_total', 'avg_order_value']\n",
    "available_features = [c for c in feature_cols if c in customers.columns]\n",
    "\n",
    "X = customers[available_features].fillna(0)\n",
    "y = customers['churn_30d']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Train logistic regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get probabilities\n",
    "probabilities = model.predict_proba(X_test)[:, 1]\n",
    "print(f\"Model trained. Probability range: [{probabilities.min():.2f}, {probabilities.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COLLEAGUE'S CODE (CONTAINS BUG) =====\n",
    "\n",
    "# Business costs\n",
    "FP_COST = 50   # Cost of wasted retention offer (sent to non-churner)\n",
    "FN_COST = 200  # Cost of lost customer (missed churner)\n",
    "\n",
    "# Colleague uses DEFAULT threshold of 0.5\n",
    "THRESHOLD = 0.5  # <-- BUG: Not optimized for cost structure!\n",
    "\n",
    "predictions = (probabilities >= THRESHOLD).astype(int)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate total cost\n",
    "total_cost = fp * FP_COST + fn * FN_COST\n",
    "\n",
    "print(\"=== Colleague's Model (threshold = 0.5) ===\")\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  True Negatives:  {tn:4d} (correctly identified non-churners)\")\n",
    "print(f\"  False Positives: {fp:4d} (wasted offers @ ${FP_COST} = ${fp * FP_COST:,})\")\n",
    "print(f\"  False Negatives: {fn:4d} (missed churners @ ${FN_COST} = ${fn * FN_COST:,})\")\n",
    "print(f\"  True Positives:  {tp:4d} (caught churners)\")\n",
    "print(f\"\\nðŸ’° TOTAL COST: ${total_cost:,}\")\n",
    "print(f\"\\nMetrics:\")\n",
    "print(f\"  Precision: {precision_score(y_test, predictions):.1%}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, predictions):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Your Investigation\n",
    "\n",
    "The CFO asks: \"Can we reduce costs?\"\n",
    "\n",
    "### Step 1: Understand the cost structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think about the costs:\n",
    "print(\"Cost Structure Analysis:\")\n",
    "print(f\"  FP cost: ${FP_COST} (sending offer to non-churner)\")\n",
    "print(f\"  FN cost: ${FN_COST} (missing a churner)\")\n",
    "print(f\"\\n  FN is {FN_COST / FP_COST}x more expensive than FP!\")\n",
    "\n",
    "print(\"\\nðŸ¤” Question: If missing a churner costs 4x more than a wasted offer...\")\n",
    "print(\"   Should we be MORE aggressive (lower threshold) or LESS aggressive (higher)?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The theoretical optimal threshold formula\n",
    "# For cost-sensitive classification:\n",
    "#   optimal_threshold â‰ˆ FP_cost / (FP_cost + FN_cost)\n",
    "\n",
    "theoretical_optimal = FP_COST / (FP_COST + FN_COST)\n",
    "print(f\"Theoretical optimal threshold: {theoretical_optimal:.2f}\")\n",
    "print(f\"Colleague's threshold: 0.50\")\n",
    "print(f\"\\nâŒ The default 0.5 threshold is WAY too high!\")\n",
    "print(f\"   We should use ~{theoretical_optimal:.2f} to catch more churners.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Find the actual optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test different thresholds and find the cost-minimizing one\n",
    "\n",
    "def calculate_cost(y_true, y_pred, fp_cost, fn_cost):\n",
    "    \"\"\"Calculate total business cost from predictions.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    return fp * fp_cost + fn * fn_cost\n",
    "\n",
    "# Uncomment and complete:\n",
    "\n",
    "# thresholds = np.arange(0.05, 0.95, 0.05)\n",
    "# results = []\n",
    "# \n",
    "# for thresh in thresholds:\n",
    "#     preds = (probabilities >= thresh).astype(int)\n",
    "#     \n",
    "#     cm = confusion_matrix(y_test, preds)\n",
    "#     tn, fp, fn, tp = cm.ravel()\n",
    "#     \n",
    "#     cost = calculate_cost(y_test, preds, FP_COST, FN_COST)\n",
    "#     prec = precision_score(y_test, preds, zero_division=0)\n",
    "#     rec = recall_score(y_test, preds)\n",
    "#     \n",
    "#     results.append({\n",
    "#         'threshold': thresh,\n",
    "#         'fp': fp,\n",
    "#         'fn': fn,\n",
    "#         'cost': cost,\n",
    "#         'precision': prec,\n",
    "#         'recall': rec\n",
    "#     })\n",
    "# \n",
    "# results_df = pd.DataFrame(results)\n",
    "# print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find and report the optimal threshold\n",
    "\n",
    "# Uncomment after completing above:\n",
    "\n",
    "# optimal_idx = results_df['cost'].idxmin()\n",
    "# optimal_row = results_df.loc[optimal_idx]\n",
    "# \n",
    "# print(f\"\\n=== OPTIMAL THRESHOLD: {optimal_row['threshold']:.2f} ===\")\n",
    "# print(f\"  Cost: ${optimal_row['cost']:,.0f}\")\n",
    "# print(f\"  False Positives: {optimal_row['fp']:.0f} (@ ${FP_COST} = ${optimal_row['fp'] * FP_COST:,.0f})\")\n",
    "# print(f\"  False Negatives: {optimal_row['fn']:.0f} (@ ${FN_COST} = ${optimal_row['fn'] * FN_COST:,.0f})\")\n",
    "# print(f\"  Precision: {optimal_row['precision']:.1%}\")\n",
    "# print(f\"  Recall: {optimal_row['recall']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate savings\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# original_cost = total_cost  # From colleague's code\n",
    "# optimal_cost = optimal_row['cost']\n",
    "# savings = original_cost - optimal_cost\n",
    "# \n",
    "# print(f\"\\n=== SAVINGS ===\")\n",
    "# print(f\"  Original (threshold=0.5): ${original_cost:,.0f}\")\n",
    "# print(f\"  Optimal (threshold={optimal_row['threshold']:.2f}): ${optimal_cost:,.0f}\")\n",
    "# print(f\"  SAVINGS: ${savings:,.0f} ({savings/original_cost*100:.0f}% reduction!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK: Did you find a better threshold?\n",
    "# ============================================\n",
    "\n",
    "# Uncomment after completing:\n",
    "\n",
    "# assert optimal_row['threshold'] < 0.5, \"Optimal threshold should be BELOW 0.5 (FN costs more than FP)\"\n",
    "# assert optimal_cost < original_cost, \"Optimal cost should be lower than original\"\n",
    "# assert optimal_row['recall'] > recall_score(y_test, predictions), \"Lower threshold should increase recall\"\n",
    "# \n",
    "# print(\"âœ“ Threshold optimization correct!\")\n",
    "# print(f\"âœ“ Moved from 0.5 to {optimal_row['threshold']:.2f}\")\n",
    "# print(f\"âœ“ Saved ${savings:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Visualize the cost curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize threshold vs cost\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# \n",
    "# # Cost curve\n",
    "# ax1 = axes[0]\n",
    "# ax1.plot(results_df['threshold'], results_df['cost'], 'purple', linewidth=2)\n",
    "# ax1.axvline(x=0.5, color='red', linestyle='--', label='Original (0.5)', alpha=0.7)\n",
    "# ax1.axvline(x=optimal_row['threshold'], color='green', linestyle='--', \n",
    "#             label=f'Optimal ({optimal_row[\"threshold\"]:.2f})', alpha=0.7)\n",
    "# ax1.scatter([0.5], [original_cost], color='red', s=100, zorder=5)\n",
    "# ax1.scatter([optimal_row['threshold']], [optimal_cost], color='green', s=100, zorder=5)\n",
    "# ax1.set_xlabel('Threshold')\n",
    "# ax1.set_ylabel('Total Cost ($)')\n",
    "# ax1.set_title('Business Cost by Threshold')\n",
    "# ax1.legend()\n",
    "# ax1.grid(True, alpha=0.3)\n",
    "# \n",
    "# # Precision/Recall tradeoff\n",
    "# ax2 = axes[1]\n",
    "# ax2.plot(results_df['threshold'], results_df['precision'], 'b-', label='Precision', linewidth=2)\n",
    "# ax2.plot(results_df['threshold'], results_df['recall'], 'r-', label='Recall', linewidth=2)\n",
    "# ax2.axvline(x=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "# ax2.axvline(x=optimal_row['threshold'], color='green', linestyle='--', alpha=0.7)\n",
    "# ax2.set_xlabel('Threshold')\n",
    "# ax2.set_ylabel('Score')\n",
    "# ax2.set_title('Precision-Recall Tradeoff')\n",
    "# ax2.legend()\n",
    "# ax2.grid(True, alpha=0.3)\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Write your postmortem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postmortem = \"\"\"\n",
    "## Postmortem: The Expensive Threshold\n",
    "\n",
    "### What happened:\n",
    "- (Your answer: What was the symptom? What did the CFO observe?)\n",
    "\n",
    "### Root cause:\n",
    "- (Your answer: What was wrong with the threshold? Why?)\n",
    "\n",
    "### How to prevent:\n",
    "- (Your answer: What should we do before deploying classification models?)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(postmortem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Drill Complete!\n",
    "\n",
    "**Key lessons:**\n",
    "\n",
    "1. **The default threshold (0.5) is rarely optimal.** It assumes equal costs for FP and FN, which is almost never true in business.\n",
    "\n",
    "2. **When FN >> FP cost, lower the threshold.** You want to catch more positives even at the cost of more false alarms.\n",
    "\n",
    "3. **When FP >> FN cost, raise the threshold.** You want to be more certain before flagging positives.\n",
    "\n",
    "4. **The formula: optimal_threshold â‰ˆ FP_cost / (FP_cost + FN_cost)**\n",
    "\n",
    "---\n",
    "\n",
    "## Cost-Optimal Threshold Cheatsheet\n",
    "\n",
    "| FP Cost | FN Cost | Optimal Threshold | Example |\n",
    "|---------|---------|-------------------|----------|\n",
    "| $50 | $200 | ~0.20 | Churn (losing customer is expensive) |\n",
    "| $100 | $100 | ~0.50 | Balanced costs |\n",
    "| $500 | $50 | ~0.91 | Spam filter (false positive is annoying) |\n",
    "| $10 | $10000 | ~0.001 | Fraud detection (missing fraud is catastrophic) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
