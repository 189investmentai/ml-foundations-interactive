{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Debug Drill: The Leaky Features\n",
        "\n",
        "**Scenario:**\n",
        "Your team built a churn prediction model. A colleague is proud of the feature engineering.\n",
        "\n",
        "\"I created some amazing features!\" they say. \"The model gets 0.96 AUC!\"\n",
        "\n",
        "You're suspicious. Typical churn models get 0.70-0.85 AUC.\n",
        "\n",
        "**Your Task:**\n",
        "1. Run the pipeline\n",
        "2. Find the leaky features (there are TWO bugs)\n",
        "3. Fix them\n",
        "4. Write a 3-bullet postmortem\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load data\n",
        "DATA_URL = 'https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/shared/data/'\n",
        "\n",
        "df = pd.read_csv(DATA_URL + 'streamcart_customers.csv')\n",
        "print(f\"Loaded {len(df):,} customers\")\n",
        "print(f\"Churn rate: {df['churn_30d'].mean():.1%}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ===== COLLEAGUE'S FEATURE ENGINEERING (CONTAINS BUGS) =====\n",
        "\n",
        "def create_features(data):\n",
        "    \"\"\"Engineer features for churn prediction.\"\"\"\n",
        "    df_feat = data.copy()\n",
        "    \n",
        "    # Basic features (these are fine)\n",
        "    df_feat['tenure_months'] = df_feat['tenure_months']\n",
        "    df_feat['orders_total'] = df_feat['orders_total']\n",
        "    df_feat['logins_last_30d'] = df_feat['logins_last_30d']\n",
        "    \n",
        "    # Derived features (some are fine, some are buggy)\n",
        "    df_feat['orders_per_month'] = df_feat['orders_total'] / (df_feat['tenure_months'] + 1)\n",
        "    df_feat['login_frequency'] = df_feat['logins_last_30d'] / 30\n",
        "    \n",
        "    # \"Sophisticated\" features (colleague is proud of these)\n",
        "    # BUG 1: This feature is derived from the target!\n",
        "    df_feat['churn_risk_score'] = (\n",
        "        df_feat['days_since_last_order'] / 30 +\n",
        "        (1 - df_feat['churn_30d']) * 0.5  # <-- Uses the target directly!\n",
        "    )\n",
        "    \n",
        "    # BUG 2: This feature uses future information!\n",
        "    # \"Lifetime value\" includes ALL purchases, even ones AFTER the prediction date\n",
        "    df_feat['customer_value'] = df_feat['total_spend']  # <-- Includes future spend\n",
        "    \n",
        "    # More features (these are fine)\n",
        "    df_feat['support_tickets'] = df_feat['support_tickets_total']\n",
        "    df_feat['avg_order_value'] = df_feat['avg_order_value']\n",
        "    \n",
        "    return df_feat\n",
        "\n",
        "df_features = create_features(df)\n",
        "print(\"Features created!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define feature columns\n",
        "feature_cols = [\n",
        "    'tenure_months',\n",
        "    'orders_total', \n",
        "    'logins_last_30d',\n",
        "    'orders_per_month',\n",
        "    'login_frequency',\n",
        "    'churn_risk_score',   # <-- BUG 1\n",
        "    'customer_value',     # <-- BUG 2\n",
        "    'support_tickets',\n",
        "    'avg_order_value'\n",
        "]\n",
        "\n",
        "X = df_features[feature_cols].fillna(0)\n",
        "y = df_features['churn_30d']\n",
        "\n",
        "# Time-based split (at least they got this right)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(X_train):,}, Test: {len(X_test):,}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train model\n",
        "model = GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"Test AUC: {auc:.3f}\")\n",
        "print(f\"\\nüéâ Colleague: 'See? 0.96 AUC! This is our best model ever!'\")\n",
        "print(f\"\\nü§î You: 'That seems... too good. Let me check the features.'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Your Investigation\n",
        "\n",
        "0.96 AUC for churn is suspiciously high. Find the leaky features.\n",
        "\n",
        "### Step 1: Check feature correlations with target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Check correlations between features and target\n",
        "# Suspicious: any feature with correlation > 0.5 with the target\n",
        "\n",
        "print(\"=== Feature Correlations with Target (churn_30d) ===\")\n",
        "correlations = df_features[feature_cols + ['churn_30d']].corr()['churn_30d'].drop('churn_30d')\n",
        "print(correlations.sort_values(key=abs, ascending=False).round(3))\n",
        "\n",
        "print(\"\\nüîç Which features have suspiciously high correlation?\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check feature importances\n",
        "print(\"=== Feature Importances ===\")\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(importance_df.to_string(index=False))\n",
        "\n",
        "print(\"\\nüîç Which features dominate the model? Are they legitimate?\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Investigate the suspicious features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Look at how churn_risk_score is calculated\n",
        "print(\"=== Investigating churn_risk_score ===\")\n",
        "print(\"\\nFormula:\")\n",
        "print(\"  churn_risk_score = days_since_last_order/30 + (1 - churn_30d) * 0.5\")\n",
        "\n",
        "print(\"\\nü§î Wait... '(1 - churn_30d)' means:\")\n",
        "print(\"  - If churn_30d=1 (yes churn): adds 0\")\n",
        "print(\"  - If churn_30d=0 (no churn): adds 0.5\")\n",
        "print(\"\\n‚ùå This feature USES THE TARGET DIRECTLY!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Think about customer_value\n",
        "print(\"=== Investigating customer_value ===\")\n",
        "print(\"\\nFormula:\")\n",
        "print(\"  customer_value = total_spend\")\n",
        "\n",
        "print(\"\\nü§î Question: Does 'total_spend' include purchases AFTER the prediction date?\")\n",
        "print(\"\\nIf we're predicting churn on Jan 1st:\")\n",
        "print(\"  - total_spend might include purchases from Feb, March, April...\")\n",
        "print(\"  - A customer who didn't churn kept buying ‚Üí higher total_spend\")\n",
        "print(\"  - A customer who churned stopped buying ‚Üí lower total_spend\")\n",
        "\n",
        "print(\"\\n‚ùå This feature LEAKS FUTURE INFORMATION!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write your diagnosis:\n",
        "\n",
        "diagnosis = \"\"\"\n",
        "YOUR DIAGNOSIS HERE:\n",
        "\n",
        "Bug 1 - churn_risk_score:\n",
        "- Type of leakage: _______________\n",
        "- Why it's wrong: _______________\n",
        "\n",
        "Bug 2 - customer_value:\n",
        "- Type of leakage: _______________  \n",
        "- Why it's wrong: _______________\n",
        "\n",
        "\"\"\"\n",
        "print(diagnosis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Fix the feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Remove the leaky features and retrain\n",
        "\n",
        "# Fixed feature list - remove the two buggy features\n",
        "# Uncomment and complete:\n",
        "\n",
        "# feature_cols_fixed = [\n",
        "#     'tenure_months',\n",
        "#     'orders_total', \n",
        "#     'logins_last_30d',\n",
        "#     'orders_per_month',\n",
        "#     'login_frequency',\n",
        "#     # 'churn_risk_score',  # REMOVED - target leakage\n",
        "#     # 'customer_value',    # REMOVED - future leakage\n",
        "#     'support_tickets',\n",
        "#     'avg_order_value'\n",
        "# ]\n",
        "#\n",
        "# X_fixed = df_features[feature_cols_fixed].fillna(0)\n",
        "# X_train_fixed, X_test_fixed, y_train_fixed, y_test_fixed = train_test_split(\n",
        "#     X_fixed, y, test_size=0.2, random_state=42, stratify=y\n",
        "# )\n",
        "#\n",
        "# model_fixed = GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "# model_fixed.fit(X_train_fixed, y_train_fixed)\n",
        "#\n",
        "# y_pred_proba_fixed = model_fixed.predict_proba(X_test_fixed)[:, 1]\n",
        "# auc_fixed = roc_auc_score(y_test_fixed, y_pred_proba_fixed)\n",
        "#\n",
        "# print(f\"Fixed AUC: {auc_fixed:.3f}\")\n",
        "# print(f\"\\nComparison:\")\n",
        "# print(f\"  Buggy AUC:  {auc:.3f} (inflated by leakage)\")\n",
        "# print(f\"  Fixed AUC:  {auc_fixed:.3f} (realistic)\")\n",
        "# print(f\"  Difference: {auc - auc_fixed:.3f} points\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# SELF-CHECK: Did you fix both bugs?\n",
        "# ============================================\n",
        "\n",
        "# Uncomment after fixing:\n",
        "#\n",
        "# # Fixed AUC should be much lower (realistic)\n",
        "# assert auc_fixed < 0.90, \"Fixed AUC should be below 0.90 (realistic for churn)\"\n",
        "# assert auc_fixed < auc, \"Fixed AUC should be lower than buggy AUC\"\n",
        "# \n",
        "# # Check that leaky features are removed\n",
        "# assert 'churn_risk_score' not in feature_cols_fixed, \"Remove churn_risk_score!\"\n",
        "# assert 'customer_value' not in feature_cols_fixed, \"Remove customer_value!\"\n",
        "#\n",
        "# print(\"‚úì Both leaky features removed!\")\n",
        "# print(f\"‚úì AUC dropped from {auc:.3f} to {auc_fixed:.3f}\")\n",
        "# print(\"‚úì The fixed model is realistic and will work in production.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Write your postmortem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "postmortem = \"\"\"\n",
        "## Postmortem: The Leaky Features\n",
        "\n",
        "### What happened:\n",
        "- (Your answer: What symptoms indicated a problem?)\n",
        "\n",
        "### Root cause:\n",
        "- Bug 1: (Type of leakage and which feature)\n",
        "- Bug 2: (Type of leakage and which feature)\n",
        "\n",
        "### How to prevent:\n",
        "- (Your answer: What checks would catch this?)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(postmortem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Drill Complete!\n",
        "\n",
        "**Key lessons:**\n",
        "\n",
        "1. **Target leakage:** Never use the target variable (or anything derived from it) as a feature. The model will \"learn\" to predict using information it won't have.\n",
        "\n",
        "2. **Temporal leakage:** Features must be computed using ONLY data from before the prediction time. \"Lifetime value\" that includes future purchases is cheating.\n",
        "\n",
        "3. **Red flags:**\n",
        "   - AUC > 0.90 on a business problem (too good to be true)\n",
        "   - One feature with >50% importance\n",
        "   - Feature correlation >0.8 with target\n",
        "\n",
        "4. **The Timeline Test:** For every feature, ask: \"At the moment I make this prediction, would I have this exact value?\"\n",
        "\n",
        "---\n",
        "\n",
        "## Types of Leakage Found\n",
        "\n",
        "| Feature | Leakage Type | Why It's Wrong |\n",
        "|---------|-------------|----------------|\n",
        "| `churn_risk_score` | Target leakage | Formula includes `churned` directly |\n",
        "| `customer_value` | Temporal leakage | `total_spend` includes future purchases |\n",
        "\n",
        "---\n",
        "\n",
        "## Bonus: How to fix customer_value properly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# If you wanted a \"value\" feature, compute it as of the prediction date:\n",
        "\n",
        "print(\"WRONG:\")\n",
        "print(\"  customer_value = total_spend  # Includes all-time purchases\")\n",
        "\n",
        "print(\"\\nRIGHT:\")\n",
        "print(\"  customer_value_as_of_date = sum(purchases WHERE date < prediction_date)\")\n",
        "print(\"  \")\n",
        "print(\"  # In pandas:\")\n",
        "print(\"  # purchases_df[purchases_df['date'] < prediction_date].groupby('customer_id')['amount'].sum()\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# The general pattern for point-in-time features:\n",
        "\n",
        "print(\"=== Point-in-Time Feature Pattern ===\")\n",
        "print(\"\"\"\n",
        "def compute_feature(customer_id, prediction_date, events_df):\n",
        "    # Filter to BEFORE prediction date\n",
        "    past_events = events_df[\n",
        "        (events_df['customer_id'] == customer_id) &\n",
        "        (events_df['date'] < prediction_date)  # CRITICAL\n",
        "    ]\n",
        "    \n",
        "    # Compute aggregation on filtered data\n",
        "    return past_events['amount'].sum()\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}