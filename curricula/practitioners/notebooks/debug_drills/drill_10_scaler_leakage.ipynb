{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Drill: The Leaky Pipeline\n",
    "\n",
    "**Scenario:**\n",
    "A colleague built a churn prediction model with impressive performance.\n",
    "\n",
    "\"AUC = 0.92!\" they say. \"Way better than our old model!\"\n",
    "\n",
    "But in production, the AUC drops to 0.72. \"What happened?!\"\n",
    "\n",
    "**Your Task:**\n",
    "1. Run the pipeline and spot the leakage\n",
    "2. Identify TWO sources of leakage\n",
    "3. Fix the pipeline properly\n",
    "4. Write a 3-bullet postmortem\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate customer data\n",
    "n = 2000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'customer_id': range(n),\n",
    "    'tenure_days': np.random.uniform(30, 1000, n),\n",
    "    'monthly_spend': np.random.exponential(100, n),\n",
    "    'support_tickets': np.random.poisson(2, n),\n",
    "    'logins_last_30d': np.random.poisson(15, n),\n",
    "})\n",
    "\n",
    "# Generate churn based on features\n",
    "churn_prob = 1 / (1 + np.exp(\n",
    "    2 - 0.002 * df['tenure_days'] - 0.005 * df['monthly_spend'] +\n",
    "    0.2 * df['support_tickets'] - 0.05 * df['logins_last_30d']\n",
    "))\n",
    "df['churn'] = (np.random.random(n) < churn_prob).astype(int)\n",
    "\n",
    "print(f\"Dataset: {len(df)} customers\")\n",
    "print(f\"Churn rate: {df['churn'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COLLEAGUE'S CODE (TWO BUGS!) =====\n",
    "\n",
    "# Features\n",
    "feature_cols = ['tenure_days', 'monthly_spend', 'support_tickets', 'logins_last_30d']\n",
    "X = df[feature_cols].copy()\n",
    "y = df['churn']\n",
    "\n",
    "# BUG 1: Scale BEFORE splitting (leaks test statistics into train)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # <-- Fitted on ALL data!\n",
    "\n",
    "# BUG 2: Create a target-derived feature (leaks the label itself)\n",
    "# \"Average churn rate for similar customers\" - sounds reasonable, right?\n",
    "df['segment'] = pd.qcut(df['tenure_days'], q=5, labels=['New', 'Active', 'Established', 'Loyal', 'Veteran'])\n",
    "segment_churn_rate = df.groupby('segment')['churn'].transform('mean')  # <-- Uses ALL churn labels!\n",
    "X_scaled = np.column_stack([X_scaled, segment_churn_rate])\n",
    "\n",
    "# Now split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_auc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
    "test_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\"=== Colleague's Results ===\")\n",
    "print(f\"Train AUC: {train_auc:.3f}\")\n",
    "print(f\"Test AUC:  {test_auc:.3f}\")\n",
    "print(\"\\nðŸŽ‰ Amazing performance! Deploying...\")\n",
    "print(\"\\nâš ï¸ But in production, AUC drops to ~0.72. Why?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Your Investigation\n",
    "\n",
    "### Step 1: Identify the leakage sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Leakage Analysis ===\")\n",
    "print()\n",
    "print(\"âŒ BUG 1: Scaler fit on ALL data\")\n",
    "print(\"   - StandardScaler.fit_transform() called BEFORE train_test_split\")\n",
    "print(\"   - Test set statistics leak into the scaled training data\")\n",
    "print(\"   - Result: Optimistic performance estimate\")\n",
    "print()\n",
    "print(\"âŒ BUG 2: Target-derived feature\")\n",
    "print(\"   - 'segment_churn_rate' is calculated using ALL churn labels\")\n",
    "print(\"   - This includes test set labels!\")\n",
    "print(\"   - The feature directly encodes the target\")\n",
    "print()\n",
    "print(\"ðŸ’¡ Production reality:\")\n",
    "print(\"   - Can't use future data to scale\")\n",
    "print(\"   - Can't use the churn label you're trying to predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how much the leaky feature helps\n",
    "print(\"=== Feature Importance (Leaky Model) ===\")\n",
    "feature_names = feature_cols + ['segment_churn_rate']\n",
    "for name, coef in zip(feature_names, model.coef_[0]):\n",
    "    flag = \"âš ï¸ LEAKY\" if name == 'segment_churn_rate' else \"\"\n",
    "    print(f\"  {name:<20}: {coef:>7.3f} {flag}\")\n",
    "\n",
    "print(\"\\nðŸ” The leaky feature has the highest coefficient!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: TODO - Fix the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build a leak-free pipeline\n",
    "\n",
    "# Uncomment and complete:\n",
    "\n",
    "# # Step 1: Use only safe features (no target-derived)\n",
    "# X_clean = df[feature_cols].copy()\n",
    "# y_clean = df['churn']\n",
    "# \n",
    "# # Step 2: Split FIRST\n",
    "# X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(\n",
    "#     X_clean, y_clean, test_size=0.3, random_state=42, stratify=y_clean\n",
    "# )\n",
    "# \n",
    "# # Step 3: Fit scaler on TRAIN only\n",
    "# scaler_clean = StandardScaler()\n",
    "# X_train_scaled = scaler_clean.fit_transform(X_train_clean)  # Fit on train\n",
    "# X_test_scaled = scaler_clean.transform(X_test_clean)         # Transform test (no fit!)\n",
    "# \n",
    "# # Step 4: Train model\n",
    "# model_clean = LogisticRegression(max_iter=1000)\n",
    "# model_clean.fit(X_train_scaled, y_train_clean)\n",
    "# \n",
    "# # Step 5: Evaluate\n",
    "# train_auc_clean = roc_auc_score(y_train_clean, model_clean.predict_proba(X_train_scaled)[:, 1])\n",
    "# test_auc_clean = roc_auc_score(y_test_clean, model_clean.predict_proba(X_test_scaled)[:, 1])\n",
    "# \n",
    "# print(\"=== Clean Pipeline Results ===\")\n",
    "# print(f\"Train AUC: {train_auc_clean:.3f}\")\n",
    "# print(f\"Test AUC:  {test_auc_clean:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare leaky vs clean\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# print(\"=== Comparison ===\")\n",
    "# print(f\"\\n                    Leaky Pipeline    Clean Pipeline\")\n",
    "# print(f\"  Train AUC:        {train_auc:>14.3f}    {train_auc_clean:>14.3f}\")\n",
    "# print(f\"  Test AUC:         {test_auc:>14.3f}    {test_auc_clean:>14.3f}\")\n",
    "# print(f\"\\n  Leakage inflation: {test_auc - test_auc_clean:+.3f}\")\n",
    "# print(f\"\\nðŸ’¡ The 'clean' test AUC is what you'll actually get in production!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK\n",
    "# ============================================\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# assert test_auc_clean < test_auc, \"Clean pipeline should have lower (realistic) AUC\"\n",
    "# assert X_train_scaled.shape[1] == len(feature_cols), \"Should have only safe features\"\n",
    "# \n",
    "# print(\"âœ“ Pipeline fixed!\")\n",
    "# print(f\"âœ“ Removed leaky feature\")\n",
    "# print(f\"âœ“ Scaler fitted on train only\")\n",
    "# print(f\"âœ“ Realistic AUC: {test_auc_clean:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write your postmortem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postmortem = \"\"\"\n",
    "## Postmortem: The Leaky Pipeline\n",
    "\n",
    "### What happened:\n",
    "- (Your answer: What was the gap between test and production performance?)\n",
    "\n",
    "### Root cause:\n",
    "- (Your answer: Name the two leakage sources)\n",
    "\n",
    "### How to prevent:\n",
    "- (Your answer: What's the correct order of operations?)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(postmortem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Drill Complete!\n",
    "\n",
    "**Key lessons:**\n",
    "\n",
    "1. **Always split first.** Any transformation that uses statistics (mean, std, target encoding) must be fit on train only.\n",
    "\n",
    "2. **Watch for target-derived features.** If a feature uses the label in its calculation, it's leaking.\n",
    "\n",
    "3. **The correct order:** Split â†’ Fit transforms on train â†’ Apply to train and test\n",
    "\n",
    "4. **If AUC seems too good to be true, it probably is.**\n",
    "\n",
    "---\n",
    "\n",
    "## Common Leakage Sources\n",
    "\n",
    "| Source | Example | Fix |\n",
    "|--------|---------|-----|\n",
    "| Scaling before split | `fit_transform(X)` then split | Split first, fit on train |\n",
    "| Target encoding on all data | `groupby().transform('mean')` | Use CV encoding |\n",
    "| Future features | `next_month_orders` | Check temporal logic |\n",
    "| Features derived from target | `segment_churn_rate` | Remove or use proper encoding |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
