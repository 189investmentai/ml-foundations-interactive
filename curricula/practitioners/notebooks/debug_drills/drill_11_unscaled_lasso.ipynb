{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Drill: The Unscaled Lasso\n",
    "\n",
    "**Scenario:**\n",
    "A colleague is using Lasso regression for feature selection.\n",
    "\n",
    "\"Lasso says tenure is unimportant!\" they report. \"We should remove it.\"\n",
    "\n",
    "But you know tenure is a strong predictor. What's going on?\n",
    "\n",
    "**Your Task:**\n",
    "1. Run the Lasso and see the unexpected feature selection\n",
    "2. Identify why Lasso is giving wrong results\n",
    "3. Fix the pipeline and compare\n",
    "4. Write a 3-bullet postmortem\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with features on VERY different scales\n",
    "n = 500\n",
    "\n",
    "# Features on wildly different scales\n",
    "tenure_days = np.random.uniform(30, 1000, n)    # Range: ~30-1000\n",
    "monthly_spend = np.random.uniform(20, 200, n)   # Range: ~20-200\n",
    "orders = np.random.poisson(5, n)                # Range: ~0-15\n",
    "is_premium = np.random.binomial(1, 0.3, n)      # Range: 0-1\n",
    "\n",
    "# True relationship (tenure is IMPORTANT)\n",
    "true_coefs = {\n",
    "    'tenure_days': 0.5,      # Important!\n",
    "    'monthly_spend': 2.0,    # Important!\n",
    "    'orders': 30.0,          # Important!\n",
    "    'is_premium': 100.0      # Important!\n",
    "}\n",
    "\n",
    "ltv = (\n",
    "    true_coefs['tenure_days'] * tenure_days +\n",
    "    true_coefs['monthly_spend'] * monthly_spend +\n",
    "    true_coefs['orders'] * orders +\n",
    "    true_coefs['is_premium'] * is_premium +\n",
    "    np.random.normal(0, 50, n)  # Noise\n",
    ")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'tenure_days': tenure_days,\n",
    "    'monthly_spend': monthly_spend,\n",
    "    'orders': orders,\n",
    "    'is_premium': is_premium,\n",
    "    'ltv': ltv\n",
    "})\n",
    "\n",
    "print(\"=== Feature Scales ===\")\n",
    "print(df.describe().loc[['mean', 'std', 'min', 'max']].T.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COLLEAGUE'S CODE (BUG: NO SCALING) =====\n",
    "\n",
    "feature_cols = ['tenure_days', 'monthly_spend', 'orders', 'is_premium']\n",
    "X = df[feature_cols]\n",
    "y = df['ltv']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Lasso without scaling (BUG!)\n",
    "lasso_unscaled = Lasso(alpha=1.0)\n",
    "lasso_unscaled.fit(X_train, y_train)  # <-- No scaling!\n",
    "\n",
    "print(\"=== Colleague's Lasso Results (Unscaled) ===\")\n",
    "print(\"\\nCoefficients:\")\n",
    "for name, coef in zip(feature_cols, lasso_unscaled.coef_):\n",
    "    status = \"ZEROED\" if abs(coef) < 0.01 else f\"{coef:.3f}\"\n",
    "    true_val = true_coefs[name]\n",
    "    print(f\"  {name:<15}: {status:<10} (true: {true_val})\")\n",
    "\n",
    "print(f\"\\nâŒ Colleague's conclusion: 'tenure_days is unimportant, remove it!'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Your Investigation\n",
    "\n",
    "### Step 1: Understand why this happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Why Lasso Gets This Wrong ===\")\n",
    "print()\n",
    "print(\"Lasso penalizes the SUM of |coefficients|.\")\n",
    "print(\"When features are on different scales, this penalty is UNFAIR.\")\n",
    "print()\n",
    "print(\"Consider:\")\n",
    "for name in feature_cols:\n",
    "    scale = df[name].std()\n",
    "    true_coef = true_coefs[name]\n",
    "    contribution = scale * true_coef\n",
    "    print(f\"  {name:<15}: std={scale:>6.1f}, true_coef={true_coef:>5.1f}, contributionâ‰ˆ{contribution:>6.0f}\")\n",
    "\n",
    "print()\n",
    "print(\"ðŸ’¡ tenure_days has a SMALL coefficient (0.5) but high variance.\")\n",
    "print(\"   Lasso sees a small coefficient and zeros it out!\")\n",
    "print(\"   But the actual CONTRIBUTION to prediction is large.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the scale problem\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Unscaled coefficients\n",
    "ax1 = axes[0]\n",
    "ax1.bar(feature_cols, lasso_unscaled.coef_, color=['red' if abs(c) < 0.01 else 'blue' for c in lasso_unscaled.coef_])\n",
    "ax1.axhline(y=0, color='gray', linestyle='--')\n",
    "ax1.set_ylabel('Coefficient')\n",
    "ax1.set_title('Lasso Coefficients (UNSCALED) - tenure wrongly zeroed!')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# True coefficients\n",
    "ax2 = axes[1]\n",
    "ax2.bar(feature_cols, [true_coefs[f] for f in feature_cols], color='green', alpha=0.7)\n",
    "ax2.axhline(y=0, color='gray', linestyle='--')\n",
    "ax2.set_ylabel('Coefficient')\n",
    "ax2.set_title('TRUE Coefficients - tenure IS important!')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: TODO - Fix with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Scale features BEFORE Lasso\n",
    "\n",
    "# Uncomment and complete:\n",
    "\n",
    "# # Step 1: Scale the features (fit on train only!)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "# \n",
    "# # Step 2: Fit Lasso on scaled data\n",
    "# lasso_scaled = LassoCV(cv=5)  # Use CV to find best alpha\n",
    "# lasso_scaled.fit(X_train_scaled, y_train)\n",
    "# \n",
    "# print(\"=== Fixed Lasso Results (Scaled) ===\")\n",
    "# print(f\"\\nOptimal alpha: {lasso_scaled.alpha_:.4f}\")\n",
    "# print(\"\\nCoefficients:\")\n",
    "# for name, coef in zip(feature_cols, lasso_scaled.coef_):\n",
    "#     status = \"ZEROED\" if abs(coef) < 0.01 else f\"{coef:.3f}\"\n",
    "#     print(f\"  {name:<15}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare performance\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# r2_unscaled = r2_score(y_test, lasso_unscaled.predict(X_test))\n",
    "# r2_scaled = r2_score(y_test, lasso_scaled.predict(X_test_scaled))\n",
    "# \n",
    "# print(\"=== Performance Comparison ===\")\n",
    "# print(f\"\\nUnscaled Lasso:\")\n",
    "# print(f\"  RÂ²: {r2_unscaled:.3f}\")\n",
    "# print(f\"  Features selected: {(np.abs(lasso_unscaled.coef_) > 0.01).sum()}\")\n",
    "# print(f\"\\nScaled Lasso:\")\n",
    "# print(f\"  RÂ²: {r2_scaled:.3f}\")\n",
    "# print(f\"  Features selected: {(np.abs(lasso_scaled.coef_) > 0.01).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK\n",
    "# ============================================\n",
    "\n",
    "# Uncomment:\n",
    "\n",
    "# # After scaling, tenure should NOT be zeroed\n",
    "# tenure_idx = feature_cols.index('tenure_days')\n",
    "# assert abs(lasso_scaled.coef_[tenure_idx]) > 0.01, \"tenure_days should not be zeroed after scaling!\"\n",
    "# assert r2_scaled > r2_unscaled, \"Scaled Lasso should have better RÂ²\"\n",
    "# \n",
    "# print(\"âœ“ Lasso fixed!\")\n",
    "# print(f\"âœ“ tenure_days now has coefficient: {lasso_scaled.coef_[tenure_idx]:.3f}\")\n",
    "# print(f\"âœ“ RÂ² improved: {r2_unscaled:.3f} â†’ {r2_scaled:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write your postmortem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postmortem = \"\"\"\n",
    "## Postmortem: The Unscaled Lasso\n",
    "\n",
    "### What happened:\n",
    "- (Your answer: What feature was wrongly eliminated?)\n",
    "\n",
    "### Root cause:\n",
    "- (Your answer: Why does Lasso need scaled features?)\n",
    "\n",
    "### How to prevent:\n",
    "- (Your answer: What preprocessing is required for Lasso/Ridge?)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(postmortem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Drill Complete!\n",
    "\n",
    "**Key lessons:**\n",
    "\n",
    "1. **Always scale before regularization.** Lasso/Ridge penalize coefficient magnitude, so features must be comparable.\n",
    "\n",
    "2. **Unscaled Lasso makes unfair comparisons.** Features with large scales get artificially small coefficients.\n",
    "\n",
    "3. **Feature selection without scaling is wrong.** You'll drop important features just because they're on a different scale.\n",
    "\n",
    "4. **Standard scaling (mean=0, std=1) is the norm.** Makes all features comparable.\n",
    "\n",
    "---\n",
    "\n",
    "## When Scaling Matters\n",
    "\n",
    "| Model | Scaling Required? | Why |\n",
    "|-------|-------------------|-----|\n",
    "| Linear Regression | Optional | Doesn't affect predictions, only coefficient interpretation |\n",
    "| Lasso/Ridge | **Required** | Penalty applied to coefficient magnitude |\n",
    "| Logistic Regression | Recommended | Helps convergence, required for regularization |\n",
    "| SVM | **Required** | Distance-based algorithm |\n",
    "| k-NN | **Required** | Distance-based algorithm |\n",
    "| Decision Trees | Not needed | Splits are scale-invariant |\n",
    "| Random Forest | Not needed | Ensemble of trees |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
