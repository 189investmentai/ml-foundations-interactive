{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Solution: Debug Drill 01 - The Too-Good Model\n",
        "\n",
        "**Bug:** Preprocessing leakage - StandardScaler was fit on ALL data before train/test split.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DATA_URL = 'https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/shared/data/'\n",
        "df = pd.read_csv(DATA_URL + 'streamcart_customers.csv')\n",
        "\n",
        "def engineer_features(data):\n",
        "    df_feat = data.copy()\n",
        "    df_feat['orders_per_month'] = df_feat['orders_total'] / (df_feat['tenure_months'] + 1)\n",
        "    df_feat['spend_per_order'] = df_feat['total_spend'] / (df_feat['orders_total'] + 1)\n",
        "    df_feat['login_intensity'] = df_feat['logins_last_30d'] / 30\n",
        "    df_feat['engagement_ratio'] = df_feat['logins_per_month_avg'] / (df_feat['orders_per_month'] + 0.1)\n",
        "    # days_since_last_order already present in raw data\n",
        "    df_feat['tickets_per_tenure'] = df_feat['support_tickets_total'] / (df_feat['tenure_months'] + 1)\n",
        "    return df_feat\n",
        "\n",
        "df_engineered = engineer_features(df)\n",
        "\n",
        "feature_cols = [\n",
        "    'tenure_months', 'orders_per_month', 'spend_per_order', \n",
        "    'login_intensity', 'engagement_ratio', 'days_since_last_order',\n",
        "    'tickets_per_tenure', 'avg_order_value'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Bug: Preprocessing Before Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# BUGGY PIPELINE\n",
        "X = df_engineered[feature_cols].fillna(0)\n",
        "y = df_engineered['churn_30d']\n",
        "\n",
        "# BUG: Scaler fit on ALL data before split\n",
        "scaler_buggy = StandardScaler()\n",
        "X_scaled_buggy = scaler_buggy.fit_transform(X)\n",
        "\n",
        "X_train_buggy, X_test_buggy, y_train_buggy, y_test_buggy = train_test_split(\n",
        "    X_scaled_buggy, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "model_buggy = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "model_buggy.fit(X_train_buggy, y_train_buggy)\n",
        "\n",
        "auc_buggy = roc_auc_score(y_test_buggy, model_buggy.predict_proba(X_test_buggy)[:, 1])\n",
        "print(f\"Buggy AUC: {auc_buggy:.3f} (inflated)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Fix: Split First, Then Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# FIXED PIPELINE\n",
        "X_raw = df_engineered[feature_cols].fillna(0)\n",
        "y = df_engineered['churn_30d']\n",
        "\n",
        "# Step 1: Split FIRST\n",
        "X_train_raw, X_test_raw, y_train_fixed, y_test_fixed = train_test_split(\n",
        "    X_raw, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Step 2: Fit scaler on TRAIN ONLY\n",
        "scaler_fixed = StandardScaler()\n",
        "X_train_fixed = scaler_fixed.fit_transform(X_train_raw)  # fit + transform\n",
        "X_test_fixed = scaler_fixed.transform(X_test_raw)        # transform only\n",
        "\n",
        "# Step 3: Train and evaluate\n",
        "model_fixed = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "model_fixed.fit(X_train_fixed, y_train_fixed)\n",
        "\n",
        "auc_fixed = roc_auc_score(y_test_fixed, model_fixed.predict_proba(X_test_fixed)[:, 1])\n",
        "print(f\"Fixed AUC: {auc_fixed:.3f} (realistic)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"\\n=== Comparison ===\")\n",
        "print(f\"Buggy AUC:  {auc_buggy:.3f}\")\n",
        "print(f\"Fixed AUC:  {auc_fixed:.3f}\")\n",
        "print(f\"Difference: {auc_buggy - auc_fixed:.3f} points\")\n",
        "print(f\"\\nThe buggy pipeline inflated AUC by {(auc_buggy - auc_fixed) / auc_fixed * 100:.1f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diagnosis\n",
        "\n",
        "**The bug is in stage:** Preprocessing (Stage 3)\n",
        "\n",
        "**The problem is:** StandardScaler was fit on ALL data before the train/test split, so the test set statistics leaked into the training process.\n",
        "\n",
        "**This is called:** Preprocessing leakage (a type of data leakage)\n",
        "\n",
        "**Why it causes inflated AUC:** The scaler learned the mean and standard deviation of the test set. This makes the scaled test features \"easier\" to predict because they're centered using information that wouldn't be available in production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Postmortem\n",
        "\n",
        "### What happened:\n",
        "- Model achieved 97% AUC, which is unrealistically high for churn prediction\n",
        "- This triggered investigation of the pipeline\n",
        "\n",
        "### Root cause:\n",
        "- Preprocessing leakage: StandardScaler was fit on all data before train/test split\n",
        "- Test set statistics (mean, std) leaked into the preprocessing step\n",
        "- The bug was at the Stage 3-4 boundary, not in the model itself\n",
        "\n",
        "### How to prevent:\n",
        "- Always split BEFORE any preprocessing that \"learns\" from data\n",
        "- Use sklearn Pipelines to enforce correct ordering\n",
        "- Add a red flag alert for AUC > 0.90 on typical business problems\n",
        "- Code review checklist: \"Is any .fit() called before split?\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}