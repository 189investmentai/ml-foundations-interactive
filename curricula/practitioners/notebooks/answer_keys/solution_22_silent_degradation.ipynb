{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution: The Silent Degradation\n",
    "\n",
    "This notebook shows the correct solution to the monitoring drill.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from typing import Dict, List\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples, drift_factor=0, concept_drift=0):\n",
    "    \"\"\"Generate data with optional drift.\"\"\"\n",
    "    tenure = np.random.exponential(20, n_samples)\n",
    "    spend = np.random.normal(100, 30, n_samples)\n",
    "    tickets = np.random.poisson(2, n_samples)\n",
    "    \n",
    "    if drift_factor > 0:\n",
    "        spend = spend * (1 + drift_factor * 0.5)\n",
    "        tenure = tenure * (1 + drift_factor * 0.3)\n",
    "    \n",
    "    churn_prob = 0.2 + 0.2 * (tickets > 3) - 0.1 * (spend > 100)\n",
    "    \n",
    "    if concept_drift > 0:\n",
    "        churn_prob = 0.2 - 0.2 * (spend > 100) + 0.05 * (tickets > 3)\n",
    "    \n",
    "    churn_prob = np.clip(churn_prob, 0.05, 0.95)\n",
    "    churned = (np.random.random(n_samples) < churn_prob).astype(int)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'tenure': tenure,\n",
    "        'spend': spend,\n",
    "        'tickets': tickets,\n",
    "        'churned': churned\n",
    "    })\n",
    "\n",
    "# Generate training data and model\n",
    "train_data = generate_data(2000)\n",
    "features = ['tenure', 'spend', 'tickets']\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "model.fit(train_data[features], train_data['churned'])\n",
    "\n",
    "baseline_auc = roc_auc_score(train_data['churned'], model.predict_proba(train_data[features])[:, 1])\n",
    "print(f\"Baseline AUC: {baseline_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Solution: Proper Monitoring with Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psi(expected, actual, buckets=10):\n",
    "    \"\"\"Calculate Population Stability Index.\"\"\"\n",
    "    bins = np.percentile(expected, np.linspace(0, 100, buckets + 1))\n",
    "    bins[0], bins[-1] = -np.inf, np.inf\n",
    "    \n",
    "    exp_counts = np.histogram(expected, bins)[0] / len(expected)\n",
    "    act_counts = np.histogram(actual, bins)[0] / len(actual)\n",
    "    \n",
    "    exp_counts = np.clip(exp_counts, 0.0001, None)\n",
    "    act_counts = np.clip(act_counts, 0.0001, None)\n",
    "    \n",
    "    return np.sum((act_counts - exp_counts) * np.log(act_counts / exp_counts))\n",
    "\n",
    "\n",
    "class ModelMonitor:\n",
    "    \"\"\"Model monitoring with drift detection and alerts.\"\"\"\n",
    "    \n",
    "    def __init__(self, baseline_data, baseline_auc, thresholds):\n",
    "        self.baseline_data = baseline_data\n",
    "        self.baseline_auc = baseline_auc\n",
    "        self.thresholds = thresholds\n",
    "        self.alerts = []\n",
    "    \n",
    "    def check(self, current_data, predictions, actuals=None):\n",
    "        \"\"\"Check for drift and performance degradation.\"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        # Check data drift (PSI)\n",
    "        for feature in ['tenure', 'spend', 'tickets']:\n",
    "            psi = calculate_psi(\n",
    "                self.baseline_data[feature].values,\n",
    "                current_data[feature].values\n",
    "            )\n",
    "            if psi > self.thresholds['psi_critical']:\n",
    "                alerts.append(f\"ðŸš¨ CRITICAL: {feature} PSI={psi:.2f}\")\n",
    "            elif psi > self.thresholds['psi_warning']:\n",
    "                alerts.append(f\"âš ï¸ WARNING: {feature} PSI={psi:.2f}\")\n",
    "        \n",
    "        # Check performance (if we have ground truth)\n",
    "        if actuals is not None:\n",
    "            current_auc = roc_auc_score(actuals, predictions)\n",
    "            auc_drop = self.baseline_auc - current_auc\n",
    "            \n",
    "            if auc_drop > self.thresholds['auc_critical']:\n",
    "                alerts.append(f\"ðŸš¨ CRITICAL: AUC dropped {auc_drop:.2%}\")\n",
    "            elif auc_drop > self.thresholds['auc_warning']:\n",
    "                alerts.append(f\"âš ï¸ WARNING: AUC dropped {auc_drop:.2%}\")\n",
    "        \n",
    "        self.alerts.extend(alerts)\n",
    "        return alerts\n",
    "\n",
    "\n",
    "# Configure thresholds\n",
    "thresholds = {\n",
    "    'psi_warning': 0.1,\n",
    "    'psi_critical': 0.25,\n",
    "    'auc_warning': 0.03,\n",
    "    'auc_critical': 0.05\n",
    "}\n",
    "\n",
    "monitor = ModelMonitor(train_data, baseline_auc, thresholds)\n",
    "print(\"âœ“ ModelMonitor created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Production with Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Production Monitoring Over 12 Weeks ===\")\n",
    "weekly_data = []\n",
    "\n",
    "for week in range(12):\n",
    "    drift = min(week / 8, 1.0) * 0.6\n",
    "    concept_drift = max(0, (week - 4) / 8) * 0.8\n",
    "    \n",
    "    prod_data = generate_data(500, drift_factor=drift, concept_drift=concept_drift)\n",
    "    preds = model.predict_proba(prod_data[features])[:, 1]\n",
    "    actual_auc = roc_auc_score(prod_data['churned'], preds)\n",
    "    \n",
    "    alerts = monitor.check(prod_data, preds, prod_data['churned'])\n",
    "    \n",
    "    weekly_data.append({\n",
    "        'week': week + 1,\n",
    "        'auc': actual_auc,\n",
    "        'alerts': len(alerts)\n",
    "    })\n",
    "    \n",
    "    if alerts:\n",
    "        print(f\"\\nWeek {week + 1} (AUC: {actual_auc:.3f}):\")\n",
    "        for alert in alerts:\n",
    "            print(f\"  {alert}\")\n",
    "\n",
    "print(f\"\\nâœ“ Monitoring caught {len(monitor.alerts)} alerts total!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly = pd.DataFrame(weekly_data)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_weekly['week'], df_weekly['auc'], 'b-o', linewidth=2, markersize=8)\n",
    "plt.axhline(y=baseline_auc, color='g', linestyle='--', label='Baseline')\n",
    "plt.axhline(y=baseline_auc - 0.03, color='orange', linestyle='--', label='Warning')\n",
    "plt.axhline(y=baseline_auc - 0.05, color='r', linestyle='--', label='Critical')\n",
    "\n",
    "# Mark alert weeks\n",
    "for _, row in df_weekly.iterrows():\n",
    "    if row['alerts'] > 0:\n",
    "        plt.scatter(row['week'], row['auc'], color='red', s=200, zorder=5)\n",
    "\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('Model Performance with Monitoring (Red = Alerts Fired)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "assert len(monitor.alerts) > 0, \"Monitor should have caught alerts\"\n",
    "assert any('CRITICAL' in a for a in monitor.alerts), \"Should have critical alerts\"\n",
    "\n",
    "print(\"\\nâœ“ All checks passed!\")\n",
    "print(f\"âœ“ Total alerts: {len(monitor.alerts)}\")\n",
    "print(\"âœ“ Degradation was detected before business impact!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insight\n",
    "\n",
    "Effective monitoring requires:\n",
    "\n",
    "1. **Track multiple metrics** - PSI for data drift, accuracy/AUC for performance\n",
    "2. **Set tiered thresholds** - Warning for investigation, Critical for action\n",
    "3. **Alert early** - Before business metrics decline\n",
    "4. **Automate decisions** - Clear triggers for retraining\n",
    "\n",
    "| Metric | Warning | Critical |\n",
    "|--------|---------|----------|\n",
    "| PSI | > 0.1 | > 0.25 |\n",
    "| AUC Drop | > 3% | > 5% |\n",
    "| Pred Mean Shift | > 1 std | > 2 std |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
