{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 5: Decision Trees for Interpretable Predictions\n",
        "\n",
        "**Goal:** Build and interpret decision trees, understand overfitting, and extract business rules.\n",
        "\n",
        "**Prerequisites:** Module 4 (Logistic Regression)\n",
        "\n",
        "**Expected Runtime:** ~45 minutes\n",
        "\n",
        "**Outputs:**\n",
        "- Trained decision tree with visualization\n",
        "- Overfitting diagnosis via depth/leaf constraints\n",
        "- Extracted business rules from tree structure\n",
        "- Tree vs logistic regression performance comparison\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ Libraries loaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DATA_URL = 'https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/shared/data/'\n",
        "\n",
        "customers = pd.read_csv(DATA_URL + 'streamcart_customers.csv')\n",
        "print(f\"Loaded {len(customers)} customers\")\n",
        "customers.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Feature engineering\n",
        "if 'tenure_days' not in customers.columns:\n",
        "    customers['tenure_days'] = (pd.to_datetime('2024-01-01') - pd.to_datetime(customers['signup_date'])).dt.days\n",
        "if 'avg_order_value' not in customers.columns:\n",
        "    customers['avg_order_value'] = customers['total_spend'] / customers['orders_total'].replace(0, 1)\n",
        "\n",
        "# Select features\n",
        "feature_cols = ['tenure_days', 'orders_total', 'total_spend', 'support_tickets_total', 'avg_order_value']\n",
        "available_features = [c for c in feature_cols if c in customers.columns]\n",
        "print(f\"Features: {available_features}\")\n",
        "\n",
        "X = customers[available_features].fillna(0)\n",
        "y = customers['churn_30d']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "print(f\"\\nTrain: {len(X_train)}, Test: {len(X_test)}\")\n",
        "print(f\"Churn rate: {y.mean():.1%}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Baseline: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit logistic regression for comparison\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "logreg_train_acc = logreg.score(X_train, y_train)\n",
        "logreg_test_acc = logreg.score(X_test, y_test)\n",
        "\n",
        "print(\"Logistic Regression Baseline:\")\n",
        "print(f\"  Train Accuracy: {logreg_train_acc:.1%}\")\n",
        "print(f\"  Test Accuracy: {logreg_test_acc:.1%}\")\n",
        "print(f\"  Gap: {logreg_train_acc - logreg_test_acc:.1%}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Unconstrained Tree (Overfitting Demo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit a deep tree with no constraints\n",
        "tree_deep = DecisionTreeClassifier(random_state=42)\n",
        "tree_deep.fit(X_train, y_train)\n",
        "\n",
        "deep_train_acc = tree_deep.score(X_train, y_train)\n",
        "deep_test_acc = tree_deep.score(X_test, y_test)\n",
        "\n",
        "print(\"Unconstrained Decision Tree:\")\n",
        "print(f\"  Train Accuracy: {deep_train_acc:.1%}\")\n",
        "print(f\"  Test Accuracy: {deep_test_acc:.1%}\")\n",
        "print(f\"  Gap: {deep_train_acc - deep_test_acc:.1%}\")\n",
        "print(f\"\\n  Depth: {tree_deep.get_depth()}\")\n",
        "print(f\"  Number of leaves: {tree_deep.get_n_leaves()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Self-Check: Overfitting\n",
        "\n",
        "Notice the huge gap between train and test accuracy! The unconstrained tree has memorized the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. TODO: Find Optimal Depth\n",
        "\n",
        "Your task: Try different max_depth values and find the one that maximizes TEST accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Experiment: Find optimal depth by comparing train vs test accuracy\n",
        "\n",
        "depths = range(1, 15)\n",
        "results = []\n",
        "\n",
        "for depth in depths:\n",
        "    tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
        "    tree.fit(X_train, y_train)\n",
        "    \n",
        "    # Calculate train and test accuracy\n",
        "    train_acc = tree.score(X_train, y_train)\n",
        "    test_acc = tree.score(X_test, y_test)\n",
        "    \n",
        "    results.append({\n",
        "        'depth': depth,\n",
        "        'train_acc': train_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'n_leaves': tree.get_n_leaves()\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Accuracy vs Depth\n",
        "ax1 = axes[0]\n",
        "ax1.plot(results_df['depth'], results_df['train_acc'], 'b-o', label='Train', linewidth=2)\n",
        "ax1.plot(results_df['depth'], results_df['test_acc'], 'r-o', label='Test', linewidth=2)\n",
        "ax1.axhline(y=logreg_test_acc, color='green', linestyle='--', label='Logistic Regression')\n",
        "ax1.set_xlabel('Max Depth')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_title('Train vs Test Accuracy by Depth')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Number of leaves vs Depth\n",
        "ax2 = axes[1]\n",
        "ax2.plot(results_df['depth'], results_df['n_leaves'], 'purple', marker='s', linewidth=2)\n",
        "ax2.set_xlabel('Max Depth')\n",
        "ax2.set_ylabel('Number of Leaves')\n",
        "ax2.set_title('Model Complexity by Depth')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find and report the optimal depth\n",
        "optimal_idx = results_df['test_acc'].idxmax()\n",
        "optimal_depth = results_df.loc[optimal_idx, 'depth']\n",
        "\n",
        "print(f\"=== Optimal max_depth: {optimal_depth} ===\")\n",
        "print(f\"Test accuracy: {results_df.loc[optimal_idx, 'test_acc']:.1%}\")\n",
        "print(f\"Train accuracy: {results_df.loc[optimal_idx, 'train_acc']:.1%}\")\n",
        "print(f\"Number of leaves: {results_df.loc[optimal_idx, 'n_leaves']}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train the Optimal Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train tree with optimal depth (using the value found above)\n",
        "# Note: optimal_depth is set dynamically in the previous cell\n",
        "\n",
        "tree_optimal = DecisionTreeClassifier(\n",
        "    max_depth=optimal_depth,\n",
        "    min_samples_leaf=10,\n",
        "    random_state=42\n",
        ")\n",
        "tree_optimal.fit(X_train, y_train)\n",
        "\n",
        "print(f\"=== Optimal Decision Tree (depth={optimal_depth}) ===\")\n",
        "print(f\"  Actual Depth: {tree_optimal.get_depth()}\")\n",
        "print(f\"  Number of Leaves: {tree_optimal.get_n_leaves()}\")\n",
        "print(f\"\\n  Train Accuracy: {tree_optimal.score(X_train, y_train):.1%}\")\n",
        "print(f\"  Test Accuracy: {tree_optimal.score(X_test, y_test):.1%}\")\n",
        "print(f\"  Gap: {tree_optimal.score(X_train, y_train) - tree_optimal.score(X_test, y_test):.1%}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualize the Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot the tree structure\n",
        "plt.figure(figsize=(20, 12))\n",
        "plot_tree(\n",
        "    tree_optimal,\n",
        "    feature_names=available_features,\n",
        "    class_names=['Retained', 'Churned'],\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    fontsize=10\n",
        ")\n",
        "plt.title('Decision Tree for Churn Prediction')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Text representation\n",
        "tree_rules = export_text(tree_optimal, feature_names=available_features)\n",
        "print(\"Decision Tree Rules:\")\n",
        "print(tree_rules)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Feature importances\n",
        "importances = pd.DataFrame({\n",
        "    'feature': available_features,\n",
        "    'importance': tree_optimal.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"Feature Importances:\")\n",
        "print(importances.to_string(index=False))\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(importances['feature'], importances['importance'], color='#22c55e')\n",
        "plt.xlabel('Importance (Gini reduction)')\n",
        "plt.title('Feature Importance in Churn Prediction')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Extract Business Rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def extract_rules(tree, feature_names, class_names):\n",
        "    \"\"\"\n",
        "    Extract human-readable rules from a decision tree.\n",
        "    \"\"\"\n",
        "    from sklearn.tree import _tree\n",
        "    \n",
        "    tree_ = tree.tree_\n",
        "    feature_name = [\n",
        "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
        "        for i in tree_.feature\n",
        "    ]\n",
        "    \n",
        "    rules = []\n",
        "    \n",
        "    def recurse(node, path=\"\"):\n",
        "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
        "            name = feature_name[node]\n",
        "            threshold = tree_.threshold[node]\n",
        "            \n",
        "            # Left branch (<=)\n",
        "            left_path = f\"{path} AND {name} <= {threshold:.1f}\" if path else f\"{name} <= {threshold:.1f}\"\n",
        "            recurse(tree_.children_left[node], left_path)\n",
        "            \n",
        "            # Right branch (>)\n",
        "            right_path = f\"{path} AND {name} > {threshold:.1f}\" if path else f\"{name} > {threshold:.1f}\"\n",
        "            recurse(tree_.children_right[node], right_path)\n",
        "        else:\n",
        "            # Leaf node\n",
        "            value = tree_.value[node][0]\n",
        "            total = sum(value)\n",
        "            class_idx = np.argmax(value)\n",
        "            confidence = value[class_idx] / total\n",
        "            \n",
        "            if class_idx == 1:  # Only show churn rules\n",
        "                rules.append({\n",
        "                    'rule': path,\n",
        "                    'prediction': class_names[class_idx],\n",
        "                    'samples': int(total),\n",
        "                    'confidence': confidence\n",
        "                })\n",
        "    \n",
        "    recurse(0)\n",
        "    return pd.DataFrame(rules).sort_values('confidence', ascending=False)\n",
        "\n",
        "# Extract and display churn rules\n",
        "churn_rules = extract_rules(tree_optimal, available_features, ['Retained', 'Churned'])\n",
        "print(\"Top Churn Rules:\")\n",
        "for i, row in churn_rules.head(5).iterrows():\n",
        "    print(f\"\\nIF {row['rule']}\")\n",
        "    print(f\"   → {row['prediction']} ({row['confidence']:.0%} of {row['samples']} customers)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Compare Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final comparison\n",
        "print(\"Model Comparison:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nLogistic Regression:\")\n",
        "print(f\"  Test Accuracy: {logreg_test_acc:.1%}\")\n",
        "print(f\"  Interpretability: Coefficients\")\n",
        "\n",
        "print(f\"\\nDecision Tree (depth={optimal_depth}):\")\n",
        "print(f\"  Test Accuracy: {tree_optimal.score(X_test, y_test):.1%}\")\n",
        "print(f\"  Interpretability: {tree_optimal.get_n_leaves()} rules\")\n",
        "\n",
        "print(f\"\\nUnconstrained Tree:\")\n",
        "print(f\"  Test Accuracy: {deep_test_acc:.1%}\")\n",
        "print(f\"  Interpretability: {tree_deep.get_n_leaves()} rules (too many!)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Stakeholder Summary\n",
        "\n",
        "### TODO: Write a 3-bullet summary (~100 words) for the support team\n",
        "\n",
        "Template:\n",
        "• **The rules:** Top 2-3 rules that identify high-risk customers (e.g., \"tenure < 30 days AND support tickets > 2\")\n",
        "• **Accuracy:** Test accuracy ___%, catching ___% of churners with these rules\n",
        "• **How to use:** [Should they prioritize certain customer segments? What action should they take?]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Summary:**\n",
        "\n",
        "_[Write your summary here]_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# SELF-CHECK: Verify your tree experiments are correct\n",
        "# Run this after completing the depth experiment\n",
        "\n",
        "# Check that you found the optimal depth\n",
        "assert 'optimal_depth' in dir(), \"Should have found optimal_depth\"\n",
        "assert 1 <= optimal_depth <= 14, f\"Optimal depth {optimal_depth} seems unusual\"\n",
        "\n",
        "# Check that optimal tree exists\n",
        "assert 'tree_optimal' in dir(), \"Should have trained tree_optimal\"\n",
        "\n",
        "# Check that tree is not overfitting\n",
        "train_acc = tree_optimal.score(X_train, y_train)\n",
        "test_acc = tree_optimal.score(X_test, y_test)\n",
        "gap = train_acc - test_acc\n",
        "assert gap < 0.20, f\"Train-test gap ({gap:.1%}) suggests overfitting\"\n",
        "\n",
        "# Check that we beat the unconstrained tree\n",
        "assert tree_optimal.get_n_leaves() < tree_deep.get_n_leaves(), \"Optimal tree should have fewer leaves\"\n",
        "\n",
        "print(\"✅ Self-check passed!\")\n",
        "print(f\"   Optimal depth: {optimal_depth}\")\n",
        "print(f\"   Train accuracy: {train_acc:.1%}\")\n",
        "print(f\"   Test accuracy: {test_acc:.1%}\")\n",
        "print(f\"   Train-test gap: {gap:.1%}\")\n",
        "print(f\"   Leaves: {tree_optimal.get_n_leaves()} (vs {tree_deep.get_n_leaves()} unconstrained)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Self-Assessment Checklist\n",
        "\n",
        "- [ ] I identified the overfitting problem with unconstrained trees\n",
        "- [ ] I found the optimal depth using train/test comparison\n",
        "- [ ] I can visualize and interpret tree structure\n",
        "- [ ] I extracted human-readable business rules\n",
        "- [ ] I compared tree vs logistic regression tradeoffs\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "1. **Debug Drill:** Fix an overfit tree\n",
        "2. **Module 6:** Ensemble Methods — Random Forests and Boosting"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}