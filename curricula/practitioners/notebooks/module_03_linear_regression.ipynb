{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 3: Linear Regression - Predicting Customer Spend\n",
        "\n",
        "**Goal:** Build a linear regression model to predict customer total spend from behavioral features.\n",
        "\n",
        "**Time:** ~45 minutes\n",
        "\n",
        "**What you'll do:**\n",
        "1. Load and explore StreamCart customer data\n",
        "2. Establish a mean baseline\n",
        "3. Build a simple linear regression (single feature)\n",
        "4. Build a multiple linear regression (multiple features)\n",
        "5. Analyze residuals for model diagnostics\n",
        "6. Interpret coefficients in business terms\n",
        "7. Communicate results to stakeholders\n",
        "\n",
        "**Prerequisites:**\n",
        "- Python basics\n",
        "- Pandas fundamentals\n",
        "- Basic statistics (mean, variance)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Visualization settings\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = [10, 6]\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# For reproducibility\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Explore Data\n",
        "\n",
        "We'll use StreamCart customer data. Each row is a customer with behavioral features and their total spend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DATA_URL = 'https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/shared/data/'\n",
        "\n",
        "df = pd.read_csv(DATA_URL + 'streamcart_customers.csv')\n",
        "print(f\"Loaded {len(df):,} customers\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Let's understand our target variable: total_spend\n",
        "print(\"=== Target Variable: total_spend ===\")\n",
        "print(df['total_spend'].describe())\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.hist(df['total_spend'], bins=50, edgecolor='white', alpha=0.7)\n",
        "plt.xlabel('Total Spend ($)')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Customer Total Spend')\n",
        "plt.axvline(df['total_spend'].mean(), color='red', linestyle='--', label=f\"Mean: ${df['total_spend'].mean():.0f}\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Explore potential features\n",
        "feature_cols = ['tenure_months', 'logins_last_30d', 'orders_total', 'avg_order_value', \n",
        "                'support_tickets_total', 'logins_per_month_avg']\n",
        "\n",
        "print(\"=== Potential Features ===\")\n",
        "for col in feature_cols:\n",
        "    correlation = df[col].corr(df['total_spend'])\n",
        "    print(f\"{col:25s} correlation with total_spend: {correlation:+.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Establish a Baseline\n",
        "\n",
        "**Always start with a baseline!** The simplest baseline is predicting the mean for everyone.\n",
        "\n",
        "This tells us: \"If our model can't beat predicting the average, it's not learning anything useful.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split data first (important: always split before looking at test data!)\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {len(train_df):,} customers\")\n",
        "print(f\"Test set: {len(test_df):,} customers\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Baseline: predict the training mean for everyone\n",
        "baseline_prediction = train_df['total_spend'].mean()\n",
        "print(f\"Baseline prediction (mean): ${baseline_prediction:.2f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "baseline_mae = mean_absolute_error(test_df['total_spend'], [baseline_prediction] * len(test_df))\n",
        "baseline_rmse = np.sqrt(mean_squared_error(test_df['total_spend'], [baseline_prediction] * len(test_df)))\n",
        "\n",
        "print(f\"\\nBaseline Performance:\")\n",
        "print(f\"  MAE:  ${baseline_mae:.2f}\")\n",
        "print(f\"  RMSE: ${baseline_rmse:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# SELF-CHECK: Baseline sanity check\n",
        "# ============================================\n",
        "assert baseline_mae > 50, \"Baseline MAE seems too low - check your data\"\n",
        "assert baseline_mae < 500, \"Baseline MAE seems too high - check your data\"\n",
        "print(\"âœ“ Baseline looks reasonable\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Simple Linear Regression (Single Feature)\n",
        "\n",
        "Let's start with the simplest model: using just **tenure_months** to predict total_spend.\n",
        "\n",
        "**Hypothesis:** Customers who've been with us longer have spent more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the relationship first\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(train_df['tenure_months'], train_df['total_spend'], alpha=0.3, s=20)\n",
        "plt.xlabel('Tenure (months)')\n",
        "plt.ylabel('Total Spend ($)')\n",
        "plt.title('Tenure vs Total Spend')\n",
        "plt.show()\n",
        "\n",
        "# What do you observe? Is the relationship roughly linear?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit simple linear regression\n",
        "X_train_simple = train_df[['tenure_months']]\n",
        "X_test_simple = test_df[['tenure_months']]\n",
        "y_train = train_df['total_spend']\n",
        "y_test = test_df['total_spend']\n",
        "\n",
        "model_simple = LinearRegression()\n",
        "model_simple.fit(X_train_simple, y_train)\n",
        "\n",
        "# Print the equation\n",
        "print(\"=== Simple Linear Regression ===\")\n",
        "print(f\"Equation: total_spend = {model_simple.intercept_:.2f} + {model_simple.coef_[0]:.2f} Ã— tenure_months\")\n",
        "print(f\"\\nInterpretation:\")\n",
        "print(f\"  - Intercept (Î²â‚€): ${model_simple.intercept_:.2f} = predicted spend for a brand new customer (tenure = 0)\")\n",
        "print(f\"  - Coefficient (Î²â‚): ${model_simple.coef_[0]:.2f} = additional spend per month of tenure\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Evaluate simple model\n",
        "y_pred_simple = model_simple.predict(X_test_simple)\n",
        "\n",
        "simple_mae = mean_absolute_error(y_test, y_pred_simple)\n",
        "simple_rmse = np.sqrt(mean_squared_error(y_test, y_pred_simple))\n",
        "simple_r2 = r2_score(y_test, y_pred_simple)\n",
        "\n",
        "print(\"=== Simple Model Performance ===\")\n",
        "print(f\"  MAE:  ${simple_mae:.2f} (baseline: ${baseline_mae:.2f})\")\n",
        "print(f\"  RMSE: ${simple_rmse:.2f} (baseline: ${baseline_rmse:.2f})\")\n",
        "print(f\"  RÂ²:   {simple_r2:.3f}\")\n",
        "print(f\"\\nImprovement over baseline: {(baseline_mae - simple_mae) / baseline_mae * 100:.1f}% reduction in MAE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the regression line\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(test_df['tenure_months'], y_test, alpha=0.3, s=20, label='Actual')\n",
        "\n",
        "# Plot regression line\n",
        "x_line = np.linspace(0, test_df['tenure_months'].max(), 100)\n",
        "y_line = model_simple.intercept_ + model_simple.coef_[0] * x_line\n",
        "plt.plot(x_line, y_line, 'r-', linewidth=2, label='Prediction')\n",
        "\n",
        "plt.xlabel('Tenure (months)')\n",
        "plt.ylabel('Total Spend ($)')\n",
        "plt.title(f'Simple Linear Regression (RÂ² = {simple_r2:.3f})')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# SELF-CHECK: Simple model should beat baseline\n",
        "# ============================================\n",
        "assert simple_mae < baseline_mae, \"Model should beat the baseline!\"\n",
        "assert model_simple.coef_[0] > 0, \"Tenure coefficient should be positive (longer tenure = more spend)\"\n",
        "print(\"âœ“ Simple model passes sanity checks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Multiple Linear Regression\n",
        "\n",
        "Now let's add more features. Multiple regression uses the equation:\n",
        "\n",
        "**y = Î²â‚€ + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + ... + Î²â‚™xâ‚™**\n",
        "\n",
        "Each coefficient tells us: \"Holding all other features constant, a 1-unit increase in this feature is associated with Î²áµ¢ change in the target.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Select features for multiple regression\n",
        "features = ['tenure_months', 'logins_last_30d', 'orders_total', 'avg_order_value']\n",
        "\n",
        "X_train_multi = train_df[features].fillna(0)\n",
        "X_test_multi = test_df[features].fillna(0)\n",
        "\n",
        "model_multi = LinearRegression()\n",
        "model_multi.fit(X_train_multi, y_train)\n",
        "\n",
        "# Print coefficients\n",
        "print(\"=== Multiple Linear Regression ===\")\n",
        "print(f\"Intercept: ${model_multi.intercept_:.2f}\\n\")\n",
        "print(\"Coefficients:\")\n",
        "for feature, coef in zip(features, model_multi.coef_):\n",
        "    print(f\"  {feature:20s}: {coef:+.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Evaluate multiple regression model\n",
        "y_pred_multi = model_multi.predict(X_test_multi)\n",
        "\n",
        "multi_mae = mean_absolute_error(y_test, y_pred_multi)\n",
        "multi_rmse = np.sqrt(mean_squared_error(y_test, y_pred_multi))\n",
        "multi_r2 = r2_score(y_test, y_pred_multi)\n",
        "\n",
        "print(\"=== Multiple Model Performance ===\")\n",
        "print(f\"  MAE:  ${multi_mae:.2f}\")\n",
        "print(f\"  RMSE: ${multi_rmse:.2f}\")\n",
        "print(f\"  RÂ²:   {multi_r2:.3f}\")\n",
        "\n",
        "print(f\"\\n=== Comparison ===\")\n",
        "print(f\"  Baseline MAE:      ${baseline_mae:.2f}\")\n",
        "print(f\"  Simple Model MAE:  ${simple_mae:.2f}\")\n",
        "print(f\"  Multiple Model MAE: ${multi_mae:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# SELF-CHECK: Multiple model should improve RÂ²\n",
        "# ============================================\n",
        "assert multi_r2 > simple_r2, \"Adding features should improve RÂ² (on training data at least)\"\n",
        "print(f\"âœ“ RÂ² improved from {simple_r2:.3f} to {multi_r2:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Residual Analysis\n",
        "\n",
        "Residuals = Actual - Predicted\n",
        "\n",
        "A good model has residuals that are:\n",
        "- **Random** (no patterns)\n",
        "- **Centered around zero**\n",
        "- **Roughly constant spread** (homoscedasticity)\n",
        "\n",
        "Patterns in residuals tell us the model is systematically wrong."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate residuals\n",
        "residuals = y_test - y_pred_multi\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Plot 1: Residuals vs Predicted\n",
        "axes[0].scatter(y_pred_multi, residuals, alpha=0.3, s=20)\n",
        "axes[0].axhline(y=0, color='r', linestyle='--')\n",
        "axes[0].set_xlabel('Predicted Value ($)')\n",
        "axes[0].set_ylabel('Residual ($)')\n",
        "axes[0].set_title('Residuals vs Predicted')\n",
        "\n",
        "# Plot 2: Histogram of residuals\n",
        "axes[1].hist(residuals, bins=50, edgecolor='white', alpha=0.7)\n",
        "axes[1].axvline(x=0, color='r', linestyle='--')\n",
        "axes[1].set_xlabel('Residual ($)')\n",
        "axes[1].set_ylabel('Count')\n",
        "axes[1].set_title('Distribution of Residuals')\n",
        "\n",
        "# Plot 3: Actual vs Predicted\n",
        "axes[2].scatter(y_test, y_pred_multi, alpha=0.3, s=20)\n",
        "max_val = max(y_test.max(), y_pred_multi.max())\n",
        "axes[2].plot([0, max_val], [0, max_val], 'r--', label='Perfect prediction')\n",
        "axes[2].set_xlabel('Actual Total Spend ($)')\n",
        "axes[2].set_ylabel('Predicted Total Spend ($)')\n",
        "axes[2].set_title('Actual vs Predicted')\n",
        "axes[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nWhat to look for:\")\n",
        "print(\"  - Left plot: Should show random scatter around zero (no patterns)\")\n",
        "print(\"  - Middle plot: Should be roughly bell-shaped, centered at zero\")\n",
        "print(\"  - Right plot: Points should cluster around the diagonal line\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Coefficient Interpretation Workshop\n",
        "\n",
        "This is where we translate model outputs into business insights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a coefficient summary table\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Coefficient': model_multi.coef_,\n",
        "    'Unit': ['months', 'logins', 'orders', 'dollars']\n",
        "})\n",
        "coef_df['Interpretation'] = [\n",
        "    f\"Each additional month of tenure â†’ ${coef_df.loc[0, 'Coefficient']:.2f} more spend\",\n",
        "    f\"Each additional login (last 30d) â†’ ${coef_df.loc[1, 'Coefficient']:.2f} more spend\",\n",
        "    f\"Each additional order â†’ ${coef_df.loc[2, 'Coefficient']:.2f} more spend\",\n",
        "    f\"Each $1 higher avg order value â†’ ${coef_df.loc[3, 'Coefficient']:.2f} more total spend\"\n",
        "]\n",
        "\n",
        "print(\"=== Coefficient Interpretations ===\")\n",
        "print(coef_df.to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize coefficient magnitudes\n",
        "# Note: These are NOT directly comparable due to different scales!\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Raw coefficients\n",
        "colors = ['green' if c > 0 else 'red' for c in model_multi.coef_]\n",
        "axes[0].barh(features, model_multi.coef_, color=colors, alpha=0.7)\n",
        "axes[0].axvline(x=0, color='black', linewidth=0.5)\n",
        "axes[0].set_xlabel('Coefficient Value')\n",
        "axes[0].set_title('Raw Coefficients (NOT directly comparable!)')\n",
        "\n",
        "# Standardized coefficients (for fair comparison)\n",
        "X_train_std = (X_train_multi - X_train_multi.mean()) / X_train_multi.std()\n",
        "model_std = LinearRegression()\n",
        "model_std.fit(X_train_std, y_train)\n",
        "\n",
        "colors_std = ['green' if c > 0 else 'red' for c in model_std.coef_]\n",
        "axes[1].barh(features, model_std.coef_, color=colors_std, alpha=0.7)\n",
        "axes[1].axvline(x=0, color='black', linewidth=0.5)\n",
        "axes[1].set_xlabel('Standardized Coefficient')\n",
        "axes[1].set_title('Standardized Coefficients (comparable importance)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey insight: Raw coefficients depend on feature scales.\")\n",
        "print(\"To compare feature importance, use standardized coefficients or feature importance scores.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Write a business interpretation for one coefficient\n",
        "#\n",
        "# Fill in the blank:\n",
        "# \"Holding all else equal, one more ______ in the last 30 days is associated with $______ more total spend.\"\n",
        "#\n",
        "# Your answer:\n",
        "your_interpretation = \"\"\"\n",
        "Holding all else equal, one more ______ is associated with $______ more total spend.\n",
        "\"\"\"\n",
        "print(your_interpretation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Explain It to a PM\n",
        "\n",
        "The final step: translate your model into a message a product manager can act on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Summary statistics for your update\n",
        "print(\"=== Summary for PM Update ===\")\n",
        "print(f\"\\nModel Performance:\")\n",
        "print(f\"  - RÂ² = {multi_r2:.3f} ({multi_r2*100:.1f}% of spend variation explained)\")\n",
        "print(f\"  - Average prediction error: ${multi_mae:.2f}\")\n",
        "print(f\"  - Improvement over baseline: {(baseline_mae - multi_mae) / baseline_mae * 100:.1f}%\")\n",
        "\n",
        "print(f\"\\nKey Drivers of Customer Spend:\")\n",
        "for feature, coef in sorted(zip(features, model_std.coef_), key=lambda x: abs(x[1]), reverse=True):\n",
        "    direction = \"â†‘\" if coef > 0 else \"â†“\"\n",
        "    print(f\"  {direction} {feature}: {abs(coef):.2f} (standardized importance)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Write your PM update (150-250 words)\n",
        "#\n",
        "# Include:\n",
        "# 1. What the model predicts\n",
        "# 2. How accurate it is (in plain language)\n",
        "# 3. Key drivers discovered\n",
        "# 4. One actionable recommendation\n",
        "#\n",
        "# Avoid: jargon like \"RÂ²\", \"coefficients\", \"residuals\"\n",
        "\n",
        "pm_update = \"\"\"\n",
        "## Customer Spend Prediction Model - Summary\n",
        "\n",
        "[YOUR UPDATE HERE]\n",
        "\n",
        "**What we built:**\n",
        "\n",
        "\n",
        "**How well it works:**\n",
        "\n",
        "\n",
        "**Key findings:**\n",
        "\n",
        "\n",
        "**Recommendation:**\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(pm_update)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "In this lab, you learned to:\n",
        "\n",
        "1. **Always establish a baseline** - Predicting the mean is the simplest model\n",
        "2. **Build simple models first** - Single feature before multiple features\n",
        "3. **Interpret coefficients** - Each one has a business meaning (with units!)\n",
        "4. **Check residuals** - Patterns reveal model problems\n",
        "5. **Communicate to stakeholders** - Translate metrics into decisions\n",
        "\n",
        "### Key Metrics Learned\n",
        "\n",
        "| Metric | Meaning | Business Translation |\n",
        "|--------|---------|---------------------|\n",
        "| MAE | Average absolute error | \"Our predictions are off by $X on average\" |\n",
        "| RMSE | Root mean squared error | \"Typical error, but big misses hurt more\" |\n",
        "| RÂ² | Variance explained | \"Our model explains X% of why customers differ in spend\" |\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Try the **Debug Drill** to find bugs in regression models\n",
        "- Review the **Cheatsheet** for quick reference\n",
        "- Take the **Quiz** to test your understanding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "# FINAL SELF-CHECK: Did you complete everything?\n",
        "# ============================================\n",
        "print(\"Lab Completion Checklist:\")\n",
        "print(f\"  [âœ“] Loaded data: {len(df):,} customers\")\n",
        "print(f\"  [âœ“] Baseline MAE: ${baseline_mae:.2f}\")\n",
        "print(f\"  [âœ“] Simple model RÂ²: {simple_r2:.3f}\")\n",
        "print(f\"  [âœ“] Multiple model RÂ²: {multi_r2:.3f}\")\n",
        "print(f\"  [âœ“] Model beats baseline: {multi_mae < baseline_mae}\")\n",
        "print(f\"  [ ] TODO: Coefficient interpretation filled in\")\n",
        "print(f\"  [ ] TODO: PM update written\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ Great work! Make sure to complete the TODO sections.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}