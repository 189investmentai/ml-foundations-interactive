{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”§ Debug Drill: The Suspiciously Perfect Model\n",
    "\n",
    "**Scenario:**\n",
    "Your colleague built a churn prediction model and is excited to show you the results.\n",
    "\n",
    "\"Look at this AUC!\" they say. \"It's almost perfect!\"\n",
    "\n",
    "**Your Task:**\n",
    "1. Run the notebook\n",
    "2. Find the bug (hint: why is performance SO good?)\n",
    "3. Fix it\n",
    "4. Write a 3-bullet postmortem\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_score\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/streamcart_customers.csv')\n",
    "except:\n",
    "    df = pd.read_csv('../../data/streamcart_customers.csv')\n",
    "\n",
    "print(f\"Loaded {len(df):,} customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COLLEAGUE'S CODE (CONTAINS BUG) =====\n",
    "\n",
    "# Feature engineering\n",
    "df['has_cancel_reason'] = df['cancel_reason'].notna().astype(int)\n",
    "df['days_until_churn'] = pd.to_datetime(df['churn_date']).sub(pd.to_datetime(df['snapshot_date'])).dt.days\n",
    "df['days_until_churn'] = df['days_until_churn'].fillna(999)  # Non-churners get 999\n",
    "\n",
    "# Select features\n",
    "features = [\n",
    "    'tenure_months',\n",
    "    'logins_last_30d',\n",
    "    'support_tickets_last_30d',\n",
    "    'has_cancel_reason',      # <-- Colleague added this\n",
    "    'days_until_churn'        # <-- And this\n",
    "]\n",
    "\n",
    "X = df[features].fillna(0)\n",
    "y = df['churn_30d']\n",
    "\n",
    "# Split and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Amazing results!\")\n",
    "print(f\"AUC: {auc:.3f}\")\n",
    "print(f\"\\nThis model is ready for production, right?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Your Investigation\n",
    "\n",
    "Something is wrong. An AUC this high is suspicious.\n",
    "\n",
    "### Step 1: What's the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Investigate the features\n",
    "# Hint: For each feature, ask \"Would I have this at prediction time?\"\n",
    "\n",
    "# Check the suspicious features:\n",
    "print(\"=== Investigating has_cancel_reason ===\")\n",
    "print(df.groupby('churn_30d')['has_cancel_reason'].mean())\n",
    "\n",
    "print(\"\\n=== Investigating days_until_churn ===\")\n",
    "print(df.groupby('churn_30d')['days_until_churn'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you notice? Write your diagnosis:\n",
    "\n",
    "diagnosis = \"\"\"\n",
    "YOUR DIAGNOSIS HERE:\n",
    "\n",
    "The problem is...\n",
    "\n",
    "This is called...\n",
    "\n",
    "\"\"\"\n",
    "print(diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fix the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix the feature selection - remove leaky features\n",
    "\n",
    "features_fixed = [\n",
    "    # List only non-leaky features here\n",
    "]\n",
    "\n",
    "# Retrain with fixed features\n",
    "# X_fixed = ...\n",
    "# model_fixed = ...\n",
    "# auc_fixed = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK: Did you fix it?\n",
    "# ============================================\n",
    "\n",
    "# A properly trained model should have AUC between 0.60 and 0.85\n",
    "# NOT above 0.95!\n",
    "\n",
    "# assert auc_fixed < 0.90, \"AUC still too high - check for remaining leakage!\"\n",
    "# assert auc_fixed > 0.55, \"AUC too low - did you remove good features by mistake?\"\n",
    "# print(f\"âœ“ Fixed AUC: {auc_fixed:.3f} - This looks realistic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write your postmortem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postmortem = \"\"\"\n",
    "## Postmortem: Churn Model Leakage Bug\n",
    "\n",
    "### What happened:\n",
    "- (Your answer)\n",
    "\n",
    "### Root cause:\n",
    "- (Your answer)\n",
    "\n",
    "### How to prevent:\n",
    "- (Your answer)\n",
    "\"\"\"\n",
    "\n",
    "print(postmortem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Drill Complete!\n",
    "\n",
    "**Key lesson:** If your model performance seems too good to be true, it probably is. Always ask \"Would I have this data at prediction time?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
