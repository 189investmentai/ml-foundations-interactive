{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Is This Even an ML Problem?\n",
    "\n",
    "**Goal:** Learn to frame ML problems correctly and avoid the most common mistake (data leakage)\n",
    "\n",
    "**Time:** ~20 minutes\n",
    "\n",
    "**What you'll do:**\n",
    "1. Explore the StreamCart dataset\n",
    "2. Practice the 7-line framing template\n",
    "3. Identify data leakage in features\n",
    "4. Define a proper churn label\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell to load the data. No installation needed‚Äîjust pandas and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load StreamCart customer data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/data/streamcart_customers.csv')\n",
    "\n",
    "print(f\"Loaded {len(df):,} customers\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Explore the Data\n",
    "\n",
    "Before building any model, understand what you're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's in this dataset?\n",
    "print(\"=== Column Types ===\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n=== Basic Stats ===\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target variable: churn_30d\n",
    "print(\"=== Churn Distribution ===\")\n",
    "print(df['churn_30d'].value_counts())\n",
    "print(f\"\\nChurn rate: {df['churn_30d'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Check\n",
    "\n",
    "**Question:** About what percentage of customers churned in the next 30 days?\n",
    "\n",
    "This is your **baseline**. A model that predicts \"no churn\" for everyone would be right ~89% of the time. But that's useless for the business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: The 7-Line Framing Template\n",
    "\n",
    "Before writing any model code, fill out this template. If you can't, you're not ready to build.\n",
    "\n",
    "| Line | Question | Your Answer |\n",
    "|------|----------|-------------|\n",
    "| 1. Problem | What business outcome are we trying to improve? | |\n",
    "| 2. Action | What will we DO with the prediction? | |\n",
    "| 3. Prediction | What exactly does the model output? | |\n",
    "| 4. Label | How do we define this in historical data? | |\n",
    "| 5. Features | What info is available at prediction time? | |\n",
    "| 6. Metric | How do we measure if the model helps? | |\n",
    "| 7. Constraints | What limits exist in production? | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill out the framing for StreamCart's churn problem\n",
    "#\n",
    "# Context: StreamCart's retention team can call 500 customers per week.\n",
    "# They want to prioritize customers most likely to cancel.\n",
    "\n",
    "problem_framing = {\n",
    "    \"problem\": \"????\",      # What business metric are we improving?\n",
    "    \"action\": \"????\",       # What will the retention team DO?\n",
    "    \"prediction\": \"????\",   # What does the model output? (probability? score? yes/no?)\n",
    "    \"label\": \"????\",        # How is churn defined in the data?\n",
    "    \"features\": \"????\",     # List 3-5 features that would be available\n",
    "    \"metric\": \"????\",       # How do we know if the model is good? (hint: 500/week capacity)\n",
    "    \"constraints\": \"????\"   # Any production limits?\n",
    "}\n",
    "\n",
    "# Uncomment to see your answers:\n",
    "# for k, v in problem_framing.items():\n",
    "#     print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK: Run this to validate your framing\n",
    "# ============================================\n",
    "\n",
    "def check_framing(framing):\n",
    "    errors = []\n",
    "    \n",
    "    # Check problem\n",
    "    if 'churn' not in framing['problem'].lower() and 'cancel' not in framing['problem'].lower() and 'retain' not in framing['problem'].lower():\n",
    "        errors.append(\"Problem should mention churn, cancellation, or retention\")\n",
    "    \n",
    "    # Check action\n",
    "    if framing['action'] == \"????\" or len(framing['action']) < 10:\n",
    "        errors.append(\"Action should describe what the team will DO with predictions\")\n",
    "    \n",
    "    # Check metric mentions capacity\n",
    "    if '500' not in framing['metric'] and 'precision' not in framing['metric'].lower() and 'top' not in framing['metric'].lower():\n",
    "        errors.append(\"Metric should account for the 500/week capacity (hint: precision@500)\")\n",
    "    \n",
    "    # Check features don't include leakage\n",
    "    leaky_terms = ['cancel_reason', 'churn_date', 'cancel_date']\n",
    "    for term in leaky_terms:\n",
    "        if term in framing['features'].lower():\n",
    "            errors.append(f\"'{term}' is leakage! It only exists AFTER someone churns.\")\n",
    "    \n",
    "    if errors:\n",
    "        print(\"‚ùå Issues found:\")\n",
    "        for e in errors:\n",
    "            print(f\"   - {e}\")\n",
    "    else:\n",
    "        print(\"‚úì Framing looks good!\")\n",
    "    \n",
    "    return len(errors) == 0\n",
    "\n",
    "check_framing(problem_framing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Spotting Data Leakage\n",
    "\n",
    "This is the **#1 mistake** in applied ML. Leakage means using information that wouldn't be available at prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at all columns\n",
    "print(\"=== All Columns ===\")\n",
    "for col in df.columns:\n",
    "    print(f\"  {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Which columns would cause DATA LEAKAGE if used as features?\n",
    "#\n",
    "# Remember: At prediction time (snapshot_date), we're predicting if they'll\n",
    "# churn in the NEXT 30 days. Any info that only exists AFTER they churn is leakage.\n",
    "\n",
    "leaky_columns = [\n",
    "    # \"???\",  # List columns that would leak\n",
    "    # \"???\",\n",
    "]\n",
    "\n",
    "safe_columns = [\n",
    "    # \"???\",  # List columns that are safe to use\n",
    "    # \"???\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK: Verify your leakage detection\n",
    "# ============================================\n",
    "\n",
    "KNOWN_LEAKY = {'churn_30d', 'churn_date', 'cancel_reason'}\n",
    "KNOWN_SAFE = {'tenure_months', 'logins_last_7d', 'logins_last_30d', \n",
    "              'support_tickets_last_30d', 'items_skipped_last_3_boxes',\n",
    "              'nps_score', 'plan_type', 'avg_order_value'}\n",
    "\n",
    "your_leaky = set(leaky_columns)\n",
    "your_safe = set(safe_columns)\n",
    "\n",
    "# Check leaky\n",
    "if KNOWN_LEAKY.issubset(your_leaky):\n",
    "    print(\"‚úì Correctly identified leaky columns!\")\n",
    "else:\n",
    "    missing = KNOWN_LEAKY - your_leaky\n",
    "    print(f\"‚ùå Missed leaky columns: {missing}\")\n",
    "    print(\"   Hint: These only exist AFTER someone churns\")\n",
    "\n",
    "# Check safe\n",
    "if len(your_safe) >= 5:\n",
    "    print(f\"‚úì Identified {len(your_safe)} safe features\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Only {len(your_safe)} safe features. Look for behavioral features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Why Leakage Is Dangerous\n",
    "\n",
    "Let's see what happens if you accidentally use a leaky feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Split data\n",
    "X = df[['tenure_months', 'logins_last_30d', 'support_tickets_last_30d']].fillna(0)\n",
    "y = df['churn_30d']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model (no leakage)\n",
    "model_clean = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)\n",
    "model_clean.fit(X_train, y_train)\n",
    "\n",
    "clean_auc = roc_auc_score(y_test, model_clean.predict_proba(X_test)[:, 1])\n",
    "print(f\"AUC without leakage: {clean_auc:.3f}\")\n",
    "print(\"This is realistic performance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's \"accidentally\" include a leaky feature\n",
    "# cancel_reason is encoded (it only exists for churners!)\n",
    "\n",
    "df['has_cancel_reason'] = df['cancel_reason'].notna().astype(int)\n",
    "\n",
    "X_leaky = df[['tenure_months', 'logins_last_30d', 'support_tickets_last_30d', 'has_cancel_reason']].fillna(0)\n",
    "\n",
    "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(X_leaky, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_leaky = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)\n",
    "model_leaky.fit(X_train_l, y_train_l)\n",
    "\n",
    "leaky_auc = roc_auc_score(y_test_l, model_leaky.predict_proba(X_test_l)[:, 1])\n",
    "print(f\"AUC with leakage: {leaky_auc:.3f}\")\n",
    "print(\"\\n‚ö†Ô∏è  This is suspiciously perfect! The model is 'cheating'.\")\n",
    "print(\"   In production, has_cancel_reason would always be 0 (they haven't canceled yet).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Lesson\n",
    "\n",
    "If your AUC is above 0.95, **be suspicious**. Real-world churn models typically achieve 0.70-0.85.\n",
    "\n",
    "A model with leakage will:\n",
    "- Look amazing in development\n",
    "- Fail completely in production\n",
    "- Waste months of work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Defining the Label Properly\n",
    "\n",
    "The label `churn_30d` is already defined. But let's understand what goes into defining it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's in our label?\n",
    "print(\"snapshot_date:\", df['snapshot_date'].iloc[0])\n",
    "print(\"\\nFor churners:\")\n",
    "churners = df[df['churn_30d'] == 1][['customer_id', 'snapshot_date', 'churn_date']].head(5)\n",
    "print(churners)\n",
    "\n",
    "print(\"\\nFor non-churners:\")\n",
    "stayers = df[df['churn_30d'] == 0][['customer_id', 'snapshot_date', 'churn_date']].head(5)\n",
    "print(stayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: If you had to define churn_30d from raw data, how would you do it?\n",
    "#\n",
    "# Complete this function:\n",
    "\n",
    "def define_churn_label(df, snapshot_date, window_days=30):\n",
    "    \"\"\"\n",
    "    Define churn label: Did the customer cancel within window_days after snapshot_date?\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame with 'cancel_date' column (or None if still active)\n",
    "    snapshot_date : The point-in-time we're predicting FROM\n",
    "    window_days : How many days to look forward\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Series with 1 (churned) or 0 (stayed)\n",
    "    \"\"\"\n",
    "    # TODO: Implement this\n",
    "    # Hint: churn = 1 if cancel_date is between snapshot_date and snapshot_date + window_days\n",
    "    \n",
    "    pass  # Replace with your implementation\n",
    "\n",
    "# Test your function:\n",
    "# my_labels = define_churn_label(df, '2024-01-15', 30)\n",
    "# print(f\"My label matches: {(my_labels == df['churn_30d']).mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Final Exercise: Explain It\n",
    "\n",
    "Your VP asks: \"Why can't we just predict churn using their subscription status?\"\n",
    "\n",
    "Write a 3-4 sentence response explaining why that's circular reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your response here (as a comment or string):\n",
    "\n",
    "vp_response = \"\"\"\n",
    "YOUR RESPONSE HERE\n",
    "\"\"\"\n",
    "\n",
    "print(vp_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Module 1 Complete!\n",
    "\n",
    "**What you learned:**\n",
    "- The 7-line framing template\n",
    "- How to identify data leakage\n",
    "- Why leakage creates fake performance\n",
    "- How to define labels properly\n",
    "\n",
    "**Key takeaway:** The most important ML skill isn't coding‚Äîit's asking \"Would I have this data at prediction time?\"\n",
    "\n",
    "**Next:** [Module 2: Your First Prediction Model ‚Üí](./module_02_logistic_regression.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
