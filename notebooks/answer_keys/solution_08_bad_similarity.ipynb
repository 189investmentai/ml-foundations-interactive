{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANSWER KEY: Debug Drill 08 - Bad Similarity Search\n",
    "\n",
    "**Bugs:**\n",
    "1. Using `CountVectorizer` instead of `TfidfVectorizer` (no term weighting)\n",
    "2. Using `euclidean_distances` instead of `cosine_similarity` (affected by document length)\n",
    "\n",
    "**Key Lesson:** For text similarity, use TF-IDF + cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sample support tickets\n",
    "tickets = pd.DataFrame({\n",
    "    'ticket_id': range(1, 11),\n",
    "    'ticket_text': [\n",
    "        \"I want a refund for my order\",\n",
    "        \"How do I return this product and get my money back\",\n",
    "        \"Package never arrived, very frustrated\",\n",
    "        \"Where is my order? Still waiting for delivery\",\n",
    "        \"Can I change my shipping address please\",\n",
    "        \"Need to update my billing information\",\n",
    "        \"Product arrived damaged, want replacement\",\n",
    "        \"How to cancel my subscription\",\n",
    "        \"Charged twice for same order, need refund\",\n",
    "        \"Great product, just wanted to say thanks\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bug (Colleague's Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== BUGGY CODE =====\n",
    "\n",
    "# Bug 1: Using CountVectorizer (no weighting)\n",
    "vectorizer_buggy = CountVectorizer(max_features=100)\n",
    "ticket_vectors_buggy = vectorizer_buggy.fit_transform(tickets['ticket_text'])\n",
    "\n",
    "# Bug 2: Using Euclidean distance (affected by length)\n",
    "query = \"I need my money back\"\n",
    "query_vector_buggy = vectorizer_buggy.transform([query])\n",
    "\n",
    "distances = euclidean_distances(query_vector_buggy, ticket_vectors_buggy)[0]\n",
    "most_similar_idx = np.argmin(distances)  # Smallest distance = most similar\n",
    "\n",
    "print(\"Buggy search for: 'I need my money back'\")\n",
    "print(f\"\\nBest match (Euclidean): {tickets.iloc[most_similar_idx]['ticket_text']}\")\n",
    "print(f\"\\nTop 3 matches:\")\n",
    "for idx in np.argsort(distances)[:3]:\n",
    "    print(f\"  {distances[idx]:.2f}: {tickets.iloc[idx]['ticket_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why This Is Wrong\n",
    "\n",
    "**Problem 1: CountVectorizer**\n",
    "- Just counts word occurrences\n",
    "- Common words like \"the\", \"I\", \"my\" have same weight as important words\n",
    "- Doesn't capture term importance\n",
    "\n",
    "**Problem 2: Euclidean Distance**\n",
    "- Affected by document LENGTH\n",
    "- Longer documents have larger vectors â†’ larger distances\n",
    "- A short document might appear \"similar\" just because it's short\n",
    "\n",
    "**Why TF-IDF + Cosine works:**\n",
    "- TF-IDF downweights common words, highlights distinctive terms\n",
    "- Cosine measures ANGLE between vectors, not magnitude\n",
    "- Two documents about \"refunds\" point in the same direction regardless of length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FIXED CODE =====\n",
    "\n",
    "# Fix 1: Use TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=500,\n",
    "    stop_words='english',  # Remove common words\n",
    "    ngram_range=(1, 2)     # Include bigrams like \"money back\"\n",
    ")\n",
    "ticket_vectors_fixed = tfidf.fit_transform(tickets['ticket_text'])\n",
    "\n",
    "# Fix 2: Use cosine_similarity\n",
    "query = \"I need my money back\"\n",
    "query_vector_fixed = tfidf.transform([query])\n",
    "\n",
    "similarities = cosine_similarity(query_vector_fixed, ticket_vectors_fixed)[0]\n",
    "most_similar_idx = np.argmax(similarities)  # Highest similarity = best match\n",
    "\n",
    "print(\"Fixed search for: 'I need my money back'\")\n",
    "print(f\"\\nBest match (Cosine): {tickets.iloc[most_similar_idx]['ticket_text']}\")\n",
    "print(f\"\\nTop 3 matches:\")\n",
    "for idx in np.argsort(similarities)[::-1][:3]:\n",
    "    print(f\"  {similarities[idx]:.3f}: {tickets.iloc[idx]['ticket_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results side by side\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: Buggy vs Fixed\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "queries = [\n",
    "    \"I need my money back\",\n",
    "    \"package not delivered\",\n",
    "    \"cancel my account\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    # Buggy\n",
    "    q_buggy = vectorizer_buggy.transform([q])\n",
    "    dist = euclidean_distances(q_buggy, ticket_vectors_buggy)[0]\n",
    "    buggy_match = tickets.iloc[np.argmin(dist)]['ticket_text']\n",
    "    \n",
    "    # Fixed\n",
    "    q_fixed = tfidf.transform([q])\n",
    "    sim = cosine_similarity(q_fixed, ticket_vectors_fixed)[0]\n",
    "    fixed_match = tickets.iloc[np.argmax(sim)]['ticket_text']\n",
    "    \n",
    "    print(f\"\\nQuery: '{q}'\")\n",
    "    print(f\"  Buggy: {buggy_match[:50]}...\")\n",
    "    print(f\"  Fixed: {fixed_match[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what TF-IDF learned\n",
    "print(\"\\nTop terms by TF-IDF weight (for 'refund' ticket):\")\n",
    "refund_vec = tfidf.transform([\"I want a refund for my order\"])\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "weights = refund_vec.toarray()[0]\n",
    "top_indices = np.argsort(weights)[::-1][:5]\n",
    "for idx in top_indices:\n",
    "    if weights[idx] > 0:\n",
    "        print(f\"  {feature_names[idx]}: {weights[idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-check\n",
    "# Query about refund should match refund-related tickets\n",
    "q_test = tfidf.transform([\"refund money back\"])\n",
    "sim_test = cosine_similarity(q_test, ticket_vectors_fixed)[0]\n",
    "best_match = tickets.iloc[np.argmax(sim_test)]['ticket_text'].lower()\n",
    "\n",
    "assert 'refund' in best_match or 'money back' in best_match, \"Should match refund ticket\"\n",
    "print(\"\\nPASS: Similarity search returns semantically relevant results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Reference\n",
    "\n",
    "| Component | Wrong | Right | Why |\n",
    "|-----------|-------|-------|-----|\n",
    "| Vectorizer | CountVectorizer | TfidfVectorizer | TF-IDF weights by importance |\n",
    "| Distance | Euclidean | Cosine Similarity | Cosine ignores document length |\n",
    "| Preprocessing | None | stop_words='english' | Remove noise words |\n",
    "| N-grams | (1,1) only | (1,2) | Capture phrases like \"money back\" |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completed Postmortem\n",
    "\n",
    "### What happened:\n",
    "- Colleague's similarity search returned irrelevant tickets\n",
    "- \"I need my money back\" was matching unrelated tickets instead of refund requests\n",
    "\n",
    "### Root cause:\n",
    "- CountVectorizer doesn't weight terms by importance (\"the\" = \"refund\")\n",
    "- Euclidean distance is biased by document length, not semantic content\n",
    "\n",
    "### How to prevent:\n",
    "- Default to TF-IDF + Cosine for text similarity\n",
    "- Test with known similar pairs to validate search quality\n",
    "- Use stop_words and ngrams for better matching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
