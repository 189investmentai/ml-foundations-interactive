{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANSWER KEY: Debug Drill 09 - Hallucination Detection\n",
    "\n",
    "**Bug:** LLM chatbot confidently states incorrect information (\"90-day return policy\" when actual is 30 days).\n",
    "\n",
    "**Key Lesson:** LLMs hallucinate. Ground responses in a knowledge base and add verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, Tuple, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bug (Colleague's Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== BUGGY CODE =====\n",
    "# Colleague's chatbot with NO fact-checking\n",
    "\n",
    "def buggy_chatbot(question: str) -> str:\n",
    "    \"\"\"Simulates an LLM response without verification.\"\"\"\n",
    "    # These are simulated LLM responses (which may hallucinate)\n",
    "    responses = {\n",
    "        \"return policy\": \"Our return policy allows returns within 90 days of purchase.\",  # WRONG! Actual is 30 days\n",
    "        \"shipping time\": \"Orders typically arrive within 1-2 business days.\",  # WRONG! Actual is 3-5 days\n",
    "        \"price match\": \"We offer a 200% price match guarantee!\",  # WRONG! We don't offer this\n",
    "    }\n",
    "    \n",
    "    for topic, response in responses.items():\n",
    "        if topic in question.lower():\n",
    "            return response\n",
    "    \n",
    "    return \"I'm not sure about that. Let me connect you with support.\"\n",
    "\n",
    "# Test the buggy chatbot\n",
    "print(\"Buggy chatbot responses:\")\n",
    "print(f\"Q: What is your return policy?\")\n",
    "print(f\"A: {buggy_chatbot('return policy')}\")\n",
    "print(f\"\\nThis is WRONG! The actual return policy is 30 days, not 90!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why This Is Wrong\n",
    "\n",
    "**LLMs hallucinate because:**\n",
    "1. They generate plausible-sounding text, not verified facts\n",
    "2. They don't \"know\" your specific business policies\n",
    "3. They may have seen similar policies during training and mix them up\n",
    "\n",
    "**Business impact:**\n",
    "- Customer expects 90-day return → actually gets 30 days → bad experience\n",
    "- Company might be legally liable for incorrect claims\n",
    "- Trust in the chatbot (and brand) erodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fix: Grounding + Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FIXED CODE =====\n",
    "\n",
    "# Step 1: Define the AUTHORITATIVE knowledge base\n",
    "KNOWLEDGE_BASE = {\n",
    "    \"return_policy\": {\n",
    "        \"text\": \"We offer a 30-day return window for all products in original condition.\",\n",
    "        \"numbers\": [30],\n",
    "        \"keywords\": [\"return\", \"refund\", \"days\"]\n",
    "    },\n",
    "    \"shipping\": {\n",
    "        \"text\": \"Standard shipping takes 3-5 business days. Express shipping is 1-2 days.\",\n",
    "        \"numbers\": [3, 5, 1, 2],\n",
    "        \"keywords\": [\"shipping\", \"delivery\", \"days\"]\n",
    "    },\n",
    "    \"price_match\": {\n",
    "        \"text\": \"We do not offer price matching. Our prices are final.\",\n",
    "        \"numbers\": [],\n",
    "        \"keywords\": [\"price\", \"match\", \"guarantee\"]\n",
    "    },\n",
    "    \"warranty\": {\n",
    "        \"text\": \"All electronics come with a 1-year manufacturer warranty.\",\n",
    "        \"numbers\": [1],\n",
    "        \"keywords\": [\"warranty\", \"year\", \"guarantee\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Knowledge Base loaded with\", len(KNOWLEDGE_BASE), \"topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create hallucination detector\n",
    "\n",
    "def detect_hallucination(response: str, topic: str) -> Tuple[bool, float, List[str]]:\n",
    "    \"\"\"\n",
    "    Check if a response contains potential hallucinations.\n",
    "    Returns: (is_safe, confidence, issues)\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    confidence = 1.0\n",
    "    \n",
    "    if topic not in KNOWLEDGE_BASE:\n",
    "        return False, 0.0, [\"Topic not in knowledge base\"]\n",
    "    \n",
    "    kb_entry = KNOWLEDGE_BASE[topic]\n",
    "    kb_text = kb_entry[\"text\"].lower()\n",
    "    kb_numbers = kb_entry[\"numbers\"]\n",
    "    response_lower = response.lower()\n",
    "    \n",
    "    # Check 1: Number verification\n",
    "    response_numbers = [int(n) for n in re.findall(r'\\b(\\d+)\\b', response)]\n",
    "    for num in response_numbers:\n",
    "        if num not in kb_numbers and num > 0:\n",
    "            # Allow for small variations, but flag significant differences\n",
    "            if not any(abs(num - kb_num) <= 1 for kb_num in kb_numbers):\n",
    "                issues.append(f\"Number {num} not in knowledge base (expected: {kb_numbers})\")\n",
    "                confidence -= 0.3\n",
    "    \n",
    "    # Check 2: Superlative claims (often hallucinated)\n",
    "    superlatives = [\"best\", \"guaranteed\", \"always\", \"never\", \"100%\", \"unlimited\"]\n",
    "    for sup in superlatives:\n",
    "        if sup in response_lower and sup not in kb_text:\n",
    "            issues.append(f\"Superlative '{sup}' not supported by knowledge base\")\n",
    "            confidence -= 0.2\n",
    "    \n",
    "    # Check 3: Contradiction detection\n",
    "    negation_pairs = [\n",
    "        (\"do not offer\", \"offer\"),\n",
    "        (\"no \", \"yes\"),\n",
    "    ]\n",
    "    for neg, pos in negation_pairs:\n",
    "        if neg in kb_text and pos in response_lower and neg not in response_lower:\n",
    "            issues.append(f\"Response may contradict knowledge base\")\n",
    "            confidence -= 0.4\n",
    "    \n",
    "    is_safe = confidence >= 0.7 and len(issues) == 0\n",
    "    return is_safe, max(0, confidence), issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create safe response function\n",
    "\n",
    "def get_safe_response(question: str, llm_response: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Verify LLM response against knowledge base.\n",
    "    Fall back to KB if hallucination detected.\n",
    "    \"\"\"\n",
    "    # Determine topic from question\n",
    "    topic = None\n",
    "    question_lower = question.lower()\n",
    "    \n",
    "    for kb_topic, entry in KNOWLEDGE_BASE.items():\n",
    "        if any(kw in question_lower for kw in entry[\"keywords\"]):\n",
    "            topic = kb_topic\n",
    "            break\n",
    "    \n",
    "    if topic is None:\n",
    "        return {\n",
    "            \"response\": \"I'm not sure about that. Let me connect you with support.\",\n",
    "            \"source\": \"fallback\",\n",
    "            \"verified\": False\n",
    "        }\n",
    "    \n",
    "    # Check for hallucinations\n",
    "    is_safe, confidence, issues = detect_hallucination(llm_response, topic)\n",
    "    \n",
    "    if is_safe:\n",
    "        return {\n",
    "            \"response\": llm_response,\n",
    "            \"source\": \"llm_verified\",\n",
    "            \"verified\": True,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "    else:\n",
    "        # Fall back to knowledge base\n",
    "        return {\n",
    "            \"response\": KNOWLEDGE_BASE[topic][\"text\"],\n",
    "            \"source\": \"knowledge_base\",\n",
    "            \"verified\": True,\n",
    "            \"issues_detected\": issues,\n",
    "            \"original_response\": llm_response\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fixed system\n",
    "print(\"=\"*60)\n",
    "print(\"FIXED CHATBOT WITH HALLUCINATION DETECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_cases = [\n",
    "    (\"What is your return policy?\", \"Our return policy allows returns within 90 days.\"),  # Hallucination!\n",
    "    (\"How long does shipping take?\", \"Shipping takes 3-5 business days.\"),  # Correct\n",
    "    (\"Do you price match?\", \"Yes, we offer a 200% price match guarantee!\"),  # Hallucination!\n",
    "]\n",
    "\n",
    "for question, llm_response in test_cases:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(f\"LLM said: {llm_response}\")\n",
    "    \n",
    "    result = get_safe_response(question, llm_response)\n",
    "    print(f\"Safe response: {result['response']}\")\n",
    "    print(f\"Source: {result['source']}\")\n",
    "    if 'issues_detected' in result:\n",
    "        print(f\"Issues caught: {result['issues_detected']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-check\n",
    "# Verify hallucination was caught\n",
    "result = get_safe_response(\"return policy\", \"90 day returns\")\n",
    "assert result['source'] == 'knowledge_base', \"Should fall back to KB for hallucination\"\n",
    "assert '30' in result['response'], \"Should return correct 30-day policy\"\n",
    "\n",
    "print(\"\\nPASS: Hallucination detection working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hallucination Prevention Strategies\n",
    "\n",
    "| Strategy | How It Works | When to Use |\n",
    "|----------|--------------|-------------|\n",
    "| RAG | Retrieve docs before generating | Factual Q&A |\n",
    "| Knowledge Base Fallback | Verify against KB, fallback if wrong | Policy questions |\n",
    "| Number Verification | Check numbers against source | Financial, dates |\n",
    "| Confidence Scoring | Only surface high-confidence responses | All production use |\n",
    "| Human Escalation | Route uncertain responses to humans | High-stakes queries |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completed Postmortem\n",
    "\n",
    "### What happened:\n",
    "- Chatbot confidently stated \"90-day return policy\" when actual policy is 30 days\n",
    "- Customers received incorrect information, damaging trust\n",
    "\n",
    "### Root cause:\n",
    "- LLM generates plausible text without access to actual business facts\n",
    "- No verification layer between LLM output and customer\n",
    "\n",
    "### How to prevent:\n",
    "- Always ground LLM responses in authoritative knowledge base\n",
    "- Implement verification checks (numbers, contradictions, superlatives)\n",
    "- Fall back to KB when hallucination detected\n",
    "- Log and review flagged responses for continuous improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
