{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8: Similarity and Embeddings\n",
    "\n",
    "**Goal:** Turn text into numbers that capture meaning\n",
    "\n",
    "**Time:** ~20 minutes\n",
    "\n",
    "**What you'll do:**\n",
    "1. Create TF-IDF embeddings from support tickets\n",
    "2. Find similar tickets using cosine similarity\n",
    "3. Build a simple semantic search\n",
    "4. Understand neural embeddings (preview)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load support tickets\n",
    "tickets = pd.read_csv('https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/data/streamcart_tickets.csv')\n",
    "\n",
    "print(f\"Loaded {len(tickets):,} support tickets\")\n",
    "tickets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some examples\n",
    "print(\"=== Sample Tickets ===\")\n",
    "for i, row in tickets.sample(5, random_state=42).iterrows():\n",
    "    print(f\"[{row['category']}] {row['ticket_text']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: TF-IDF Embeddings\n",
    "\n",
    "Turn text into vectors where each dimension = importance of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=500,      # Keep top 500 words\n",
    "    stop_words='english',  # Remove common words\n",
    "    ngram_range=(1, 2)     # Include 2-word phrases\n",
    ")\n",
    "\n",
    "# Transform tickets to vectors\n",
    "ticket_vectors = tfidf.fit_transform(tickets['ticket_text'])\n",
    "\n",
    "print(f\"Original: {len(tickets)} tickets with variable-length text\")\n",
    "print(f\"After TF-IDF: {ticket_vectors.shape[0]} tickets Ã— {ticket_vectors.shape[1]} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at what TF-IDF learned\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Top words\n",
    "word_importance = np.array(ticket_vectors.sum(axis=0)).flatten()\n",
    "top_indices = word_importance.argsort()[-20:]\n",
    "\n",
    "print(\"=== Most Important Terms ===\")\n",
    "for idx in reversed(top_indices):\n",
    "    print(f\"  {feature_names[idx]}: {word_importance[idx]:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Finding Similar Tickets\n",
    "\n",
    "Cosine similarity: how much do two vectors point in the same direction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a query ticket\n",
    "query_idx = 0\n",
    "query_text = tickets.iloc[query_idx]['ticket_text']\n",
    "query_vector = ticket_vectors[query_idx]\n",
    "\n",
    "print(f\"Query ticket: '{query_text}'\")\n",
    "print(f\"Category: {tickets.iloc[query_idx]['category']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find 5 most similar tickets\n",
    "#\n",
    "# Steps:\n",
    "# 1. Calculate cosine similarity between query and all tickets\n",
    "# 2. Sort by similarity (descending)\n",
    "# 3. Return top 5 (excluding the query itself)\n",
    "\n",
    "similarities = None  # Replace with your code\n",
    "\n",
    "# Uncomment when ready:\n",
    "# similarities = cosine_similarity(query_vector, ticket_vectors)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK\n",
    "# ============================================\n",
    "\n",
    "assert similarities is not None, \"Calculate similarities first!\"\n",
    "assert len(similarities) == len(tickets), \"Should have one score per ticket\"\n",
    "\n",
    "# Get top 5 similar (excluding query)\n",
    "top_indices = similarities.argsort()[::-1][1:6]\n",
    "\n",
    "print(f\"=== Top 5 Similar Tickets ===\")\n",
    "print(f\"Query: '{query_text}'\\n\")\n",
    "\n",
    "for i, idx in enumerate(top_indices, 1):\n",
    "    print(f\"{i}. [{tickets.iloc[idx]['category']}] {tickets.iloc[idx]['ticket_text']}\")\n",
    "    print(f\"   Similarity: {similarities[idx]:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Semantic Search\n",
    "\n",
    "Search tickets using natural language queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tickets(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Search tickets using a natural language query.\n",
    "    \"\"\"\n",
    "    # Convert query to vector (using same TF-IDF)\n",
    "    query_vec = tfidf.transform([query])\n",
    "    \n",
    "    # Calculate similarities\n",
    "    sims = cosine_similarity(query_vec, ticket_vectors)[0]\n",
    "    \n",
    "    # Get top results\n",
    "    top_idx = sims.argsort()[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_idx:\n",
    "        results.append({\n",
    "            'text': tickets.iloc[idx]['ticket_text'],\n",
    "            'category': tickets.iloc[idx]['category'],\n",
    "            'similarity': sims[idx]\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some searches\n",
    "queries = [\n",
    "    \"refund my money\",\n",
    "    \"package not delivered\",\n",
    "    \"cancel subscription\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\n=== Query: '{q}' ===\")\n",
    "    results = search_tickets(q, top_k=3)\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"{i}. [{r['category']}] {r['text']} (sim: {r['similarity']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Limitations of TF-IDF\n",
    "\n",
    "TF-IDF only matches exact words. It misses semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Does TF-IDF understand synonyms?\n",
    "test_queries = [\n",
    "    (\"I want a refund\", \"Give me my money back\"),\n",
    "    (\"shipping problem\", \"delivery issue\"),\n",
    "    (\"help with login\", \"can't access my account\")\n",
    "]\n",
    "\n",
    "print(\"=== TF-IDF Synonym Test ===\")\n",
    "print(\"(High similarity = understands they mean the same thing)\\n\")\n",
    "\n",
    "for q1, q2 in test_queries:\n",
    "    v1 = tfidf.transform([q1])\n",
    "    v2 = tfidf.transform([q2])\n",
    "    sim = cosine_similarity(v1, v2)[0][0]\n",
    "    print(f\"'{q1}' â†” '{q2}'\")\n",
    "    print(f\"  Similarity: {sim:.2f}\")\n",
    "    print(f\"  {('âœ“ Understood' if sim > 0.3 else 'âœ— Missed connection')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem\n",
    "\n",
    "TF-IDF doesn't understand that \"refund\" and \"money back\" mean the same thing. For that, we need **neural embeddings**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Preview - Neural Embeddings\n",
    "\n",
    "Modern embeddings (BERT, sentence-transformers) capture meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This requires sentence-transformers (optional install)\n",
    "# !pip install sentence-transformers -q\n",
    "\n",
    "neural_preview = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  METHOD              â”‚  HOW IT WORKS                â”‚  BEST FOR             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  TF-IDF              â”‚  Word frequency counts       â”‚  Exact keyword match  â”‚\n",
    "â”‚                      â”‚  Fast, interpretable         â”‚  Known search terms   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Word2Vec/GloVe      â”‚  Average word vectors        â”‚  Short text           â”‚\n",
    "â”‚                      â”‚  Captures some meaning       â”‚  Limited context      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Sentence-BERT       â”‚  Full sentence context       â”‚  Semantic search      â”‚\n",
    "â”‚                      â”‚  Understands synonyms        â”‚  Question answering   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "ğŸ’¡ In practice: Start with TF-IDF. If semantic matching matters, upgrade to\n",
    "   sentence-transformers. The API is almost identical!\n",
    "\"\"\"\n",
    "print(neural_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Try neural embeddings (uncomment if sentence-transformers installed)\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# \n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')  # Fast, good quality\n",
    "# \n",
    "# # Same test with neural embeddings\n",
    "# print(\"=== Neural Embedding Synonym Test ===\")\n",
    "# for q1, q2 in test_queries:\n",
    "#     v1 = model.encode([q1])\n",
    "#     v2 = model.encode([q2])\n",
    "#     sim = cosine_similarity(v1, v2)[0][0]\n",
    "#     print(f\"'{q1}' â†” '{q2}': {sim:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Building a Ticket Classifier\n",
    "\n",
    "Use embeddings to auto-categorize new tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    ticket_vectors, tickets['category'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"=== Ticket Classifier Performance ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try classifying new tickets\n",
    "new_tickets = [\n",
    "    \"I want to cancel my account\",\n",
    "    \"Where is my package?\",\n",
    "    \"Please refund my credit card\"\n",
    "]\n",
    "\n",
    "new_vectors = tfidf.transform(new_tickets)\n",
    "predictions = clf.predict(new_vectors)\n",
    "\n",
    "print(\"=== New Ticket Predictions ===\")\n",
    "for ticket, pred in zip(new_tickets, predictions):\n",
    "    print(f\"'{ticket}' â†’ {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Final Exercise: Explain It\n",
    "\n",
    "The support team asks: \"How does the auto-categorization work? Is it just keyword matching?\"\n",
    "\n",
    "Write a 4-5 sentence response explaining embeddings in non-technical terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your response:\n",
    "\n",
    "support_response = \"\"\"\n",
    "YOUR RESPONSE HERE\n",
    "\"\"\"\n",
    "\n",
    "print(support_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Module 8 Complete!\n",
    "\n",
    "**What you learned:**\n",
    "- How TF-IDF converts text to vectors\n",
    "- How cosine similarity finds related content\n",
    "- How to build semantic search\n",
    "- Limitations of TF-IDF vs neural embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=== Module 8 Summary ===\")\n",
    "print(f\"\\nEmbedding dimensions: {ticket_vectors.shape[1]}\")\n",
    "print(f\"Vocabulary size: {len(tfidf.vocabulary_)}\")\n",
    "print(f\"Classifier accuracy: {(y_pred == y_test).mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next:** [Module 9: Understanding Transformers â†’](./module_09_transformers.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
