{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5: The Art of Feature Engineering\n",
    "\n",
    "**Goal:** Create features that capture what customers are actually doing\n",
    "\n",
    "**Time:** ~20 minutes\n",
    "\n",
    "**What you'll do:**\n",
    "1. Create behavioral features from raw events\n",
    "2. Engineer ratio and change features\n",
    "3. Add temporal features safely (no leakage!)\n",
    "4. Measure impact on model performance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/streamcart_customers.csv')\n",
    "except:\n",
    "    df = pd.read_csv('../data/streamcart_customers.csv')\n",
    "\n",
    "print(f\"Loaded {len(df):,} customers\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Start with Baseline\n",
    "\n",
    "First, let's establish performance with raw features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw features (what we've been using)\n",
    "raw_features = ['tenure_months', 'logins_last_7d', 'logins_last_30d',\n",
    "                'support_tickets_last_30d', 'items_skipped_last_3_boxes', 'nps_score']\n",
    "\n",
    "X_raw = df[raw_features].fillna(-1)\n",
    "y = df['churn_30d']\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_raw, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train baseline model\n",
    "baseline_model = lgb.LGBMClassifier(n_estimators=100, max_depth=5, random_state=42, verbose=-1)\n",
    "baseline_model.fit(X_train_raw, y_train)\n",
    "\n",
    "baseline_auc = roc_auc_score(y_test, baseline_model.predict_proba(X_test_raw)[:, 1])\n",
    "print(f\"Baseline AUC (raw features): {baseline_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Create Ratio Features\n",
    "\n",
    "Ratios often capture behavior better than raw counts.\n",
    "\n",
    "**Example:** \"3 orders\" means different things for a 1-month vs 24-month customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for feature engineering\n",
    "df_eng = df.copy()\n",
    "\n",
    "# TODO: Create these ratio features\n",
    "# \n",
    "# 1. orders_per_month: total orders divided by tenure\n",
    "# 2. support_ticket_rate: tickets per month of tenure\n",
    "# 3. login_consistency: logins_7d / logins_30d (recent vs month)\n",
    "\n",
    "# Handle division by zero with small epsilon\n",
    "eps = 0.1\n",
    "\n",
    "df_eng['orders_per_month'] = None  # Replace with your code\n",
    "df_eng['support_ticket_rate'] = None  # Replace with your code\n",
    "df_eng['login_consistency'] = None  # Replace with your code\n",
    "\n",
    "# Uncomment when ready:\n",
    "# df_eng['orders_per_month'] = df['orders_total'] / (df['tenure_months'] + eps)\n",
    "# df_eng['support_ticket_rate'] = df['support_tickets_total'] / (df['tenure_months'] + eps)\n",
    "# df_eng['login_consistency'] = df['logins_last_7d'] / (df['logins_last_30d'] + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK\n",
    "# ============================================\n",
    "\n",
    "assert df_eng['orders_per_month'].notna().all(), \"orders_per_month should have no NaN\"\n",
    "assert (df_eng['login_consistency'] >= 0).all(), \"login_consistency should be >= 0\"\n",
    "\n",
    "print(\"âœ“ Ratio features created!\")\n",
    "print(f\"\\norders_per_month range: [{df_eng['orders_per_month'].min():.2f}, {df_eng['orders_per_month'].max():.2f}]\")\n",
    "print(f\"login_consistency range: [{df_eng['login_consistency'].min():.2f}, {df_eng['login_consistency'].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Create Change Features\n",
    "\n",
    "Is the customer getting more or less engaged over time?\n",
    "\n",
    "**Idea:** Compare recent activity to historical average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create change features\n",
    "#\n",
    "# 1. login_trend: Are recent logins (7d) above or below their average?\n",
    "#    Formula: logins_7d - (logins_per_month_avg * 7/30)\n",
    "#\n",
    "# 2. recent_activity_drop: Binary flag for low recent activity\n",
    "#    Formula: 1 if logins_7d == 0 AND logins_30d > 0, else 0\n",
    "\n",
    "# Expected weekly logins based on monthly average\n",
    "df_eng['expected_weekly_logins'] = df['logins_per_month_avg'] * (7/30)\n",
    "\n",
    "df_eng['login_trend'] = None  # Replace with your code\n",
    "df_eng['recent_activity_drop'] = None  # Replace with your code\n",
    "\n",
    "# Uncomment when ready:\n",
    "# df_eng['login_trend'] = df['logins_last_7d'] - df_eng['expected_weekly_logins']\n",
    "# df_eng['recent_activity_drop'] = ((df['logins_last_7d'] == 0) & (df['logins_last_30d'] > 0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK\n",
    "# ============================================\n",
    "\n",
    "print(f\"login_trend distribution:\")\n",
    "print(f\"  Negative (declining): {(df_eng['login_trend'] < 0).mean():.1%}\")\n",
    "print(f\"  Positive (growing):   {(df_eng['login_trend'] > 0).mean():.1%}\")\n",
    "print(f\"\\nrecent_activity_drop: {df_eng['recent_activity_drop'].mean():.1%} of customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Create Interaction Features\n",
    "\n",
    "Sometimes combinations of features matter more than features alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction: New customer with support tickets = high risk\n",
    "df_eng['new_with_tickets'] = ((df['tenure_months'] < 3) & \n",
    "                              (df['support_tickets_last_30d'] > 0)).astype(int)\n",
    "\n",
    "# Interaction: Low NPS + skipped items = very unhappy\n",
    "df_eng['unhappy_skipper'] = ((df['nps_score'] < 6) & \n",
    "                             (df['items_skipped_last_3_boxes'] > 0)).astype(int)\n",
    "\n",
    "# Engagement score: combine multiple signals\n",
    "df_eng['engagement_score'] = (\n",
    "    df['logins_last_30d'] / (df['logins_last_30d'].max() + 1) +\n",
    "    df['orders_last_30d'] / (df['orders_last_30d'].max() + 1) -\n",
    "    df['items_skipped_last_3_boxes'] / 3\n",
    ")\n",
    "\n",
    "print(\"Created interaction features:\")\n",
    "print(f\"  new_with_tickets: {df_eng['new_with_tickets'].mean():.1%}\")\n",
    "print(f\"  unhappy_skipper: {df_eng['unhappy_skipper'].mean():.1%}\")\n",
    "print(f\"  engagement_score range: [{df_eng['engagement_score'].min():.2f}, {df_eng['engagement_score'].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Verify No Leakage!\n",
    "\n",
    "Before using new features, check they don't leak future information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leakage check: our engineered features should not have unrealistic correlation\n",
    "engineered_features = [\n",
    "    'orders_per_month', 'support_ticket_rate', 'login_consistency',\n",
    "    'login_trend', 'recent_activity_drop', 'new_with_tickets',\n",
    "    'unhappy_skipper', 'engagement_score'\n",
    "]\n",
    "\n",
    "print(\"=== Correlation with Churn ===\")\n",
    "print(\"(Suspicious if > 0.5 absolute)\\n\")\n",
    "\n",
    "for feat in engineered_features:\n",
    "    if df_eng[feat].notna().any():\n",
    "        corr = df_eng[feat].corr(df_eng['churn_30d'])\n",
    "        flag = \"âš ï¸ CHECK THIS\" if abs(corr) > 0.5 else \"âœ“\"\n",
    "        print(f\"  {feat:25} {corr:+.3f}  {flag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Train Model with Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined feature set\n",
    "all_features = raw_features + engineered_features\n",
    "\n",
    "X_eng = df_eng[all_features].fillna(-1)\n",
    "\n",
    "# Same train/test split\n",
    "X_train_eng, X_test_eng, _, _ = train_test_split(X_eng, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model with engineered features\n",
    "eng_model = lgb.LGBMClassifier(n_estimators=100, max_depth=5, random_state=42, verbose=-1)\n",
    "eng_model.fit(X_train_eng, y_train)\n",
    "\n",
    "eng_auc = roc_auc_score(y_test, eng_model.predict_proba(X_test_eng)[:, 1])\n",
    "\n",
    "print(f\"=== AUC Comparison ===\")\n",
    "print(f\"Baseline (raw features only): {baseline_auc:.3f}\")\n",
    "print(f\"With engineered features:     {eng_auc:.3f}\")\n",
    "print(f\"\\nImprovement: {eng_auc - baseline_auc:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which features matter now?\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'importance': eng_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['steelblue' if f in raw_features else 'darkgreen' for f in importance_df['feature']]\n",
    "plt.barh(importance_df['feature'], importance_df['importance'], color=colors)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (blue=raw, green=engineered)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision@500 comparison\n",
    "k = 500\n",
    "baseline_probs = baseline_model.predict_proba(X_test_raw)[:, 1]\n",
    "eng_probs = eng_model.predict_proba(X_test_eng)[:, 1]\n",
    "\n",
    "baseline_prec = y_test.iloc[np.argsort(baseline_probs)[-k:]].mean()\n",
    "eng_prec = y_test.iloc[np.argsort(eng_probs)[-k:]].mean()\n",
    "random_prec = y_test.mean()\n",
    "\n",
    "print(f\"=== Precision@{k} ===\")\n",
    "print(f\"Random:     {random_prec:.1%}\")\n",
    "print(f\"Baseline:   {baseline_prec:.1%} (lift: {baseline_prec/random_prec:.1f}x)\")\n",
    "print(f\"Engineered: {eng_prec:.1%} (lift: {eng_prec/random_prec:.1f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Feature Engineering Recipe\n",
    "\n",
    "A practical checklist for any tabular ML project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  FEATURE TYPE        â”‚  PATTERN                    â”‚  EXAMPLE               â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Ratios              â”‚  A / (B + eps)              â”‚  orders_per_month      â”‚\n",
    "â”‚  Changes / Trends    â”‚  recent - historical        â”‚  login_trend           â”‚\n",
    "â”‚  Binary flags        â”‚  condition.astype(int)      â”‚  recent_activity_drop  â”‚\n",
    "â”‚  Interactions        â”‚  (condition1 & condition2)  â”‚  new_with_tickets      â”‚\n",
    "â”‚  Aggregations        â”‚  sum / mean / std of group  â”‚  avg_order_value       â”‚\n",
    "â”‚  Time-based          â”‚  days_since_X, month, dow   â”‚  days_since_last_order â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "LEAKAGE CHECK for every feature:\n",
    "  \"At prediction time, would I have this information?\"\n",
    "  \n",
    "  âœ“ Safe: anything based on past behavior\n",
    "  âœ— Leakage: anything that depends on future outcome\n",
    "\"\"\"\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Final Exercise: Explain It\n",
    "\n",
    "You present your improved model to stakeholders. One asks: \"How did you improve it by 3%? Did you use more data?\"\n",
    "\n",
    "Write a 4-5 sentence response explaining feature engineering in non-technical terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your response:\n",
    "\n",
    "stakeholder_response = \"\"\"\n",
    "YOUR RESPONSE HERE\n",
    "\"\"\"\n",
    "\n",
    "print(stakeholder_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Module 5 Complete!\n",
    "\n",
    "**What you learned:**\n",
    "- How to create ratio, change, and interaction features\n",
    "- Why these often improve models\n",
    "- How to check for leakage in engineered features\n",
    "- A practical feature engineering recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=== Module 5 Summary ===\")\n",
    "print(f\"\\nFeatures: {len(raw_features)} raw â†’ {len(all_features)} total\")\n",
    "print(f\"AUC: {baseline_auc:.3f} â†’ {eng_auc:.3f} ({eng_auc - baseline_auc:+.3f})\")\n",
    "print(f\"Precision@500: {baseline_prec:.1%} â†’ {eng_prec:.1%}\")\n",
    "print(f\"\\nTop engineered feature: {importance_df[importance_df['feature'].isin(engineered_features)].iloc[-1]['feature']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next:** [Module 6: Evaluating What Matters â†’](./module_06_evaluation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
