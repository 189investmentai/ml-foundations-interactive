{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Your First Prediction Model\n",
    "\n",
    "**Goal:** Train a logistic regression model and interpret what it learned\n",
    "\n",
    "**Time:** ~20 minutes\n",
    "\n",
    "**What you'll do:**\n",
    "1. Train logistic regression on churn data\n",
    "2. Interpret the coefficients\n",
    "3. Calculate precision@500 (our business metric)\n",
    "4. Compare different customer profiles\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/189investmentai/ml-foundations-interactive/main/streamcart_customers.csv')\n",
    "except:\n",
    "    df = pd.read_csv('../data/streamcart_customers.csv')\n",
    "\n",
    "print(f\"Loaded {len(df):,} customers\")\n",
    "print(f\"Churn rate: {df['churn_30d'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Prepare the Data\n",
    "\n",
    "Select features that are:\n",
    "- Available at prediction time (no leakage!)\n",
    "- Likely predictive of churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features we'll use (these are safe‚Äîno leakage)\n",
    "features = [\n",
    "    'tenure_months',\n",
    "    'logins_last_7d',\n",
    "    'logins_last_30d',\n",
    "    'support_tickets_last_30d',\n",
    "    'items_skipped_last_3_boxes',\n",
    "    'nps_score'\n",
    "]\n",
    "\n",
    "# Handle missing values (NPS has some nulls)\n",
    "X = df[features].fillna(df[features].median())\n",
    "y = df['churn_30d']\n",
    "\n",
    "print(\"Features:\")\n",
    "for f in features:\n",
    "    print(f\"  {f}: range [{X[f].min():.0f}, {X[f].max():.0f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} customers\")\n",
    "print(f\"Test set: {len(X_test):,} customers\")\n",
    "print(f\"\\nTrain churn rate: {y_train.mean():.1%}\")\n",
    "print(f\"Test churn rate: {y_test.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Train Logistic Regression\n",
    "\n",
    "Logistic regression learns a weight (coefficient) for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and train a LogisticRegression model\n",
    "#\n",
    "# Hint: model = LogisticRegression(max_iter=1000)\n",
    "#       model.fit(X_train, y_train)\n",
    "\n",
    "model = None  # Replace with your code\n",
    "\n",
    "# Uncomment when ready:\n",
    "# model = LogisticRegression(max_iter=1000)\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK: Is the model trained?\n",
    "# ============================================\n",
    "\n",
    "assert model is not None, \"Create the model first!\"\n",
    "assert hasattr(model, 'coef_'), \"Model not trained‚Äîdid you call .fit()?\"\n",
    "print(\"‚úì Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Interpret the Coefficients\n",
    "\n",
    "This is where logistic regression shines‚Äîwe can understand **what** the model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the model learned\n",
    "print(\"=== Coefficients ===\")\n",
    "print(\"(Positive = increases churn probability, Negative = decreases churn probability)\\n\")\n",
    "\n",
    "for feature, coef in sorted(zip(features, model.coef_[0]), key=lambda x: -abs(x[1])):\n",
    "    direction = \"‚Üë churn\" if coef > 0 else \"‚Üì churn\"\n",
    "    print(f\"{feature:30} {coef:+.4f}  ({direction})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'coefficient': model.coef_[0]\n",
    "}).sort_values('coefficient')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "colors = ['green' if c < 0 else 'red' for c in coef_df['coefficient']]\n",
    "plt.barh(coef_df['feature'], coef_df['coefficient'], color=colors)\n",
    "plt.xlabel('Coefficient (positive = more churn)')\n",
    "plt.title('What Predicts Churn?')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to Answer:\n",
    "\n",
    "1. Which feature has the strongest positive effect on churn?\n",
    "2. Which feature is most protective against churn?\n",
    "3. Do these directions make business sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Answer in comments\n",
    "#\n",
    "# 1. Strongest positive (increases churn): ???\n",
    "# 2. Most protective (decreases churn): ???\n",
    "# 3. Does this make sense? ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Get Predictions\n",
    "\n",
    "Now let's use the model to predict churn probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get predicted probabilities for the test set\n",
    "#\n",
    "# Hint: predict_proba returns [P(no churn), P(churn)]\n",
    "#       You want the second column (index 1)\n",
    "\n",
    "y_pred_proba = None  # Replace with your code\n",
    "\n",
    "# Uncomment when ready:\n",
    "# y_pred_proba = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK: Are predictions valid?\n",
    "# ============================================\n",
    "\n",
    "assert y_pred_proba is not None, \"Generate predictions first!\"\n",
    "assert len(y_pred_proba) == len(y_test), \"Wrong number of predictions\"\n",
    "assert y_pred_proba.min() >= 0 and y_pred_proba.max() <= 1, \"Probabilities should be 0-1\"\n",
    "\n",
    "print(f\"‚úì Generated {len(y_pred_proba):,} predictions\")\n",
    "print(f\"  Range: {y_pred_proba.min():.2%} to {y_pred_proba.max():.2%}\")\n",
    "print(f\"  Mean: {y_pred_proba.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of predictions\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(y_pred_proba, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Predicted Churn Probability')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.title('Distribution of Predictions')\n",
    "plt.axvline(x=y_test.mean(), color='red', linestyle='--', label=f'Base rate ({y_test.mean():.1%})')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Evaluate with AUC\n",
    "\n",
    "AUC tells us: how well does the model **rank** customers by churn risk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"AUC: {auc:.3f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  0.50 = random guessing\")\n",
    "print(f\"  0.70 = decent\")\n",
    "print(f\"  0.80 = good\")\n",
    "print(f\"  0.90+ = either excellent or suspicious (check for leakage!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: The Business Metric - Precision@500\n",
    "\n",
    "AUC is nice, but the retention team can only call **500 customers per week**.\n",
    "\n",
    "The real question: Of the top 500 predictions, how many are actual churners?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate Precision@500\n",
    "#\n",
    "# Steps:\n",
    "# 1. Sort customers by predicted probability (highest first)\n",
    "# 2. Take the top 500\n",
    "# 3. Calculate what fraction actually churned\n",
    "\n",
    "k = 500\n",
    "\n",
    "# Get indices of top K predictions (highest probability)\n",
    "top_k_indices = np.argsort(y_pred_proba)[-k:]  # argsort gives low-to-high, so take last k\n",
    "\n",
    "# What fraction of top K actually churned?\n",
    "precision_at_k = None  # Replace with your code\n",
    "\n",
    "# Uncomment when ready:\n",
    "# precision_at_k = y_test.iloc[top_k_indices].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SELF-CHECK: Compare to baseline\n",
    "# ============================================\n",
    "\n",
    "assert precision_at_k is not None, \"Calculate precision@500 first!\"\n",
    "\n",
    "baseline = y_test.mean()  # Random selection would get this rate\n",
    "lift = precision_at_k / baseline\n",
    "\n",
    "print(f\"=== Precision@{k} ===\")\n",
    "print(f\"Model: {precision_at_k:.1%}\")\n",
    "print(f\"Random baseline: {baseline:.1%}\")\n",
    "print(f\"Lift: {lift:.1f}x\")\n",
    "print(f\"\\n‚Üí The model finds {lift:.1f}x more churners than random targeting!\")\n",
    "\n",
    "assert precision_at_k > baseline, \"Model should beat random!\"\n",
    "print(\"\\n‚úì Model is better than random!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does precision change at different K?\n",
    "ks = [100, 200, 300, 500, 750, 1000]\n",
    "precisions = []\n",
    "\n",
    "for k in ks:\n",
    "    top_k = np.argsort(y_pred_proba)[-k:]\n",
    "    prec = y_test.iloc[top_k].mean()\n",
    "    precisions.append(prec)\n",
    "    print(f\"Precision@{k}: {prec:.1%} (lift: {prec/baseline:.1f}x)\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(ks, precisions, 'o-', label='Model')\n",
    "plt.axhline(y=baseline, color='red', linestyle='--', label=f'Random ({baseline:.1%})')\n",
    "plt.xlabel('K (number of customers targeted)')\n",
    "plt.ylabel('Precision (% churners in top K)')\n",
    "plt.title('Precision at Different K')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Compare Customer Profiles\n",
    "\n",
    "Let's see how the model scores different types of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hypothetical customer profiles\n",
    "profiles = pd.DataFrame([\n",
    "    # High risk: new, inactive, complaining\n",
    "    {'tenure_months': 2, 'logins_last_7d': 0, 'logins_last_30d': 2,\n",
    "     'support_tickets_last_30d': 3, 'items_skipped_last_3_boxes': 2, 'nps_score': 4},\n",
    "    \n",
    "    # Low risk: veteran, engaged, happy\n",
    "    {'tenure_months': 24, 'logins_last_7d': 5, 'logins_last_30d': 20,\n",
    "     'support_tickets_last_30d': 0, 'items_skipped_last_3_boxes': 0, 'nps_score': 9},\n",
    "    \n",
    "    # Medium: average customer\n",
    "    {'tenure_months': 8, 'logins_last_7d': 2, 'logins_last_30d': 8,\n",
    "     'support_tickets_last_30d': 1, 'items_skipped_last_3_boxes': 1, 'nps_score': 7},\n",
    "])\n",
    "\n",
    "profile_names = ['High Risk (new, inactive)', 'Low Risk (veteran, engaged)', 'Average Customer']\n",
    "\n",
    "# Predict\n",
    "profile_probs = model.predict_proba(profiles)[:, 1]\n",
    "\n",
    "print(\"=== Customer Profile Predictions ===\")\n",
    "for name, prob in zip(profile_names, profile_probs):\n",
    "    print(f\"{name}: {prob:.1%} churn probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find actual high and low risk customers in test set\n",
    "high_risk_idx = np.argmax(y_pred_proba)\n",
    "low_risk_idx = np.argmin(y_pred_proba)\n",
    "\n",
    "print(\"=== Real High Risk Customer ===\")\n",
    "print(X_test.iloc[high_risk_idx])\n",
    "print(f\"Predicted churn: {y_pred_proba[high_risk_idx]:.1%}\")\n",
    "print(f\"Actually churned: {'Yes' if y_test.iloc[high_risk_idx] == 1 else 'No'}\")\n",
    "\n",
    "print(\"\\n=== Real Low Risk Customer ===\")\n",
    "print(X_test.iloc[low_risk_idx])\n",
    "print(f\"Predicted churn: {y_pred_proba[low_risk_idx]:.1%}\")\n",
    "print(f\"Actually churned: {'Yes' if y_test.iloc[low_risk_idx] == 1 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Final Exercise: Explain It\n",
    "\n",
    "Your PM asks: \"Why are we using such a simple model? Shouldn't we use AI?\"\n",
    "\n",
    "Write a 4-5 sentence response explaining why logistic regression is a good starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your response here:\n",
    "\n",
    "pm_response = \"\"\"\n",
    "YOUR RESPONSE HERE\n",
    "\"\"\"\n",
    "\n",
    "print(pm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Module 2 Complete!\n",
    "\n",
    "**What you learned:**\n",
    "- How to train logistic regression\n",
    "- How to interpret coefficients\n",
    "- How to calculate precision@K (the business metric)\n",
    "- How to compare customer profiles\n",
    "\n",
    "**Key metrics from this lab:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=== Module 2 Summary ===\")\n",
    "print(f\"Model: Logistic Regression\")\n",
    "print(f\"Features: {len(features)}\")\n",
    "print(f\"AUC: {auc:.3f}\")\n",
    "print(f\"Precision@500: {precision_at_k:.1%}\")\n",
    "print(f\"Lift@500: {lift:.1f}x\")\n",
    "print(f\"\\nTop predictor of churn: {features[np.argmax(model.coef_[0])]}\")\n",
    "print(f\"Most protective factor: {features[np.argmin(model.coef_[0])]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next:** [Module 3: When Linear Isn't Enough ‚Üí](./module_03_decision_trees.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
